{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gym/envs/registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from gymnasium import spaces\n",
    "%matplotlib inline\n",
    "# import gymnasium as gym\n",
    "# from gym.envs.registration import registry, register\n",
    "from minigrid.wrappers import DictObservationSpaceWrapper # so that text mission string is actually a numerical dict\n",
    "\n",
    "# env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode = \"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env) # ONLY DO THIS FOR PPO TRAINING\n",
    "# env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "# import gym\n",
    "import torch\n",
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper, RGBImgObsWrapper, RGBImgPartialObsWrapper, DictObservationSpaceWrapper, ViewSizeWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x164877ec0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (56, 56, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x164877ec0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\")\n",
    "print(env.observation_space)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the wrappers for the environment\n",
    "\n",
    "`MissionEncodingWrapper` adds one for every discrete space in the one-hot encoding of the mission, allowing 0 to be encoded as well.\n",
    "\n",
    "`ImageFeaturesExtractor` extracts relevant features if the observation is just an image, used with `ImgObsWrapper`\n",
    "\n",
    "`MinigridFeaturesExtractor` extracts relevant features from the entire observation, used with `MissionEncodingWrapper` and `DictObservationSpaceWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "# a custom wrapper to make the mission vector work with one hot encoding\n",
    "class MissionEncodingWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['mission'] = spaces.MultiDiscrete(np.array([n+1 for n in env.observation_space['mission'].nvec]))\n",
    "    def observation(self, obs):\n",
    "        return obs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gymnasium.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        direction = observation_space['direction']\n",
    "        image = observation_space['image']\n",
    "        mission_string = observation_space['mission']\n",
    "        n_input_channels = image.shape[0] # should be 3, for RGB\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        direction_output_dim = 8\n",
    "        self.direction_net = nn.Sequential(nn.Linear(direction.n, direction_output_dim), nn.ReLU()) \n",
    "        \n",
    "        \n",
    "        ## add text extractor\n",
    "        self.transformer = nn.Transformer(d_model=len(mission_string), nhead=2, num_encoder_layers=2, num_decoder_layers=2) # squared because of one hot encoding\n",
    "        \n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space['image'].sample()[None]).float()).shape[1] ## 1024 for this example\n",
    "            \n",
    "        self.sentence_transformer_dim = len(mission_string) # is one-hot best here? or should we condense it to 50D vector?\n",
    "            \n",
    "        linear_input_dim = n_flatten + self.sentence_transformer_dim + direction_output_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(linear_input_dim, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        image_features = self.cnn(observations['image']) # .transpose((2, 0, 1)\n",
    "        direction_features = self.direction_net(observations['direction'])\n",
    "        if direction_features.shape[1] == 1:\n",
    "            direction_features = direction_features.squeeze(1)\n",
    "            \n",
    "       \n",
    "        one_hot_mission = observations['mission'].squeeze(0)\n",
    "       \n",
    "        mission_string_encoding = torch.empty((observations['mission'].shape[0], self.sentence_transformer_dim))\n",
    "        \n",
    "        # turn back into labels instead of one hot encoding\n",
    "        for i in range(0, self.sentence_transformer_dim**2, self.sentence_transformer_dim):\n",
    "\n",
    "            if len(one_hot_mission.size()) == 1:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = (torch.argmax(one_hot_mission[i:i+self.sentence_transformer_dim], dim = 0))\n",
    "            else:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = torch.argmax(one_hot_mission[:, i:i+self.sentence_transformer_dim], dim = 1)\n",
    "       \n",
    "        src = trg = torch.as_tensor(mission_string_encoding).unsqueeze(0).float()\n",
    "        \n",
    "        sentence_features = self.transformer(src, trg).squeeze(0) # to match dimensions\n",
    "\n",
    "        \n",
    "        try:\n",
    "            observations = torch.cat([image_features, sentence_features, direction_features], dim = 1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"image features dim\", image_features.shape)\n",
    "            print(\"sentence features dim\", sentence_features.shape)\n",
    "            print(\"direction features dim\", direction_features.shape)\n",
    "        return self.linear(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save it. -- also try `FlatObsWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (152, 152, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x164877ec0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "(608, 608, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x164a0d220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env)\n",
    "# env = MissionEncodingWrapper(env)\n",
    "env = RGBImgObsWrapper(env)\n",
    "\n",
    "print(env.observation_space)\n",
    "env.reset()\n",
    "r = env.render()\n",
    "print(r.shape)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions:\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    FORWARD = 2\n",
    "    PICKUP = 3\n",
    "    DROP = 4\n",
    "    TOGGLE = 5\n",
    "    DONE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIRECTION:\n",
    "Up: 3\n",
    "Left: 2\n",
    "Down: 1\n",
    "Right: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Video of the trained policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to render image\n",
    "\n",
    "-- good for passing into GPT4 VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "render = env.render()\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "ax.imshow(render) # , cmap=plt.get_cmap('gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from api.settings import Settings\n",
    "\n",
    "openai_client = OpenAI(api_key=Settings().openai_key)\n",
    "\n",
    "def vision(prompt_text: str, img_base64: str):\n",
    "    \"\"\"Run a GPT-4 vision model on the prompt text and image.\n",
    "\n",
    "    ```\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(r)\n",
    "    vision(\"what do you see?\", image_to_base64(im))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{img_base64}\",\n",
    "                        \"detail\": \"low\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# def complete(prompt_text: str):\n",
    "#     \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "#     gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": prompt_text},\n",
    "#             ],\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     response = openai_client.chat.completions.create(\n",
    "#         model=gpt_model,\n",
    "#         messages=messages,\n",
    "#         temperature=0.2,\n",
    "#         max_tokens=300,\n",
    "#     )\n",
    "#     return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.9,\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the green key from the blue room, unlock the green door and go to the goal'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the purple key from the grey room, unlock the purple door and go to the goal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "plt.imshow(render)\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = '''You are an assistant aiding with subgoal generataion for reinforcement learning problems. Specifically, you will\n",
    "be given an example environment picture and a textual goal description, and you are to output language subgoals that the agent\n",
    "should achieve in order to efficiently and successfully achieve the main goal.\n",
    "\n",
    "The goal description is:\n",
    "\n",
    "get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal\n",
    "\n",
    "where you can use {lockedroom_color}, {keyroom_color}, and {door_color} as variables in the subgoals and the goal is a light green square.\n",
    "The variables can be the values red, green, blue, purple, yellow or grey.\n",
    "\n",
    "These subgoals should be with respect to the image itself: they should specify specific observations that\n",
    "show that the agent is on track. They should also be singular; they should output exactly one subtask instead of a group of multiple steps.\n",
    "Output a list of ONLY these text subgoals in the following format (without any introduction text):\n",
    "\n",
    "- [subgoal 1]\n",
    "- [subgoal 2]\n",
    "- ...\n",
    "\n",
    "where [subgoal i] is replaced by the ith subgoal. subgoals Do not create directional subgoals but rather strategic\n",
    "subgoals that do not hard code the direction but instead tell the agent which states are more beneficial. The subgoals should be able to be completed\n",
    "by the agent moving, picking up a key, or using a key.\n",
    "\n",
    "You should enough subgoals to be descriptive but not redundant. Use the included example image to be specific.\n",
    "\n",
    "Remember that the included image is an example of the environment but the door, key, and goal locations may differ so use it for context but do not\n",
    "hardcode the goals with respect to this specific image.\n",
    "'''\n",
    "\n",
    "prompt2_part1 = '''\n",
    "You are an assistant tasked with turning language subgoals into machine readable code. You will be given text subgoals, and you must translate\n",
    "these subgoals into code that takes in an observation of the format\n",
    "\n",
    "{'direction': Discrete(4), 'image': np.ndarray, 'mission': str}\n",
    "\n",
    "'direction' is a number with the corresponding direction:\n",
    "    3: Up\n",
    "    2: Left\n",
    "    1: Down\n",
    "    0: Right\n",
    "\n",
    "'image' is of shape (width x height x 3), and the final dimension corresponds to a 3D tuple of (OBJECT_IDX, COLOR_IDX, STATE). Here, \n",
    "\n",
    "OBJECT_IDX is a number with the corresponding object type: \n",
    "    0: \"unseen\"\n",
    "    1: \"empty\"\n",
    "    2: \"wall\"\n",
    "    3: \"floor\"\n",
    "    4: \"door\"\n",
    "    5: \"key\"\n",
    "    \n",
    "COLOR_IDX is a number with the corresponding color:\n",
    "    0: \"red\"\n",
    "    1: \"green\"\n",
    "    2: \"blue\"\n",
    "    3: \"purple\"\n",
    "    4: \"yellow\"\n",
    "    5: \"grey\"\n",
    "\n",
    "STATE is a number with the corresponding state if the object is a door: \n",
    "    0: \"open\"\n",
    "    1: \"closed\"\n",
    "    2: \"locked\"\n",
    "\n",
    "The agent is centered at the bottom of the image.\n",
    "\n",
    "'mission' is of the form get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal\n",
    "\n",
    "The text subgoals will include these variables {lockedroom_color}, {keyroom_color}, and {door_color}, which are integers corresponding to the above encoding for COLOR_IDX.\n",
    "\n",
    "As part of your reward function, you can use these three variables {lockedroom_color}, {keyroom_color}, and {door_color}\n",
    "to determine your specific reward function for the subgoal. You can also use the action which comes as an integer 0 through 6, labeled as follows:\n",
    "\n",
    "0: turn left, 1: turn right, 2: move forward, 3: pick up an object, 4: DON'T USE, 5: toggle/activate an object, 6: DON'T USE\n",
    "\n",
    "The reward function must have the signature: reward_{i}(observation, action, lockedroom_color, keyroom_color, door_color) where i is '''\n",
    "\n",
    "prompt2_part2 = '''\n",
    ". \n",
    "Output the subgoal as a  python functions that takes in the above parameters and returns the reward that prioritizes the specific subgoal. The only external library you can use is numpy.\n",
    "This reward function should be dense; it should make the agent want to move closer to the specific subgoal. For example, you can use a distance function to achieve this for certain subgoals. You can also\n",
    "add reward components to ensure the prerequisites for the current subgoal are achieved if you think that would help.\n",
    "Have the maximum reward of the function be 1 (where the goal is obtained) and the minimum be 0. DO NOT use float('inf') or float('-inf') in your function.\n",
    "The code should be the only thing you output, all in one python function without sub functions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from api.image import image_to_base64\n",
    "\n",
    "im = Image.fromarray(render)\n",
    "completion1 = vision(prompt1, image_to_base64(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Locate the {keyroom_color} room.\n",
      "- Navigate to the {keyroom_color} room.\n",
      "- Acquire the {lockedroom_color} key located in the {keyroom_color} room.\n",
      "- Identify the {door_color} door.\n",
      "- Move to the {door_color} door.\n",
      "- Use the {lockedroom_color} key to unlock the {door_color} door.\n",
      "- Proceed through the unlocked {door_color} door.\n",
      "- Reach the goal area marked by the light green square.\n"
     ]
    }
   ],
   "source": [
    "print(completion1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations:: vision -- need better model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(render)\n",
    "iterations = 3\n",
    "subgoal_set = []\n",
    "chars = ['A', 'B', 'C']\n",
    "for j in range(iterations):\n",
    "    completions = []\n",
    "    for i, sg in enumerate(completion1.choices[0].message.content.splitlines()):\n",
    "        completions.append(complete(prompt2_part1 + str(i) + chars[j] + prompt2_part2 + '\\nThe textual subgoal is as follows: ' + sg))\n",
    "        \n",
    "    completion_funcs = [c.choices[0].message.content for c in completions]\n",
    "    completion_funcs_execute = ['\\n'.join(c.splitlines()[1:-1]) for c in completion_funcs]\n",
    "    subgoal_set.append(completion_funcs_execute)\n",
    "    for c in completion_funcs_execute:\n",
    "        exec(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mission_to_string(mission_encoding):\n",
    "    indices = [idx - 1 for idx in mission_encoding] # remove offset\n",
    "    translation = {v: k for k, v in DictObservationSpaceWrapper.get_minigrid_words().items()}\n",
    "    translation[-1] = ''\n",
    "    return ' '.join([translation[idx] for idx in indices])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import RewardWrapper\n",
    "RENDERS = []\n",
    "class CustomRewardWrapper(RewardWrapper):\n",
    "    def __init__(self, env, reward_func):\n",
    "        super().__init__(env)\n",
    "        self.generate_reward_func = reward_func # (obs, action) -> reard\n",
    "        self.counts = {} # ((x, y), action) => count\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        #params\n",
    "        bonus_factor = 0.01 # the exploration bonus\n",
    "        intrinsic_factor = 0.9 # how much the intrinsic reward should be weighted\n",
    "        progress_bonus = 1.5 # the bonus for reaching farther and farther goals\n",
    "        \n",
    "        observation, _, terminated, truncated, info = self.env.step(action)\n",
    "        reward, goal_number =  self.reward_func(observation, action)\n",
    "\n",
    "        # save render for debugging\n",
    "        if goal_number >= 3:\n",
    "            RENDERS.append(self.env.render())\n",
    "        \n",
    "        reward *= (progress_bonus ** goal_number) * intrinsic_factor # to incentivize further goals\n",
    "        \n",
    "        pos = tuple(self.agent_pos)\n",
    "        state_and_action = (pos, action.item())\n",
    "\n",
    "        # Get the count for this key\n",
    "        count = self.counts[state_and_action] if state_and_action in self.counts else 0\n",
    "\n",
    "        # Update the count for this key\n",
    "        self.counts[state_and_action] = count + 1\n",
    "        \n",
    "        bonus = 1 / math.sqrt(self.counts[state_and_action])\n",
    "        #reward += bonus_factor + bonus\n",
    "\n",
    "        # Get the position in front of the agent\n",
    "        fwd_pos = self.front_pos\n",
    "        fwd_cell = self.grid.get(*fwd_pos)\n",
    "        if action == self.actions.forward and fwd_cell is not None and fwd_cell.type == \"goal\":\n",
    "            print(\"REACHED GOAL, EXTRINSIC REWARD: \", self._reward())\n",
    "            reward += self._reward()\n",
    "            \n",
    "            \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        self.reward_func = self.generate_reward_func()\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(subgoal_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MANUAL Test for subgoal sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "x = env.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [6 3]]\n",
      "(6, 3)\n",
      "[[False False False False False False False]\n",
      " [False False False False False False False]\n",
      " [ True False False False False False False]\n",
      " [False False False False False False False]\n",
      " [False False False False False False False]\n",
      " [False False False False False False False]\n",
      " [False False False False False False False]]\n",
      "(array([2]), array([0]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, *_ = env.step(np.array([Actions.TOGGLE]))\n",
    "r = env.render()\n",
    "plt.imshow(r)\n",
    "image = obs['image']\n",
    "keyroom_color = 2 # blue\n",
    "key = 5\n",
    "key_positions = np.nonzero((obs['image'][:, :, 0] == key) & (obs['image'][:, :, 1] == keyroom_color))\n",
    "agent_position = (image.shape[0] - 1, image.shape[1] // 2)ss\n",
    "\n",
    "if len(key_positions) > 0:\n",
    "    print((obs['image'][:, :, 0] == key) & (obs['image'][:, :, 1] == keyroom_color))\n",
    "    print(key_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key_positions = np.argwhere((obs['image'][:, :, 0] == 5) & (obs['image'][:, :, 1] == keyroom_color))\n",
    "print(key_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2857142857142857\n",
      "0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env.reset()\n",
    "action = np.array([Actions.TOGGLE])\n",
    "obs, _, _, _, _ = env.step(action)\n",
    "r = env.render()\n",
    "plt.imshow(r)\n",
    "COLOR_TO_IDX = {\"red\": 0, \"green\": 1, \"blue\": 2, \"purple\": 3, \"yellow\": 4, \"grey\": 5}\n",
    "\n",
    "mission = obs['mission']#mission_to_string(obs['mission'])\n",
    "# preprocess -- ideally this would be done with LLM if we had more compute\n",
    "lockedroom_color = COLOR_TO_IDX[mission.split(' ')[2]]\n",
    "keyroom_color = COLOR_TO_IDX[mission.split(' ')[6]]\n",
    "door_color = COLOR_TO_IDX[mission.split(' ')[10]]\n",
    "\n",
    "print(reward_1A(obs, action, lockedroom_color, keyroom_color, door_color))\n",
    "print(reward_2A(obs, action, lockedroom_color, keyroom_color, door_color))\n",
    "print(reward_3A(obs, action, lockedroom_color, keyroom_color, door_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def reward_1A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    # Extract variables from observation\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    mission = observation['mission']\n",
      "    \n",
      "    # Constants\n",
      "    KEY_OBJECT_IDX = 5\n",
      "    KEY_PICKUP_ACTION = 3\n",
      "    \n",
      "    # Setup rewards\n",
      "    max_reward = 1.0\n",
      "    min_reward = 0.0\n",
      "    distance_penalty_weight = 0.01\n",
      "    wrong_action_penalty = -0.1\n",
      "\n",
      "    # Determine the position of the agent (assumed at the bottom center of the image)\n",
      "    agent_position = (image.shape[0] - 1, image.shape[1] // 2)\n",
      "    \n",
      "    # Identify all key positions in the keyroom_color room\n",
      "    key_positions = np.argwhere((image[:, :, 0] == KEY_OBJECT_IDX) & (image[:, :, 1] == keyroom_color))\n",
      "    \n",
      "    # If there are no keys in the keyroom_color, return minimum reward\n",
      "    if key_positions.size == 0:\n",
      "        return min_reward\n",
      "    \n",
      "    # Calculate the Manhattan distance to the closest key of the correct color in the keyroom_color room\n",
      "    distances = np.abs(key_positions - np.array(agent_position))\n",
      "    min_distance = np.min(np.sum(distances, axis=1))\n",
      "    \n",
      "    # Check if action is to pick up the key\n",
      "    if action == KEY_PICKUP_ACTION:\n",
      "        # Check if the agent is at the position of any key of lockedroom_color in the keyroom_color room\n",
      "        if any((agent_position[0], agent_position[1]) == tuple(pos) for pos in key_positions):\n",
      "            # Verify that the key picked is the lockedroom_color key, ensure reward is 1\n",
      "            if image[agent_position[0], agent_position[1], 1] == lockedroom_color:\n",
      "                return max_reward\n",
      "            else:\n",
      "                return min_reward + wrong_action_penalty\n",
      "        else:\n",
      "            # Penalty for trying to pick up non-existent key\n",
      "            return min_reward + wrong_action_penalty\n",
      "    else:\n",
      "        # Compute distance penalty, to encourage moving closer to the key\n",
      "        normalized_distance_penalty = distance_penalty_weight * min_distance\n",
      "    \n",
      "        # Final reward based on moving closer to the key\n",
      "        return max(min_reward, max_reward - normalized_distance_penalty)\n",
      "import numpy as np\n",
      "\n",
      "def reward_1B(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    mission = observation['mission']\n",
      "    \n",
      "    # Constants\n",
      "    KEY_OBJECT_IDX = 5\n",
      "    FLOOR_OBJECT_IDX = 3\n",
      "    \n",
      "    # Calculate the center of the image (agent's position)\n",
      "    (width, height, _) = image.shape\n",
      "    agent_x = width // 2\n",
      "    agent_y = height - 1  # Agent is always at the bottom center\n",
      "    \n",
      "    # Find all keys of the required color in the image\n",
      "    key_positions = np.argwhere((image[:, :, 0] == KEY_OBJECT_IDX) & (image[:, :, 1] == keyroom_color))\n",
      "    \n",
      "    if len(key_positions) == 0:\n",
      "        # No key found, minimal reward\n",
      "        return 0\n",
      "    \n",
      "    # Calculate distances to all keys\n",
      "    distances = np.sqrt((key_positions[:, 0] - agent_x) ** 2 + (key_positions[:, 1] - agent_y) ** 2)\n",
      "    \n",
      "    # Find the minimum distance\n",
      "    min_distance = np.min(distances)\n",
      "    \n",
      "    # Normalize distance to be between 0 and 1, where 0 is farthest and 1 is picking up the key\n",
      "    max_distance = np.sqrt(agent_x ** 2 + agent_y ** 2)  # Max possible distance from the agent to corner of the image\n",
      "    normalized_distance_reward = 1 - (min_distance / max_distance)\n",
      "    \n",
      "    # Check if agent is on a key location of the correct color and if the pick up action is used\n",
      "    if action == 3:  # Action 3: pick up an object\n",
      "        # Check if under the agent there's a key of the correct color\n",
      "        object_at_agent = image[agent_x, agent_y]\n",
      "        if object_at_agent[0] == KEY_OBJECT_IDX and object_at_agent[1] == keyroom_color:\n",
      "            return 1  # Maximum reward when the key is picked up\n",
      "    \n",
      "    return normalized_distance_reward\n",
      "import numpy as np\n",
      "\n",
      "def reward_1C(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    image = observation['image']\n",
      "    width, height, _ = image.shape\n",
      "\n",
      "    # Agent is at the bottom center of the image\n",
      "    agent_x = width // 2\n",
      "    agent_y = height - 1\n",
      "    \n",
      "    # Rewards for each pixel that matches the desired key in the keyroom\n",
      "    reward = 0.0\n",
      "\n",
      "    # Check for key within the specified color room\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            object_idx, color_idx, _ = image[x, y]\n",
      "            \n",
      "            # Check if the object is a key and in the correct room color\n",
      "            if object_idx == 5 and color_idx == lockedroom_color:\n",
      "                room_color = image[x, y][1]\n",
      "                \n",
      "                # Check if the key is in the correct keyroom color\n",
      "                if room_color == keyroom_color:\n",
      "                    # Simple distance calculation, Manhattan distance\n",
      "                    dist = abs(x - agent_x) + abs(y - agent_y)\n",
      "                    sub_reward = 1 - dist / (width + height)\n",
      "                    \n",
      "                    # If picking up the key, maximum reward\n",
      "                    if action == 3 and dist == 0:\n",
      "                        reward = 1.0\n",
      "                    else:\n",
      "                        # Higher reward closer to the key\n",
      "                        reward = max(reward, sub_reward)\n",
      "\n",
      "    return reward\n"
     ]
    }
   ],
   "source": [
    "print(subgoal_set[0][1])\n",
    "print(subgoal_set[1][1])\n",
    "print(subgoal_set[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def reward_2A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    image = observation['image']\n",
      "    width, height, _ = image.shape\n",
      "    agent_y = height - 1  # Agent is at the bottom row of the image\n",
      "    \n",
      "    # Finding the {door_color} door position\n",
      "    door_positions = []\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            # Check if it is a door with the required color and is either closed or locked\n",
      "            if image[x, y, 0] == 4 and image[x, y, 1] == door_color and image[x, y, 2] in (1, 2):\n",
      "                door_positions.append((x, y))\n",
      "    \n",
      "    # If no door is found, minimum reward\n",
      "    if not door_positions:\n",
      "        return 0.0\n",
      "    \n",
      "    # Compute the minimum Manhattan distance from the agent position to any {door_color} door\n",
      "    min_distance = min(abs(x - (width // 2)) + abs(y - agent_y) for x, y in door_positions)\n",
      "  \n",
      "    # Normalize the distance to get a reward between 0 and 1, where 1 is at the door\n",
      "    max_possible_distance = width + height - 2  # Maximum possible Manhattan distance in the grid\n",
      "    reward = 1 - (min_distance / max_possible_distance)\n",
      "    \n",
      "    # Ensure rewarding action towards the door\n",
      "    if action == 2:  # If the action is \"move forward\"\n",
      "        # Check the cell in front of the agent; the agent is always facing up direction from the center bottom\n",
      "        front_cell = image[width // 2, agent_y - 1]\n",
      "        # Moving towards a door\n",
      "        if front_cell[0] == 4 and front_cell[1] == door_color and front_cell[2] in (1, 2):\n",
      "            reward += 0.1  # Encourage moving towards the door\n",
      "    \n",
      "    # Cap the reward to be between 0 and 1\n",
      "    return min(max(reward, 0.0), 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(subgoal_set[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subgoal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "EPSILON = 0.1\n",
    "def generate_total_reward():\n",
    "    goal_number = 0\n",
    "      \n",
    "    reward_funcs = [\n",
    "        (reward_0A, reward_0B, reward_0C),\n",
    "        (reward_1A, reward_1B, reward_1C),\n",
    "        (reward_2A, reward_2B, reward_2C),\n",
    "        (reward_3A, reward_3B, reward_3C),\n",
    "        (reward_4A, reward_4B, reward_4C),\n",
    "        (reward_5A, reward_5B, reward_5C),\n",
    "        (reward_6A, reward_6B, reward_6C),\n",
    "        (reward_7A, reward_7B, reward_7C)\n",
    "    ]\n",
    "    def total_reward(obs, action):\n",
    "        nonlocal goal_number\n",
    "        \n",
    "        # print(obs)\n",
    "        gamma = 0.0005 # probability to skip to next subgoal\n",
    "        \n",
    "        COLOR_TO_IDX = {\"red\": 0, \"green\": 1, \"blue\": 2, \"purple\": 3, \"yellow\": 4, \"grey\": 5}\n",
    "        \n",
    "        # preprocess -- ideally this would be done with LLM if we had more compute\n",
    "        lockedroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[2]]\n",
    "        keyroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[6]]\n",
    "        door_color = COLOR_TO_IDX[obs['mission'].split(' ')[10]]\n",
    "        \n",
    "        \n",
    "        rewards = []\n",
    "        for sg_num, sg in enumerate(reward_funcs):\n",
    "            reward = 0\n",
    "            for i, r in enumerate(sg):\n",
    "                if 'inf' in subgoal_set[i][sg_num]:\n",
    "                    continue\n",
    "                try:\n",
    "                    reward = max(r(obs, action, lockedroom_color, keyroom_color, door_color), reward)\n",
    "                except:\n",
    "                    pass\n",
    "            rewards.append(reward)\n",
    "            \n",
    "        \n",
    "        # goals are often related, so weight future goals (on decay)\n",
    "        decay = 0.4 # lambda\n",
    "        reward = sum((rewards[i] * (decay**i)) for i in range(len(rewards[goal_number:])))\n",
    "            \n",
    "        # or np.random.rand() < gamma\n",
    "\n",
    "        if (rewards[goal_number] > 1-EPSILON) and goal_number < len(reward_funcs) - 1:\n",
    "            \n",
    "            print(\"switching functions from \" + str(goal_number) + \" to \" + str(goal_number + 1))\n",
    "            goal_number += 1\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        return reward, goal_number\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "# env = ViewSizeWrapper(env, agent_view_size=7) # so the cnn can work with kernel size 8\n",
    "env = CustomRewardWrapper(env, generate_total_reward)\n",
    "env = RGBImgPartialObsWrapper(env) # reward is calculated using regular obs, then plugged into model with img obs\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def reward_4A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    image = observation['image']\n",
      "    direction = observation['direction']\n",
      "    \n",
      "    # Constants for image interpretation\n",
      "    OBJECT_IDX = 4  # Index for 'door'\n",
      "    DOOR_STATE_OPEN = 0\n",
      "    \n",
      "    # Locate doors that match the door_color and are open\n",
      "    door_positions = np.where((image[:, :, 0] == OBJECT_IDX) & (image[:, :, 1] == door_color) & (image[:, :, 2] == DOOR_STATE_OPEN))\n",
      "    \n",
      "    if len(door_positions[0]) > 0:\n",
      "        # Calculate distance to the nearest correct door\n",
      "        agent_position = (image.shape[0] - 1, image.shape[1] // 2)  # Agent is centered at the bottom of the image\n",
      "        distances = np.sqrt((door_positions[0] - agent_position[0]) ** 2 + (door_positions[1] - agent_position[1]) ** 2)\n",
      "        min_distance = np.min(distances)\n",
      "\n",
      "        # Normalize distance to be a value between 0 and 1, where 0 is the farthest and 1 is at the door\n",
      "        max_possible_distance = np.sqrt((image.shape[0] - 1) ** 2 + (image.shape[1] // 2) ** 2)\n",
      "        distance_reward = 1 - (min_distance / max_possible_distance)\n",
      "\n",
      "        # Check if the agent is facing the nearest door and is close by\n",
      "        nearest_door_position = (door_positions[0][np.argmin(distances)], door_positions[1][np.argmin(distances)])\n",
      "        facing_reward = 0\n",
      "        if action == 2:  # Moving forward\n",
      "            if direction == 0 and nearest_door_position[1] > agent_position[1]:  # Facing right\n",
      "                facing_reward = 1\n",
      "            elif direction == 1 and nearest_door_position[0] > agent_position[0]:  # Facing down\n",
      "                facing_reward = 1\n",
      "            elif direction == 2 and nearest_door_position[1] < agent_position[1]:  # Facing left\n",
      "                facing_reward = 1\n",
      "            elif direction == 3 and nearest_door_position[0] < agent_position[0]:  # Facing up\n",
      "                facing_reward = 1\n",
      "\n",
      "        # Larger reward if the agent is facing and moving towards the door\n",
      "        total_reward = 0.7 * distance_reward + 0.3 * facing_reward\n",
      "    else:\n",
      "        # No open door of the correct color is visible\n",
      "        total_reward = 0\n",
      "\n",
      "    return total_reward\n"
     ]
    }
   ],
   "source": [
    "print(subgoal_set[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 5.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 483      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 5.31         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087223435 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.141       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.585       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    value_loss           | 0.054        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008546986 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.054       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 173         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010636373 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0192     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.611      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 0.0571      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014399262 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.594      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.0867      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015867349 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.0686      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019455273 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.198      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.631      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 0.039       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023325607 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.653      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0518     |\n",
      "|    value_loss           | 0.048       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023980182 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.632      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0524     |\n",
      "|    value_loss           | 0.0466      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02575436 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.646     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.0298     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024800606 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.638      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0533     |\n",
      "|    value_loss           | 0.0361      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023770284 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.143      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.589      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    value_loss           | 0.0316      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023484338 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.651      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0585     |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 5.96       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02547755 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.498      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.649     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    value_loss           | 0.0352     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026154581 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.641      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0594     |\n",
      "|    value_loss           | 0.043       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025088932 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.667      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0546     |\n",
      "|    value_loss           | 0.0319      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024452921 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.652      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0655     |\n",
      "|    value_loss           | 0.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027241565 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.617      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.06       |\n",
      "|    value_loss           | 0.0493      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028879717 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.617      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0618     |\n",
      "|    value_loss           | 0.0368      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02586955 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.86      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.608     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0593    |\n",
      "|    value_loss           | 0.0357     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026262667 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.0657      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.615      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0566     |\n",
      "|    value_loss           | 0.0444      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027221352 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.602      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0578     |\n",
      "|    value_loss           | 0.0355      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026689358 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0976     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.619      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0609     |\n",
      "|    value_loss           | 0.0552      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026531609 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.635      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0633     |\n",
      "|    value_loss           | 0.0446      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026336737 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.645      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0652     |\n",
      "|    value_loss           | 0.0432      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025682822 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0643     |\n",
      "|    value_loss           | 0.0393      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027063642 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0624     |\n",
      "|    value_loss           | 0.0269      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025398454 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.669      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0626     |\n",
      "|    value_loss           | 0.0283      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024666123 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.624      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0666     |\n",
      "|    value_loss           | 0.0319      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027253397 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.661      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0689     |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029700022 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.651      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    value_loss           | 0.0457      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026964454 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.659      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0676     |\n",
      "|    value_loss           | 0.0442      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024807539 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.623      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0635     |\n",
      "|    value_loss           | 0.0433      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028050972 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0678     |\n",
      "|    value_loss           | 0.0384      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027703766 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.649      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0723     |\n",
      "|    value_loss           | 0.0361      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025716573 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.619      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0574     |\n",
      "|    value_loss           | 0.0304      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 542        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02974751 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.54       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.665     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0765    |\n",
      "|    value_loss           | 0.0273     |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.31       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 557        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02714175 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.573     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0588    |\n",
      "|    value_loss           | 0.0487     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 573        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02701883 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.658     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0666    |\n",
      "|    value_loss           | 0.045      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026704364 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.651      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0647     |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028074494 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.603      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0716     |\n",
      "|    value_loss           | 0.0277      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024772268 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0439     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.667      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0672     |\n",
      "|    value_loss           | 0.0381      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025291935 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.613      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0659     |\n",
      "|    value_loss           | 0.0441      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024538424 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.633      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.059      |\n",
      "|    value_loss           | 0.0505      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025550626 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.612      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0602     |\n",
      "|    value_loss           | 0.0322      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024200339 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.623      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    value_loss           | 0.0709      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029133067 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.652      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0709     |\n",
      "|    value_loss           | 0.036       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028405316 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.638      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0705     |\n",
      "|    value_loss           | 0.0375      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026648289 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.328      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.644      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.068      |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024190186 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.629      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0647     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 756         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030271243 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.676      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0726     |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.51       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 772        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02807336 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.644     |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.071     |\n",
      "|    value_loss           | 0.031      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025775801 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.578      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0656     |\n",
      "|    value_loss           | 0.0428      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025980446 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.628      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0665     |\n",
      "|    value_loss           | 0.0386      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 817         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025362503 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.611      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0689     |\n",
      "|    value_loss           | 0.0435      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 833        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02634183 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | -0.201     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.678     |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0656    |\n",
      "|    value_loss           | 0.0275     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027762314 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.658      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0701     |\n",
      "|    value_loss           | 0.0423      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027647737 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.642      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0715     |\n",
      "|    value_loss           | 0.03        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 880        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02687167 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.613     |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0652    |\n",
      "|    value_loss           | 0.0297     |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 895        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02654646 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.106      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.64      |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    value_loss           | 0.0301     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 911        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02663065 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.612     |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.066     |\n",
      "|    value_loss           | 0.043      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 190       |\n",
      "|    ep_rew_mean          | 6.45      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 137       |\n",
      "|    iterations           | 62        |\n",
      "|    time_elapsed         | 926       |\n",
      "|    total_timesteps      | 126976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0278209 |\n",
      "|    clip_fraction        | 0.32      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.86     |\n",
      "|    explained_variance   | 0.416     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.648    |\n",
      "|    n_updates            | 610       |\n",
      "|    policy_gradient_loss | -0.0669   |\n",
      "|    value_loss           | 0.0436    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026693502 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.651      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0645     |\n",
      "|    value_loss           | 0.0319      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 957         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025449626 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.625      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0635     |\n",
      "|    value_loss           | 0.0314      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 972        |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02477299 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | -0.113     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.632     |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.0404     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027480848 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.643      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.072      |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 136        |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 1002       |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02855917 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.638     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0755    |\n",
      "|    value_loss           | 0.0256     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028219197 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.644      |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0748     |\n",
      "|    value_loss           | 0.0344      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1033        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028186724 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.647      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.072      |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1048        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028124737 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.667      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0718     |\n",
      "|    value_loss           | 0.0305      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, ent_coef=0.3)\n",
    "model.learn(2e5)\n",
    "model.save(\"minigrid_models/minigrid_custom/15-skipping-steps\")\n",
    "\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-15', episode_trigger=lambda e: e % 1 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 30000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-15/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "env = RGBImgPartialObsWrapper(env) # reward is calculated using regular obs, then plugged into model with img obs\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "model = PPO.load(\"minigrid_models/minigrid_custom/15-skipping-steps\")\n",
    "\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-15', episode_trigger=lambda e: e % 1 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 30000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFLECTION AND FEEDBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3_reflection = '''\n",
    "I trained a PPO model on a minigrid environment with reward generated using GPT4 with the following prompt:\n",
    "''' + prompt2_part1 + prompt2_part2 + ''' The environment has colored doors the agent must pass through and unlock\n",
    "to reach the goal. For 6 subgoals, 3 reward functions were outputted by GPT4 and the maximum reward was\n",
    "taken for each subgoal. The code to do this is as follows:\n",
    "\n",
    "reward = 0\n",
    "for r in reward_funcs[goal_number]:\n",
    "    try:\n",
    "        reward = max(reward, r(obs, action, lockedroom_color, keyroom_color, door_color))\n",
    "    except:\n",
    "        pass\n",
    "if reward > 1-EPSILON:\n",
    "    goal_number += 1\n",
    "\n",
    "where reward_funcs is a list of reward functions:''' + str(subgoal_set) + '''\n",
    "\n",
    "The policy gave this final feedback:\n",
    "\n",
    "-----------------------------------------\n",
    "| rollout/                |             |\n",
    "|    ep_len_mean          | 190         |\n",
    "|    ep_rew_mean          | 44.5        |\n",
    "| time/                   |             |\n",
    "|    fps                  | 144         |\n",
    "|    iterations           | 123         |\n",
    "|    time_elapsed         | 1742        |\n",
    "|    total_timesteps      | 251904      |\n",
    "| train/                  |             |\n",
    "|    approx_kl            | 0.020666333 |\n",
    "|    clip_fraction        | 0.231       |\n",
    "|    clip_range           | 0.2         |\n",
    "|    entropy_loss         | -1.9        |\n",
    "|    explained_variance   | -0.439      |\n",
    "|    learning_rate        | 0.0003      |\n",
    "|    loss                 | -0.321      |\n",
    "|    n_updates            | 1220        |\n",
    "|    policy_gradient_loss | -0.0402     |\n",
    "|    value_loss           | 0.869       |\n",
    "-----------------------------------------\n",
    "and it only made it to subgoal 2.\n",
    "\n",
    "Your job is to edit these reward functions based on this feedback and output new rewards in the same format as the inputted list. \n",
    "These new reward functions should help solve the task better than previously. You can rewrite them entirely, or provide\n",
    "edits to them, taking into account the three 'drafts' for each subgoal. All the functions must keep their same signatures and in the same list format as the input.\n",
    "Do not use float('inf') or float('-inf').\n",
    "\n",
    "Make sure to output six (6) new reward functions, one for each of the following subgoals:\n",
    "\n",
    "- Locate the {keyroom_color} room.\n",
    "- Find and pick up the {lockedroom_color} key in the {keyroom_color} room.\n",
    "- Navigate to the {door_color} door.\n",
    "- Use the {lockedroom_color} key to unlock the {door_color} door.\n",
    "- Proceed through the unlocked {door_color} door.\n",
    "- Reach the goal area marked by the light green square.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_subgoals = complete(prompt3_reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16666666666666674\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "r = env.render()\n",
    "plt.imshow(r)\n",
    "obs, *_ = env.step(np.array([Actions.RIGHT]))\n",
    "\n",
    "r = env.render()\n",
    "plt.imshow(r)\n",
    "mission = obs['mission']\n",
    "lockedroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[2]]\n",
    "keyroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[6]]\n",
    "door_color = COLOR_TO_IDX[obs['mission'].split(' ')[10]]\n",
    "\n",
    "print(reward_0(obs, np.array([Actions.RIGHT]), lockedroom_color, keyroom_color, door_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "[\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_0A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            width, height, _ = image.shape\n",
      "            agent_x = width // 2\n",
      "            agent_y = height - 1\n",
      "            key_room_color = keyroom_color\n",
      "            min_distance = np.inf\n",
      "            for y in range(height):\n",
      "                for x in range(width):\n",
      "                    obj_idx, color_idx, _ = image[y, x]\n",
      "                    if obj_idx == 3 and color_idx == key_room_color:\n",
      "                        distance = np.sqrt((agent_x - x) ** 2 + (agent_y - y) ** 2)\n",
      "                        if distance < min_distance:\n",
      "                            min_distance = distance\n",
      "            if min_distance == 0:\n",
      "                reward = 1\n",
      "            else:\n",
      "                reward = 1 / (1 + min_distance)\n",
      "            return reward\"\"\"\n",
      "    ],\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_1A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            KEY_IDX = 5\n",
      "            width, height, _ = image.shape\n",
      "            agent_x, agent_y = width // 2, height - 1\n",
      "            key_found = False\n",
      "            min_distance_to_key = np.inf\n",
      "            for y in range(height):\n",
      "                for x in range(width):\n",
      "                    object_idx, color_idx, _ = image[y, x]\n",
      "                    if object_idx == KEY_IDX and color_idx == lockedroom_color:\n",
      "                        distance = np.sqrt((agent_x - x) ** 2 + (agent_y - y) ** 2)\n",
      "                        min_distance_to_key = min(min_distance_to_key, distance)\n",
      "                        if distance == 0 and action == 3:\n",
      "                            key_found = True\n",
      "            if not key_found:\n",
      "                reward = 1 - (min_distance_to_key / (width + height))\n",
      "            else:\n",
      "                reward = 1\n",
      "            return reward\"\"\"\n",
      "    ],\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_2A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            DOOR_IDX = 4\n",
      "            width, height, _ = image.shape\n",
      "            agent_x, agent_y = width // 2, height - 1\n",
      "            min_distance = np.inf\n",
      "            target_door_found = False\n",
      "            for y in range(height):\n",
      "                for x in range(width):\n",
      "                    if image[y, x, 0] == DOOR_IDX and image[y, x, 1] == door_color and image[y, x, 2] in [1, 2]:\n",
      "                        distance = np.sqrt((agent_x - x) ** 2 + (agent_y - y) ** 2)\n",
      "                        if distance < min_distance:\n",
      "                            min_distance = distance\n",
      "                            target_door_found = True\n",
      "            if target_door_found:\n",
      "                reward = 1 - (min_distance / np.sqrt(width**2 + height**2))\n",
      "            else:\n",
      "                reward = 0\n",
      "            return reward\"\"\"\n",
      "    ],\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_3A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            door_positions = np.argwhere((image[:, :, 0] == 4) & (image[:, :, 1] == door_color) & (image[:, :, 2] == 2))\n",
      "            agent_x, agent_y = image.shape[1] // 2, image.shape[0] - 1\n",
      "            if len(door_positions) == 0:\n",
      "                return 0\n",
      "            distances = np.sqrt((door_positions[:, 0] - agent_y) ** 2 + (door_positions[:, 1] - agent_x) ** 2)\n",
      "            min_distance = np.min(distances)\n",
      "            direction = observation['direction']\n",
      "            if action == 5:\n",
      "                facing_positions = [\n",
      "                    (agent_x, agent_y - 1),\n",
      "                    (agent_x - 1, agent_y),\n",
      "                    (agent_x, agent_y + 1),\n",
      "                    (agent_x + 1, agent_y)\n",
      "                ]\n",
      "                interaction_position = facing_positions[direction % 4]\n",
      "                if 0 <= interaction_position[1] < image.shape[0] and 0 <= interaction_position[0] < image.shape[1]:\n",
      "                    inter_obj, inter_color, inter_state = image[interaction_position[1], interaction_position[0]]\n",
      "                    if inter_obj == 4 and inter_color == door_color and inter_state == 2:\n",
      "                        return 1\n",
      "            return 1 - (min_distance / np.sqrt(image.shape[0] ** 2 + image.shape[1] ** 2))\"\"\"\n",
      "    ],\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_4A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            door_positions = np.argwhere((image[:, :, 0] == 4) & (image[:, :, 1] == door_color) & (image[:, :, 2] == 0))\n",
      "            agent_x, agent_y = image.shape[1] // 2, image.shape[0] - 1\n",
      "            if len(door_positions) == 0:\n",
      "                return 0\n",
      "            distances = np.sqrt((door_positions[:, 0] - agent_y) ** 2 + (door_positions[:, 1] - agent_x) ** 2)\n",
      "            min_distance = np.min(distances)\n",
      "            if action == 2:\n",
      "                movement_offsets = {0: (0, 1), 1: (0, -1), 2: (-1, 0), 3: (1, 0)}\n",
      "                if observation['direction'] in movement_offsets:\n",
      "                    next_step = (agent_y + movement_offsets[observation['direction']][0], agent_x + movement_offsets[observation['direction']][1])\n",
      "                    if 0 <= next_step[0] < image.shape[0] and 0 <= next_step[1] < image.shape[1]:\n",
      "                        next_step_distances = np.sqrt((door_positions[:, 0] - next_step[0]) ** 2 + (door_positions[:, 1] - next_step[1]) ** 2)\n",
      "                        if np.min(next_step_distances) < min_distance:\n",
      "                            reward = 1 - (np.min(next_step_distances) / np.sqrt(image.shape[0] ** 2 + image.shape[1] ** 2)) + 0.1\n",
      "                            return min(reward, 1)\n",
      "            return 1 - (min_distance / np.sqrt(image.shape[0] ** 2 + image.shape[1] ** 2))\"\"\"\n",
      "    ],\n",
      "    [\n",
      "        \"\"\"import numpy as np\n",
      "        def reward_5A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "            image = observation['image']\n",
      "            goal_positions = np.argwhere((image[:, :, 0] == 3) & (image[:, :, 1] == 1))\n",
      "            agent_x, agent_y = image.shape[1] // 2, image.shape[0] - 1\n",
      "            if len(goal_positions) == 0:\n",
      "                return 0\n",
      "            distances = np.sqrt((goal_positions[:, 0] - agent_y) ** 2 + (goal_positions[:, 1] - agent_x) ** 2)\n",
      "            min_distance = np.min(distances)\n",
      "            return 1 - (min_distance / np.sqrt((image.shape[0] - 1) ** 2 + (image.shape[1] // 2) ** 2))\"\"\"\n",
      "    ]\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(revised_subgoals.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '\\n'.join(revised_subgoals.choices[0].message.content.splitlines()[1:-1])\n",
    "\n",
    "exec(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_0A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward function to locate the {keyroom_color} room\n",
    "    image = observation['image']\n",
    "    height, width, _ = image.shape\n",
    "    agent_x = width // 2\n",
    "    agent_y = height - 1\n",
    "    reward = 0\n",
    "    key_room_floor_color = keyroom_color\n",
    "    min_distance = float('inf')\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            obj_idx, color_idx, _ = image[y, x]\n",
    "            if obj_idx == 3 and color_idx == key_room_floor_color:\n",
    "                distance = np.sqrt((agent_x - x) ** 2 + (agent_y - y) ** 2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "    # Improved normalization technique for distance reward\n",
    "    max_possible_distance = np.sqrt(width ** 2 + height ** 2)\n",
    "    if min_distance == 0:\n",
    "        reward = 1  # Max reward if already at the keyroom floor\n",
    "    else:\n",
    "        reward = 1 - (min_distance / max_possible_distance)\n",
    "    return reward\n",
    "\n",
    "def reward_1A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward for finding and picking up the {lockedroom_color} key in the {keyroom_color} room\n",
    "    image = observation['image']\n",
    "    width, height, _ = image.shape\n",
    "    agent_x, agent_y = width // 2, height - 1\n",
    "\n",
    "    reward = 0\n",
    "    key_found = False\n",
    "    min_distance_to_key = float('inf')\n",
    "    \n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            object_idx, color_idx, _ = image[x, y]\n",
    "            # Consider only keys within the {keyroom_color} room\n",
    "            if object_idx == 5 and color_idx == lockedroom_color:\n",
    "                if image[x, y, 0] == 3 and image[x, y, 1] == keyroom_color:\n",
    "                    distance = np.sqrt((agent_x - x) ** 2 + (agent_y - y) ** 2)\n",
    "                    if distance < min_distance_to_key:\n",
    "                        min_distance_to_key = distance\n",
    "\n",
    "                    if distance == 0 and action == 3:\n",
    "                        key_found = True\n",
    "    \n",
    "    max_distance = np.sqrt(width ** 2 + height ** 2)\n",
    "    if not key_found:\n",
    "        reward = 1 - (min_distance_to_key / max_distance)\n",
    "    else:\n",
    "        reward = 1\n",
    "    return reward\n",
    "\n",
    "def reward_2A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward to navigate to the {door_color} door\n",
    "    image = observation['image']\n",
    "    agent_position = (image.shape[1] // 2, image.shape[0] - 1)\n",
    "    target_door_found = False\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            if image[y, x, 0] == 4 and image[y, x, 1] == door_color and image[y, x, 2] in [1, 2]:\n",
    "                distance = np.sqrt((agent_position[0] - x) ** 2 + (agent_position[1] - y) ** 2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    target_door_found = True\n",
    "\n",
    "    if target_door_found:\n",
    "        max_possible_distance = np.sqrt(image.shape[0]**2 + image.shape[1]**2)\n",
    "        reward = 1 - (min_distance / max_possible_distance)\n",
    "    else:\n",
    "        reward = 0\n",
    "    return reward\n",
    "\n",
    "def reward_3A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward for using the {lockedroom_color} key to unlock the {door_color} door\n",
    "    image = observation['image']\n",
    "    direction = observation['direction']\n",
    "    reward = 0.0\n",
    "    agent_position = (image.shape[1] // 2, image.shape[0] - 1)\n",
    "    door_positions = []\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            object_idx, color_idx, state_idx = image[y, x]\n",
    "            if object_idx == 4 and color_idx == door_color and state_idx == 2:\n",
    "                door_positions.append((x, y))\n",
    "\n",
    "    min_distance_to_door = float('inf')\n",
    "    for door_pos in door_positions:\n",
    "        distance = np.sqrt((door_pos[0] - agent_position[0]) ** 2 + (door_pos[1] - agent_position[1]) ** 2)\n",
    "        if distance < min_distance_to_door:\n",
    "            min_distance_to_door = distance\n",
    "\n",
    "    normalized_distance = min_distance_to_door / np.sqrt(image.shape[0] ** 2 + image.shape[1] ** 2)\n",
    "    proximity_reward = 1.0 - normalized_distance\n",
    "\n",
    "    if action == 5:\n",
    "        potential_positions = [\n",
    "            (agent_position[0], agent_position[1] - 1),\n",
    "            (agent_position[0] - 1, agent_position[1]),\n",
    "            (agent_position[0], agent_position[1] + 1),\n",
    "            (agent_position[0] + 1, agent_position[1])\n",
    "        ]\n",
    "        interaction_position = potential_positions[direction % 4]\n",
    "        if 0 <= interaction_position[1] < image.shape[0] and 0 <= interaction_position[0] < image.shape[1]:\n",
    "            inter_obj, inter_color, inter_state = image[interaction_position[1], interaction_position[0]]\n",
    "            if inter_obj == 4 and inter_color == door_color and inter_state == 2:\n",
    "                reward = 1\n",
    "    return max(reward, proximity_reward)\n",
    "\n",
    "def reward_4A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward for proceeding through the {door_color} door after it has been unlocked\n",
    "    image = observation['image']\n",
    "    agent_position = (image.shape[0] - 1, image.shape[1] // 2)\n",
    "    door_positions = np.argwhere((image[:, :, 0] == 4) & (image[:, :, 1] == door_color) & (image[:, :, 2] == 0))\n",
    "    \n",
    "    if len(door_positions) == 0:\n",
    "        return 0\n",
    "\n",
    "    distances = np.sqrt((door_positions[:, 0] - agent_position[0]) ** 2 + (door_positions[:, 1] - agent_position[1]) ** 2)\n",
    "    min_distance = np.min(distances)\n",
    "    max_possible_distance = np.sqrt((image.shape[0] - 1) ** 2 + (image.shape[1] // 2) ** 2)\n",
    "    reward = 1 - (min_distance / max_possible_distance)\n",
    "\n",
    "    if action == 2:\n",
    "        direction = observation['direction']\n",
    "        movement_offsets = {0: (0, 1), 1: (0, -1), 2: (-1, 0), 3: (1, 0)}\n",
    "        if direction in movement_offsets:\n",
    "            next_step = (agent_position[0] + movement_offsets[direction][0], agent_position[1] + movement_offsets[direction][1])\n",
    "            if 0 <= next_step[0] < image.shape[0] and 0 <= next_step[1] < image.shape[1]:\n",
    "                next_step_distances = np.sqrt((door_positions[:, 0] - next_step[0]) ** 2 + (door_positions[:, 1] - next_step[1]) ** 2)\n",
    "                if np.min(next_step_distances) < min_distance:\n",
    "                    reward += 0.1\n",
    "    return min(reward, 1)\n",
    "\n",
    "def reward_5A(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    # Improved reward for reaching the goal area marked by the light green square\n",
    "    image = observation['image']\n",
    "    goal_positions = np.argwhere((image[:, :, 0] == 3) & (image[:, :, 1] == 1))\n",
    "    agent_position = (image.shape[0] - 1, image.shape[1] // 2)\n",
    "    \n",
    "    if goal_positions.size == 0:\n",
    "        return 0\n",
    "\n",
    "    distances = np.sqrt((goal_positions[:, 0] - agent_position[0]) ** 2 + (goal_positions[:, 1] - agent_position[1]) ** 2)\n",
    "    min_distance = np.min(distances)\n",
    "    max_possible_distance = np.sqrt(agent_position[0]**2 + (image.shape[1]//2)**2)\n",
    "    reward = 1 - (min_distance / max_possible_distance)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPSILON = 0.1\n",
    "def generate_total_reward_reflection():\n",
    "    goal_number = 0\n",
    "      \n",
    "    reward_funcs = [reward_0, reward_1, reward_2, reward_3, reward_4, reward_5]\n",
    "    def total_reward(obs, action):\n",
    "        nonlocal goal_number\n",
    "        \n",
    "        gamma = 0.005 # probability to skip to next subgoal\n",
    "        \n",
    "        # print(obs)\n",
    "        \n",
    "        COLOR_TO_IDX = {\"red\": 0, \"green\": 1, \"blue\": 2, \"purple\": 3, \"yellow\": 4, \"grey\": 5}\n",
    "        \n",
    "        # preprocess -- ideally this would be done with LLM if we had more compute\n",
    "        lockedroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[2]]\n",
    "        keyroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[6]]\n",
    "        door_color = COLOR_TO_IDX[obs['mission'].split(' ')[10]]\n",
    "        \n",
    "        reward = 0\n",
    "       \n",
    "        # if bug, try previous reward\n",
    "        try:\n",
    "            reward = reward_funcs[goal_number](obs, action, lockedroom_color, keyroom_color, door_color)\n",
    "        except:\n",
    "            reward = 0\n",
    "\n",
    "        if (reward > 1-EPSILON or np.random.rand() < gamma) and goal_number < len(reward_funcs) - 1:\n",
    "            \n",
    "            print(\"switching functions from \" + str(goal_number) + \" to \" + str(goal_number + 1))\n",
    "            goal_number += 1\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        return reward, goal_number\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "# env = ViewSizeWrapper(env, agent_view_size=7) # so the cnn can work with kernel size 8\n",
    "env = CustomRewardWrapper(env, generate_total_reward_reflection)\n",
    "env = RGBImgPartialObsWrapper(env) # reward is calculated using regular obs, then plugged into model with img obs\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 97.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 689      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 79.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037701866 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0237       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 72.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009037 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.175      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.702       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 5.37        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 63.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057556713 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 6.71         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009571193 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00201     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 52.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 190         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010656539 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.362      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.475      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010298884 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.358      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008385156 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.079       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.131      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 47.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006834037 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 42.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 179         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007327707 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 39.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007773628 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 5.6         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 37.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 176          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063322904 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 5.11         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 36.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509172 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 7.36        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 172        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007797 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.79       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    value_loss           | 6.95       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 39          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011188401 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 7           |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 39.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 170        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204756 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.3        |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    value_loss           | 5.62       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 42.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012939126 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.476       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 5.24        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012027525 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 6.98        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 168         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011535093 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 7.14        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013047374 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 5.58        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 44.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018285 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 4 to 5\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 43.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016437732 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0823     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016360875 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 42.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016523354 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017246306 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00594     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 40.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015166264 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 36.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014451744 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.388      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 34.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016178131 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 33.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01420408 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.9       |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0993    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 1.43       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 31.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016927443 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.454      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.903       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 32.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016441055 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0438      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 2.33        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 30.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013943603 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.311       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 29.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015382096 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0598      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 28.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016973274 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.429      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.971       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 27.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 161        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 442        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01797938 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0316     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 1.33       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 28.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016988732 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.979       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 28          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019234177 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.449       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 190       |\n",
      "|    ep_rew_mean          | 28.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 161       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 482       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0163153 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.88     |\n",
      "|    explained_variance   | 0.763     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.302    |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -0.0317   |\n",
      "|    value_loss           | 1.1       |\n",
      "---------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 28.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012709625 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 27.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018667525 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.357      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.95        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 25.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016483046 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 24.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019721407 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.472      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.543       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 24.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018715704 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.546      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 24.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013657067 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.472      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 23.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011046643 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.377      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 22.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014052169 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.336      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 21.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014166361 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.411      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.558       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 20.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012514545 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.25       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 20.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017656732 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.487      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.436       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 19.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 646        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01905229 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.818      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.486     |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.412      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 19.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 660         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017544236 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.379      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 0.609       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 17.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017319169 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.483      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 16.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016275179 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.486      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.84        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 16.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 700         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013898388 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.548      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014417643 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.337      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022007635 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.518      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 740         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018697016 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.479      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 754        |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02120249 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.496     |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 0.493      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017455332 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.444      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021226859 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0521     |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017251614 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.43       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019976787 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.492      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 822         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019919852 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021452898 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.523      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0511     |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015004935 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.162      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018136539 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.531      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.46        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 876         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015553758 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.414      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.757       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 892         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021819543 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.585      |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 12.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 905        |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696322 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.55       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.475     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 1.58       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 919         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016893692 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.342      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.749       |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 13.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 934        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841488 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.494     |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 1.04       |\n",
      "----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017095817 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.926       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 962         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025549438 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 975         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022062397 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019683018 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.506      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 11.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1002       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01708657 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.437     |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 0.796      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020684777 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1032        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015410769 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1046        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017906055 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.484      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.521       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014917092 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016404934 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.116      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 190       |\n",
      "|    ep_rew_mean          | 11.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 154       |\n",
      "|    iterations           | 82        |\n",
      "|    time_elapsed         | 1089      |\n",
      "|    total_timesteps      | 167936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0188273 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.88     |\n",
      "|    explained_variance   | 0.713     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.516    |\n",
      "|    n_updates            | 810       |\n",
      "|    policy_gradient_loss | -0.0402   |\n",
      "|    value_loss           | 0.488     |\n",
      "---------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 11.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 1102       |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02169669 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.58      |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.41       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 190       |\n",
      "|    ep_rew_mean          | 10.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 84        |\n",
      "|    time_elapsed         | 1117      |\n",
      "|    total_timesteps      | 172032    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0168434 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.88     |\n",
      "|    explained_variance   | 0.606     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.523    |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | -0.0385   |\n",
      "|    value_loss           | 0.366     |\n",
      "---------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1131        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022689283 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 4 to 5\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1144        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020581136 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.53       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013516026 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.359      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1171        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020482905 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.459      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1185        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019959897 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.599      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018857837 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.6        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 9.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 1213       |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02008459 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.581     |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743319 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.246      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1243        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018738687 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1257        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016393906 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.508      |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 4 to 5\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1270        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016946042 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.417      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 0.572       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019212186 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 0.836       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 8.48       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 1296       |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02018975 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.777      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.599     |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.0489    |\n",
      "|    value_loss           | 0.249      |\n",
      "----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1309        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467579 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.578      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 0.662       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1322        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014122535 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.532      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.65       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1335       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01440802 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.665      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.486     |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.674      |\n",
      "----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1348        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019505171 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.549      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1361        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020025503 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.597      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 1375       |\n",
      "|    total_timesteps      | 210944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02082006 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.589     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 5.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 1388       |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02195598 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.633     |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1404        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023387205 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.394      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1418        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019859282 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.409      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 5.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1431        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021418955 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 6.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 1447       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01764885 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.547      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.637      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1460        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016784193 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.349      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 1472        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018157724 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.217      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 0.558       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1485        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020786924 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0539     |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 1498        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015740521 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.506      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.884       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 1511        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014744699 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.47       |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 0.703       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 1524       |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01827748 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.9       |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.56      |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    value_loss           | 0.454      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 1536       |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01727482 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.573     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.355      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 1549        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018082052 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.584      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 1562        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017397966 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.519      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 1575        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018356461 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.498      |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 0.479       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017600313 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.5        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 0.697       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 1601        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020487174 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 1614        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020619176 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.402      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    value_loss           | 0.382       |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 1627        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021354306 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.588      |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 6.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 1639        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021426827 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "switching functions from 0 to 1\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 4 to 5\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, ent_coef=0.3)\n",
    "model.learn(2.5e5)\n",
    "model.save(\"minigrid_models/minigrid_custom/14-reward-with-feedback\")\n",
    "\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-14', episode_trigger=lambda e: e % 1 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 30000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-0.mp4\n",
      "switching functions from 0 to 1\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-1.mp4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-2.mp4\n",
      "switching functions from 0 to 1\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-4.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-4.mp4\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-14/rl-video-episode-3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load(\"minigrid_models/minigrid_custom/14-reward-with-feedback\")\n",
    "\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-14', episode_trigger=lambda e: e % 1 == 0)\n",
    "for episode_num in range(4):\n",
    "    obs, info = env.reset()\n",
    "\n",
    "    episode_over = False\n",
    "    while not episode_over:\n",
    "        action = action = model.predict(obs)[0]\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        episode_over = terminated or truncated\n",
    "env.close_video_recorder()\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
