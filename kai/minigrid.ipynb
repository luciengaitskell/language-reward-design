{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gym/envs/registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from gymnasium import spaces\n",
    "%matplotlib inline\n",
    "# import gymnasium as gym\n",
    "# from gym.envs.registration import registry, register\n",
    "from minigrid.wrappers import DictObservationSpaceWrapper # so that text mission string is actually a numerical dict\n",
    "\n",
    "# env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode = \"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env) # ONLY DO THIS FOR PPO TRAINING\n",
    "# env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "# import gym\n",
    "import torch\n",
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_zeros(l):\n",
    "    out = []\n",
    "    for elt in l:\n",
    "        if elt != 0:\n",
    "            out.append(elt)\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the green key from the blue room, unlock the green door and go to the goal\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n",
      "[20, 31, 5, 12, 49, 31, 4, 50, 34, 28, 31, 5, 14, 36, 25, 38, 31, 15]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "ob1, info = env.reset()\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "ob2, info = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "print(ob1['mission'])\n",
    "print(no_zeros(ob2['mission']))\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    ob3, reward, term, truc, info = env.step(action)\n",
    "    print(no_zeros(ob3['mission']))\n",
    "    print(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mob2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmission\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "ob2['mission'].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.functional.one_hot(ob2.long(), num_classes=int(env.observation_space['mission'].nvec[idx])).float()\n",
    "num_classes = env.observation_space['mission'].nvec[32]\n",
    "classes = torch.split(torch.Tensor(ob2['mission']).long().unsqueeze(0), 1, dim=1)[32].long()\n",
    "\n",
    "print(torch.nn.functional.one_hot(classes, num_classes=num_classes).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.) MultiDiscrete([50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
      " 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
      " 50 50])\n",
      "get the green key from the blue room, unlock the green door and go to the goal\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be smaller than num_classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(ob[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m7\u001b[39m], ob_space)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(ob1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmission\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m \u001b[43mpreprocess_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob_space\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/preprocessing.py:131\u001b[0m, in \u001b[0;36mpreprocess_obs\u001b[0;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mone_hot(obs\u001b[38;5;241m.\u001b[39mlong(), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(observation_space\u001b[38;5;241m.\u001b[39mn))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, spaces\u001b[38;5;241m.\u001b[39mMultiDiscrete):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Tensor concatenation of one hot encodings of each Categorical sub-space\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    130\u001b[0m         [\n\u001b[0;32m--> 131\u001b[0m             \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnvec\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m idx, obs_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(th\u001b[38;5;241m.\u001b[39msplit(obs\u001b[38;5;241m.\u001b[39mlong(), \u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    133\u001b[0m         ],\n\u001b[1;32m    134\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    135\u001b[0m     )\u001b[38;5;241m.\u001b[39mview(obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28msum\u001b[39m(observation_space\u001b[38;5;241m.\u001b[39mnvec))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, spaces\u001b[38;5;241m.\u001b[39mMultiBinary):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be smaller than num_classes."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.preprocessing import preprocess_obs\n",
    "\n",
    "ob = torch.Tensor([ob2['mission']])\n",
    "ob_space = env.observation_space['mission']\n",
    "print(ob[0, 7], ob_space)\n",
    "print(ob1['mission'])\n",
    "\n",
    "preprocess_obs(ob, ob_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "# a custom wrapper to make the mission vector work with one hot encoding\n",
    "class MissionEncodingWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['mission'] = spaces.MultiDiscrete(np.array([n+1 for n in env.observation_space['mission'].nvec]))\n",
    "    def observation(self, obs):\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        direction = observation_space['direction']\n",
    "        image = observation_space['image']\n",
    "        mission_string = observation_space['mission']\n",
    "        n_input_channels = image.shape[0] # should be 3, for RGB\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        direction_output_dim = 8\n",
    "        self.direction_net = nn.Sequential(nn.Linear(direction.n, direction_output_dim), nn.ReLU()) \n",
    "        \n",
    "        \n",
    "        ## add text extractor\n",
    "        self.transformer = nn.Transformer(d_model=len(mission_string), nhead=2, num_encoder_layers=2, num_decoder_layers=2) # squared because of one hot encoding\n",
    "        \n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space['image'].sample()[None]).float()).shape[1] ## 1024 for this example\n",
    "            \n",
    "        self.sentence_transformer_dim = len(mission_string) # is one-hot best here? or should we condense it to 50D vector?\n",
    "            \n",
    "        linear_input_dim = n_flatten + self.sentence_transformer_dim + direction_output_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(linear_input_dim, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        image_features = self.cnn(observations['image']) # .transpose((2, 0, 1)\n",
    "        direction_features = self.direction_net(observations['direction'])\n",
    "        if direction_features.shape[1] == 1:\n",
    "            direction_features = direction_features.squeeze(1)\n",
    "            \n",
    "       \n",
    "        one_hot_mission = observations['mission'].squeeze(0)\n",
    "       \n",
    "        mission_string_encoding = torch.empty((observations['mission'].shape[0], self.sentence_transformer_dim))\n",
    "        \n",
    "        # turn back into labels instead of one hot encoding\n",
    "        for i in range(0, self.sentence_transformer_dim**2, self.sentence_transformer_dim):\n",
    "\n",
    "            if len(one_hot_mission.size()) == 1:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = (torch.argmax(one_hot_mission[i:i+self.sentence_transformer_dim], dim = 0))\n",
    "            else:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = torch.argmax(one_hot_mission[:, i:i+self.sentence_transformer_dim], dim = 1)\n",
    "       \n",
    "        src = trg = torch.as_tensor(mission_string_encoding).unsqueeze(0).float()\n",
    "        \n",
    "        sentence_features = self.transformer(src, trg).squeeze(0) # to match dimensions\n",
    "\n",
    "        \n",
    "        try:\n",
    "            observations = torch.cat([image_features, sentence_features, direction_features], dim = 1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"image features dim\", image_features.shape)\n",
    "            print(\"sentence features dim\", sentence_features.shape)\n",
    "            print(\"direction features dim\", direction_features.shape)\n",
    "        return self.linear(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:178: UserWarning: \u001b[33mWARN: Unable to save last video! Did you call close()?\u001b[0m\n",
      "  logger.warn(\"Unable to save last video! Did you call close()?\")\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MultiDiscrete([51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51]))\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mobservation_space)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2e5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m## the problem: ppo requires a gym env to train. but the env observation space is of type gymnasium.spaces. \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:217\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mreset_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 217\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:730\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03mEvaluate actions according to the current policy,\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03mgiven the observations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    and entropy of the action distribution.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m    732\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:672\u001b[0m, in \u001b[0;36mActorCriticPolicy.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    features for the actor and the features for the critic.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[0;32m--> 672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mMinigridFeaturesExtractor.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     54\u001b[0m         mission_string_encoding[:, i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentence_transformer_dim] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(one_hot_mission[:, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentence_transformer_dim], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     56\u001b[0m src \u001b[38;5;241m=\u001b[39m trg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mission_string_encoding)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 58\u001b[0m sentence_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# to match dimensions\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     observations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([image_features, sentence_features, direction_features], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:219\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    218\u001b[0m                       is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal)\n\u001b[0;32m--> 219\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:494\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    491\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 494\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:890\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    888\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    891\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m    892\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:899\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    898\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 899\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5507\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5504\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5505\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[0;32m-> 5507\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5508\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   5509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   5510\u001b[0m     \u001b[38;5;66;03m# squeeze the output if input was unbatched\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env) # so that the multidiscrete mission space is 51, accounting for values 0 through 50\n",
    "env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(2e5)\n",
    "## the problem: ppo requires a gym env to train. but the env observation space is of type gymnasium.spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"minigrid_models/minigrid-ppo/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MultiDiscrete([51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51]))\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (3, 7, 7), uint8), 'mission': MultiDiscrete([51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n",
      " 51 51]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "model = #PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "print(model.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/video/rl-video-episode-0.mp4\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "5050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "5300\n",
      "5350\n",
      "5400\n",
      "5450\n",
      "5500\n",
      "5550\n",
      "5600\n",
      "5650\n",
      "5700\n",
      "5750\n",
      "5800\n",
      "5850\n",
      "5900\n",
      "5950\n",
      "6000\n",
      "6050\n",
      "6100\n",
      "6150\n",
      "6200\n",
      "6250\n",
      "6300\n",
      "6350\n",
      "6400\n",
      "6450\n",
      "6500\n",
      "6550\n",
      "6600\n",
      "6650\n",
      "6700\n",
      "6750\n",
      "6800\n",
      "6850\n",
      "6900\n",
      "6950\n",
      "7000\n",
      "7050\n",
      "7100\n",
      "7150\n",
      "7200\n",
      "7250\n",
      "7300\n",
      "7350\n",
      "7400\n",
      "7450\n",
      "7500\n",
      "7550\n",
      "7600\n",
      "7650\n",
      "7700\n",
      "7750\n",
      "7800\n",
      "7850\n",
      "7900\n",
      "7950\n",
      "8000\n",
      "8050\n",
      "8100\n",
      "8150\n",
      "8200\n",
      "8250\n",
      "8300\n",
      "8350\n",
      "8400\n",
      "8450\n",
      "8500\n",
      "8550\n",
      "8600\n",
      "8650\n",
      "8700\n",
      "8750\n",
      "8800\n",
      "8850\n",
      "8900\n",
      "8950\n",
      "9000\n",
      "9050\n",
      "9100\n",
      "9150\n",
      "9200\n",
      "9250\n",
      "9300\n",
      "9350\n",
      "9400\n",
      "9450\n",
      "9500\n",
      "9550\n",
      "9600\n",
      "9650\n",
      "9700\n",
      "9750\n",
      "9800\n",
      "9850\n",
      "9900\n",
      "9950\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import record_videos, show_videos\n",
    "\n",
    "model = PPO.load(\"minigrid_models/minigrid-ppo/2\")\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'video', episode_trigger=lambda e: e % 2 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 10000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    if steps % 50 == 0: print(steps)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()\n",
    "show_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render = env.render()\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "ax.imshow(render) # , cmap=plt.get_cmap('gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [4, 4, 1],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [2, 5, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " 'direction': 2,\n",
       " 'mission': 'get the grey key from the blue room, unlock the grey door and go to the goal'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
