{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from gymnasium import spaces\n",
    "%matplotlib inline\n",
    "# import gymnasium as gym\n",
    "# from gym.envs.registration import registry, register\n",
    "from minigrid.wrappers import DictObservationSpaceWrapper # so that text mission string is actually a numerical dict\n",
    "\n",
    "# env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode = \"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env) # ONLY DO THIS FOR PPO TRAINING\n",
    "# env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "# import gym\n",
    "import torch\n",
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper, RGBImgObsWrapper, RGBImgPartialObsWrapper, DictObservationSpaceWrapper, ViewSizeWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x149d539c0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (56, 56, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x149d539c0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\")\n",
    "print(env.observation_space)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the wrappers for the environment\n",
    "\n",
    "`MissionEncodingWrapper` adds one for every discrete space in the one-hot encoding of the mission, allowing 0 to be encoded as well.\n",
    "\n",
    "`ImageFeaturesExtractor` extracts relevant features if the observation is just an image, used with `ImgObsWrapper`\n",
    "\n",
    "`MinigridFeaturesExtractor` extracts relevant features from the entire observation, used with `MissionEncodingWrapper` and `DictObservationSpaceWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "# a custom wrapper to make the mission vector work with one hot encoding\n",
    "class MissionEncodingWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['mission'] = spaces.MultiDiscrete(np.array([n+1 for n in env.observation_space['mission'].nvec]))\n",
    "    def observation(self, obs):\n",
    "        return obs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gymnasium.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        direction = observation_space['direction']\n",
    "        image = observation_space['image']\n",
    "        mission_string = observation_space['mission']\n",
    "        n_input_channels = image.shape[0] # should be 3, for RGB\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        direction_output_dim = 8\n",
    "        self.direction_net = nn.Sequential(nn.Linear(direction.n, direction_output_dim), nn.ReLU()) \n",
    "        \n",
    "        \n",
    "        ## add text extractor\n",
    "        self.transformer = nn.Transformer(d_model=len(mission_string), nhead=2, num_encoder_layers=2, num_decoder_layers=2) # squared because of one hot encoding\n",
    "        \n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space['image'].sample()[None]).float()).shape[1] ## 1024 for this example\n",
    "            \n",
    "        self.sentence_transformer_dim = len(mission_string) # is one-hot best here? or should we condense it to 50D vector?\n",
    "            \n",
    "        linear_input_dim = n_flatten + self.sentence_transformer_dim + direction_output_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(linear_input_dim, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        image_features = self.cnn(observations['image']) # .transpose((2, 0, 1)\n",
    "        direction_features = self.direction_net(observations['direction'])\n",
    "        if direction_features.shape[1] == 1:\n",
    "            direction_features = direction_features.squeeze(1)\n",
    "            \n",
    "       \n",
    "        one_hot_mission = observations['mission'].squeeze(0)\n",
    "       \n",
    "        mission_string_encoding = torch.empty((observations['mission'].shape[0], self.sentence_transformer_dim))\n",
    "        \n",
    "        # turn back into labels instead of one hot encoding\n",
    "        for i in range(0, self.sentence_transformer_dim**2, self.sentence_transformer_dim):\n",
    "\n",
    "            if len(one_hot_mission.size()) == 1:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = (torch.argmax(one_hot_mission[i:i+self.sentence_transformer_dim], dim = 0))\n",
    "            else:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = torch.argmax(one_hot_mission[:, i:i+self.sentence_transformer_dim], dim = 1)\n",
    "       \n",
    "        src = trg = torch.as_tensor(mission_string_encoding).unsqueeze(0).float()\n",
    "        \n",
    "        sentence_features = self.transformer(src, trg).squeeze(0) # to match dimensions\n",
    "\n",
    "        \n",
    "        try:\n",
    "            observations = torch.cat([image_features, sentence_features, direction_features], dim = 1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"image features dim\", image_features.shape)\n",
    "            print(\"sentence features dim\", sentence_features.shape)\n",
    "            print(\"direction features dim\", direction_features.shape)\n",
    "        return self.linear(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save it. -- also try `FlatObsWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (152, 152, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x11a0e6d40>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "(608, 608, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16b67ee10>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env)\n",
    "# env = MissionEncodingWrapper(env)\n",
    "env = RGBImgObsWrapper(env)\n",
    "\n",
    "print(env.observation_space)\n",
    "env.reset()\n",
    "r = env.render()\n",
    "print(r.shape)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions:\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    FORWARD = 2\n",
    "    PICKUP = 3\n",
    "    DROP = 4\n",
    "    TOGGLE = 5\n",
    "    DONE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIRECTION:\n",
    "Up: 3\n",
    "Left: 2\n",
    "Down: 1\n",
    "Right: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Video of the trained policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to render image\n",
    "\n",
    "-- good for passing into GPT4 VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "render = env.render()\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "ax.imshow(render) # , cmap=plt.get_cmap('gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from api.settings import Settings\n",
    "\n",
    "openai_client = OpenAI(api_key=Settings().openai_key)\n",
    "\n",
    "def vision(prompt_text: str, img_base64: str):\n",
    "    \"\"\"Run a GPT-4 vision model on the prompt text and image.\n",
    "\n",
    "    ```\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(r)\n",
    "    vision(\"what do you see?\", image_to_base64(im))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{img_base64}\",\n",
    "                        \"detail\": \"low\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# def complete(prompt_text: str):\n",
    "#     \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "#     gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": prompt_text},\n",
    "#             ],\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     response = openai_client.chat.completions.create(\n",
    "#         model=gpt_model,\n",
    "#         messages=messages,\n",
    "#         temperature=0.2,\n",
    "#         max_tokens=300,\n",
    "#     )\n",
    "#     return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.65,\n",
    "        max_tokens=800,\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_parking_env.py\n",
    "from typing import Callable, List\n",
    "\n",
    "from gymnasium.envs.registration import register\n",
    "from minigrid.envs.lockedroom import LockedRoomEnv\n",
    "\n",
    "from gymnasium import spaces\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class CustomMinigridEnv(LockedRoomEnv):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        compute_reward: Callable[[\"CustomMinigridEnv\", spaces.Dict], float],\n",
    "        **kwargs\n",
    "    ):  \n",
    "        self.compute_reward_func = compute_reward\n",
    "        self.counts = {}\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    # this function is useless\n",
    "    \n",
    "    # def _reward(self) -> float:\n",
    "    #     return self.compute_reward_func(current_state)\n",
    "    \n",
    "    def get_reward(self, obs):\n",
    "        return self.compute_reward_func(obs)\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = super().step(action)\n",
    "        reward = self.compute_reward_func(obs)\n",
    "        \n",
    "        \n",
    "        pos = tuple(self.agent_pos)\n",
    "\n",
    "        # Get the count for this key\n",
    "        pre_count = 0\n",
    "        if pos in self.counts:\n",
    "            pre_count = self.counts[pos]\n",
    "\n",
    "        # Update the count for this key\n",
    "        new_count = pre_count + 1\n",
    "        self.counts[pos] = new_count\n",
    "\n",
    "        bonus = 1 / math.sqrt(new_count)\n",
    "        reward += bonus\n",
    "        \n",
    "        # print(\"reward: \", reward)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "register( id=\"CustomLockedRoom-v0\", entry_point=CustomMinigridEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the red key from the yellow room, unlock the red door and go to the goal'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the yellow key from the blue room, unlock the yellow door and go to the goal'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "plt.imshow(render)\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = '''You are an assistant aiding with subgoal generataion for reinforcement learning problems. Specifically, you will\n",
    "be given an example environment picture and a textual goal description, and you are to output language subgoals that the agent\n",
    "should achieve in order to efficiently and successfully achieve the main goal.\n",
    "\n",
    "The goal description is:\n",
    "\n",
    "get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal\n",
    "\n",
    "where you can use {lockedroom_color}, {keyroom_color}, and {door_color} as variables in the subgoals and the goal is a light green square.\n",
    "The variables can be the values red, green, blue, purple, yellow or grey.\n",
    "\n",
    "These subgoals should be with respect to the image itself:\n",
    "they should specify specific observations that show that the agent is on track. Output a list of ONLY these text subgoals in the following format (without any introduction text):\n",
    "\n",
    "- [subgoal 1]\n",
    "- [subgoal 2]\n",
    "- ...\n",
    "\n",
    "where [subgoal i] is replaced by the ith subgoal. You should enough subgoals to be descriptive but not redundant. subgoals Do not create directional subgoals but rather strategic\n",
    "subgoals that do not hard code the direction but instead tell the agent which states are more beneficial. The subgoals should be able to be completed\n",
    "by the agent moving, picking up a key, or using a key.\n",
    "\n",
    "Remember that the included image is an example of the environment but the door, key, and goal locations may differ so use it for context but do not\n",
    "hardcode the goals with respect to this specific image.\n",
    "'''\n",
    "\n",
    "prompt2_part1 = '''\n",
    "You are an assistant tasked with turning language subgoals into machine readable code. You will be given text subgoals, and you must translate\n",
    "these subgoals into code that takes in an observation of the format\n",
    "\n",
    "{'direction': Discrete(4), 'image': np.ndarray, 'mission': str}\n",
    "\n",
    "'direction' is a number with the corresponding direction:\n",
    "    3: Up\n",
    "    2: Left\n",
    "    1: Down\n",
    "    0: Right\n",
    "\n",
    "'image' is of shape (width x height x 3), and the final dimension corresponds to a 3D tuple of (OBJECT_IDX, COLOR_IDX, STATE). Here, \n",
    "\n",
    "OBJECT_IDX is a number with the corresponding object type: \n",
    "    0: \"unseen\"\n",
    "    1: \"empty\"\n",
    "    2: \"wall\"\n",
    "    3: \"floor\"\n",
    "    4: \"door\"\n",
    "    5: \"key\"\n",
    "    \n",
    "COLOR_IDX is a number with the corresponding color:\n",
    "    0: \"red\"\n",
    "    1: \"green\"\n",
    "    2: \"blue\"\n",
    "    3: \"purple\"\n",
    "    4: \"yellow\"\n",
    "    5: \"grey\"\n",
    "\n",
    "STATE is a number with the corresponding state if the object is a door: \n",
    "    0: \"open\"\n",
    "    1: \"closed\"\n",
    "    2: \"locked\"\n",
    "\n",
    "The agent is centered at the bottom of the image.\n",
    "\n",
    "'mission' is of the form get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal\n",
    "\n",
    "The text subgoals will include these variables {lockedroom_color}, {keyroom_color}, and {door_color}, which are integers corresponding to the above encoding for COLOR_IDX.\n",
    "\n",
    "As part of your reward function, you can use these three variables {lockedroom_color}, {keyroom_color}, and {door_color}\n",
    "to determine your specific reward function for the subgoal. You can also use the action which comes as an integer 0 through 6, labeled as follows:\n",
    "\n",
    "0: turn left, 1: turn right, 2: move forward, 3: pick up an object, 4: DON'T USE, 5: toggle/activate an object, 6: DON'T USE\n",
    "\n",
    "The reward function must have the signature: reward_{i}(observation, action, lockedroom_color, keyroom_color, door_color) where i is '''\n",
    "\n",
    "prompt2_part2 = '''\n",
    ". \n",
    "Output the subgoal as a python function that takes in the above parameters and returns the reward that prioritizes the specific subgoal. The only external library you can use is numpy.\n",
    "This reward function should be dense; it should make the agent want to move closer to the specific subgoal. Have the maximum reward of the function be 1 (where the goal is obtained) and the minimum be 0.\n",
    "The code should be the only thing you output, all in one python function without sub functions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from api.image import image_to_base64\n",
    "\n",
    "im = Image.fromarray(render)\n",
    "completion1 = vision(prompt1, image_to_base64(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Locate the {keyroom_color} room.\n",
      "- Enter the {keyroom_color} room.\n",
      "- Find the {lockedroom_color} key within the {keyroom_color} room.\n",
      "- Pick up the {lockedroom_color} key.\n",
      "- Locate the {door_color} door.\n",
      "- Use the {lockedroom_color} key to unlock the {door_color} door.\n",
      "- Pass through the unlocked {door_color} door.\n",
      "- Reach the goal area marked by the light green square.\n"
     ]
    }
   ],
   "source": [
    "print(completion1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations:: vision -- need better model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(render)\n",
    "completions = []\n",
    "for i, sg in enumerate(completion1.choices[0].message.content.splitlines()):\n",
    "    completions.append(complete(prompt2_part1 + str(i) + prompt2_part2 + '\\nThe textual subgoal is as follows: ' + sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_funcs = [c.choices[0].message.content for c in completions]\n",
    "completion_funcs_execute = ['\\n'.join(c.splitlines()[1:-1]) for c in completion_funcs]\n",
    "for c in completion_funcs_execute:\n",
    "    # print(c)\n",
    "    exec(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mission_to_string(mission_encoding):\n",
    "    indices = [idx - 1 for idx in mission_encoding] # remove offset\n",
    "    translation = {v: k for k, v in DictObservationSpaceWrapper.get_minigrid_words().items()}\n",
    "    translation[-1] = ''\n",
    "    return ' '.join([translation[idx] for idx in indices])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def reward_0(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    import numpy as np\n",
      "    \n",
      "    # Extract the image and direction from the observation\n",
      "    image = observation['image']\n",
      "    direction = observation['direction']\n",
      "    \n",
      "    # Define rewards for different cases\n",
      "    room_reward = 0\n",
      "    \n",
      "    # Check if the agent has found the {keyroom_color} room\n",
      "    # Loop through each pixel in the image to find a floor with the color matching keyroom_color\n",
      "    for i in range(image.shape[0]):\n",
      "        for j in range(image.shape[1]):\n",
      "            object_idx, color_idx, state = image[i, j]\n",
      "            if object_idx == 3 and color_idx == keyroom_color:  # 3 corresponds to 'floor'\n",
      "                # Calculate a simple distance to the center of the image where the agent is\n",
      "                center_x, center_y = image.shape[1] // 2, image.shape[0] - 1\n",
      "                distance = np.sqrt((center_x - j)**2 + (center_y - i)**2)\n",
      "                # Use an inverse distance metric for reward, normalized by the maximum possible distance\n",
      "                max_distance = np.sqrt(center_x**2 + center_y**2)\n",
      "                distance_reward = 1 - (distance / max_distance)\n",
      "                room_reward = max(room_reward, distance_reward)\n",
      "    \n",
      "    # Maximum reward when the agent is exactly on the keyroom_color floor\n",
      "    if room_reward == 1:\n",
      "        return 1\n",
      "\n",
      "    # Return the maximum reward found for being in proximity to the keyroom_color room\n",
      "    return room_reward\n",
      "def reward_1(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    import numpy as np\n",
      "\n",
      "    # Define the reward\n",
      "    reward = 0\n",
      "\n",
      "    # Extract the image and direction from the observation\n",
      "    image = observation['image']\n",
      "    direction = observation['direction']\n",
      "\n",
      "    # Constants\n",
      "    OBJECT_IDX = 4  # Index for the door\n",
      "    COLOR_IDX = keyroom_color\n",
      "    STATE_IDX = 1  # State for closed doors\n",
      "\n",
      "    # Dimensions of the image\n",
      "    width, height, _ = image.shape\n",
      "\n",
      "    # Agent is positioned at the bottom center of the image\n",
      "    agent_x = width // 2\n",
      "    agent_y = height - 1\n",
      "\n",
      "    # Check if the agent's forward position has the door of the keyroom_color\n",
      "    if direction == 0:  # Facing right\n",
      "        forward_x, forward_y = agent_x + 1, agent_y\n",
      "    elif direction == 1:  # Facing down\n",
      "        forward_x, forward_y = agent_x, agent_y - 1\n",
      "    elif direction == 2:  # Facing left\n",
      "        forward_x, forward_y = agent_x - 1, agent_y\n",
      "    elif direction == 3:  # Facing up\n",
      "        forward_x, forward_y = agent_x, agent_y + 1\n",
      "\n",
      "    # Ensure the forward position is within image bounds\n",
      "    if 0 <= forward_x < width and 0 <= forward_y < height:\n",
      "        # Get the object, color, and state in the forward position\n",
      "        object_forward, color_forward, state_forward = image[forward_x, forward_y]\n",
      "\n",
      "        # Check if the forward position has a door with the correct color and is closed\n",
      "        if object_forward == OBJECT_IDX and color_forward == COLOR_IDX and state_forward == STATE_IDX:\n",
      "            # If the agent is facing a correct door and it's closed, give a reward for trying to open it\n",
      "            if action == 5:  # Action to toggle/activate\n",
      "                reward = 1\n",
      "            else:\n",
      "                # Reward for facing the correct door but not toggling\n",
      "                reward = 0.5\n",
      "        else:\n",
      "            # Penalize slightly for not facing the correct door\n",
      "            reward = -0.1\n",
      "    else:\n",
      "        # Penalize more if trying to move out of bounds or in the wrong direction\n",
      "        reward = -0.5\n",
      "\n",
      "    return reward\n",
      "def reward_2(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    import numpy as np\n",
      "    \n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Define rewards\n",
      "    reward = 0\n",
      "    \n",
      "    # Constants for object and color indices\n",
      "    KEY_IDX = 5\n",
      "    \n",
      "    # Extract the agent's position (agent is at the bottom center of the image)\n",
      "    agent_x = image.shape[1] // 2\n",
      "    agent_y = image.shape[0] - 1\n",
      "    \n",
      "    # Check if the agent is in the room of the specified keyroom_color\n",
      "    # and if there is a key of lockedroom_color nearby\n",
      "    key_found = False\n",
      "    min_distance_to_key = float('inf')\n",
      "    \n",
      "    for y in range(image.shape[0]):\n",
      "        for x in range(image.shape[1]):\n",
      "            object_idx, color_idx, _ = image[y, x]\n",
      "            if object_idx == KEY_IDX and color_idx == lockedroom_color:\n",
      "                # Calculate Manhattan distance from the agent to the key\n",
      "                distance = abs(x - agent_x) + abs(y - agent_y)\n",
      "                min_distance_to_key = min(min_distance_to_key, distance)\n",
      "                key_found = True\n",
      "    \n",
      "    # Reward function based on distance to the key\n",
      "    if key_found:\n",
      "        # Normalize the distance to a reward, closer gets higher reward\n",
      "        max_distance = image.shape[0] + image.shape[1]  # Max possible Manhattan distance in the image\n",
      "        reward = 1 - (min_distance_to_key / max_distance)\n",
      "    else:\n",
      "        # No key found in the observation\n",
      "        reward = 0\n",
      "    \n",
      "    # Return the normalized reward\n",
      "    return reward\n",
      "import numpy as np\n",
      "\n",
      "def reward_3(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    # Extract observation details\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    mission = observation['mission']\n",
      "    \n",
      "    # Constants\n",
      "    KEY_OBJECT_IDX = 5  # Object index for 'key'\n",
      "    \n",
      "    # Agent's current position is at the bottom center of the image\n",
      "    agent_pos_x = image.shape[1] // 2  # x position, width direction, center\n",
      "    agent_pos_y = image.shape[0] - 1    # y position, height direction, bottom\n",
      "    \n",
      "    # Find the position of the lockedroom_color key in the image\n",
      "    key_positions = np.argwhere((image[:, :, 0] == KEY_OBJECT_IDX) & (image[:, :, 1] == lockedroom_color))\n",
      "    \n",
      "    # If the key is not found, provide a minimal reward\n",
      "    if key_positions.size == 0:\n",
      "        return 0.0\n",
      "    \n",
      "    # Calculate the Manhattan distance to each key of the correct color\n",
      "    distances = np.abs(key_positions[:, 0] - agent_pos_y) + np.abs(key_positions[:, 1] - agent_pos_x)\n",
      "    min_distance = np.min(distances)\n",
      "    \n",
      "    # Normalize distance to provide a reward between 0 and 1 (1 being on the key)\n",
      "    max_distance = image.shape[0] + image.shape[1]  # max possible Manhattan distance in the image\n",
      "    distance_reward = 1 - (min_distance / max_distance)\n",
      "    \n",
      "    # Check if the agent is currently on the position to pick up the correct key\n",
      "    if action == 3:  # action 3 is 'pick up an object'\n",
      "        if any((agent_pos_y == pos[0] and agent_pos_x == pos[1]) for pos in key_positions):\n",
      "            return 1.0  # Maximum reward when picking up the correct key\n",
      "    \n",
      "    return distance_reward  # Reward based on closeness to the key otherwise\n",
      "import numpy as np\n",
      "\n",
      "def reward_4(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    Reward function for the subgoal: Locate the {door_color} door.\n",
      "    \n",
      "    Args:\n",
      "    observation (dict): Contains 'direction', 'image', and 'mission' information.\n",
      "    action (int): The action performed by the agent.\n",
      "    lockedroom_color (int): Encoded color index for the locked room.\n",
      "    keyroom_color (int): Encoded color index for the key room.\n",
      "    door_color (int): Encoded color index for the door to locate.\n",
      "    \n",
      "    Returns:\n",
      "    float: The calculated reward for the given observation and action.\n",
      "    \"\"\"\n",
      "    image = observation['image']\n",
      "    # Extract width and height from the image dimensions\n",
      "    width, height, _ = image.shape\n",
      "    \n",
      "    # Define the reward\n",
      "    reward = 0.0\n",
      "    \n",
      "    # Check for the presence of the specified door_color door in the image\n",
      "    # A door is represented by OBJECT_IDX of 4\n",
      "    door_object_idx = 4\n",
      "    \n",
      "    # Initialize variables to find the closest door of the right color\n",
      "    min_distance = float('inf')\n",
      "    \n",
      "    # Find the closest door of the specified color\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            object_idx, color_idx, state_idx = image[x, y]\n",
      "            if object_idx == door_object_idx and color_idx == door_color:\n",
      "                # Calculate the distance to the door from the agent's position (bottom center of the image)\n",
      "                distance = np.sqrt((x - width // 2) ** 2 + (y - (height - 1)) ** 2)\n",
      "                if distance < min_distance:\n",
      "                    min_distance = distance\n",
      "\n",
      "    # Normalize the distance to provide a reward between 0 and 1\n",
      "    # Assuming the maximum distance could be the diagonal of the image\n",
      "    max_possible_distance = np.sqrt((width // 2) ** 2 + (height - 1) ** 2)\n",
      "    if min_distance < float('inf'):\n",
      "        reward = 1 - (min_distance / max_possible_distance)\n",
      "    \n",
      "    return reward\n",
      "import numpy as np\n",
      "\n",
      "def reward_5(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    # Extract the direction, image, and mission from the observation\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    mission = observation['mission']\n",
      "\n",
      "    # Constants for object types and states\n",
      "    OBJECT_IDX_KEY = 5\n",
      "    OBJECT_IDX_DOOR = 4\n",
      "    STATE_LOCKED = 2\n",
      "    STATE_CLOSED = 1\n",
      "    STATE_OPEN = 0\n",
      "\n",
      "    # Get the dimensions of the image\n",
      "    width, height, _ = image.shape\n",
      "\n",
      "    # Agent's position (always centered at the bottom of the image)\n",
      "    agent_x = width // 2\n",
      "    agent_y = height - 1\n",
      "\n",
      "    # Find the key with the specified color\n",
      "    key_position = None\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            if image[x, y, 0] == OBJECT_IDX_KEY and image[x, y, 1] == lockedroom_color:\n",
      "                key_position = (x, y)\n",
      "                break\n",
      "        if key_position:\n",
      "            break\n",
      "\n",
      "    # Find the door with the specified color\n",
      "    door_position = None\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            if image[x, y, 0] == OBJECT_IDX_DOOR and image[x, y, 1] == door_color:\n",
      "                door_position = (x, y)\n",
      "                break\n",
      "        if door_position:\n",
      "            break\n",
      "\n",
      "    # Calculate distances to the key and door\n",
      "    if key_position:\n",
      "        key_distance = np.sqrt((key_position[0] - agent_x) ** 2 + (key_position[1] - agent_y) ** 2)\n",
      "    else:\n",
      "        key_distance = float('inf')\n",
      "\n",
      "    if door_position:\n",
      "        door_distance = np.sqrt((door_position[0] - agent_x) ** 2 + (door_position[1] - agent_y) ** 2)\n",
      "    else:\n",
      "        door_distance = float('inf')\n",
      "\n",
      "    # Check door status\n",
      "    if door_position and image[door_position[0], door_position[1], 2] == STATE_LOCKED:\n",
      "        door_locked = True\n",
      "    else:\n",
      "        door_locked = False\n",
      "\n",
      "    # Define rewards\n",
      "    reward = 0.0\n",
      "\n",
      "    # If the door is locked and the agent has the key, motivate unlocking the door\n",
      "    if door_locked and key_position is None:\n",
      "        # Reward based on proximity to the door if the agent has picked up the key\n",
      "        reward += 1 - (door_distance / (width + height))\n",
      "    elif key_position is not None:\n",
      "        # Otherwise, reward moving towards the key\n",
      "        reward += 0.5 - (key_distance / (width + height))\n",
      "\n",
      "    # Additional reward for action 'toggle/activate object' at the door\n",
      "    if action == 5 and door_locked and door_distance < 1.5:\n",
      "        reward += 0.5  # High reward for unlocking the door\n",
      "\n",
      "    return max(0.0, reward)  # Ensure reward is not negative\n",
      "import numpy as np\n",
      "\n",
      "def reward_6(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    # Extract information from the observation\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    mission = observation['mission']\n",
      "    \n",
      "    # Constants for object, color, and state indices\n",
      "    OBJECT_IDX, COLOR_IDX, STATE_IDX = 0, 1, 2\n",
      "    DOOR, OPEN = 4, 0\n",
      "    \n",
      "    # Define rewards\n",
      "    reward = 0\n",
      "    \n",
      "    # Get the agent's position (assumed to be at the bottom center of the image)\n",
      "    agent_position_x = image.shape[1] // 2\n",
      "    agent_position_y = image.shape[0] - 1\n",
      "    \n",
      "    # Check if there's a door of the correct color and state right in front of the agent\n",
      "    if direction == 0:  # Facing right\n",
      "        front_x = agent_position_x + 1\n",
      "        front_y = agent_position_y\n",
      "    elif direction == 1:  # Facing down\n",
      "        front_x = agent_position_x\n",
      "        front_y = agent_position_y + 1\n",
      "    elif direction == 2:  # Facing left\n",
      "        front_x = agent_position_x - 1\n",
      "        front_y = agent_position_y\n",
      "    else:  # Facing up\n",
      "        front_x = agent_position_x\n",
      "        front_y = agent_position_y - 1\n",
      "    \n",
      "    # Check boundaries\n",
      "    if 0 <= front_x < image.shape[1] and 0 <= front_y < image.shape[0]:\n",
      "        front_cell = image[front_y, front_x]\n",
      "        # Check if the front cell is the correct door and it's open\n",
      "        if front_cell[OBJECT_IDX] == DOOR and front_cell[COLOR_IDX] == door_color and front_cell[STATE_IDX] == OPEN:\n",
      "            # Reward for being in front of the correct open door\n",
      "            if action == 2:  # move forward through the door\n",
      "                reward = 1\n",
      "            else:\n",
      "                reward = 0.5  # reward for facing the correct door but not moving through yet\n",
      "        else:\n",
      "            # Penalize wrong actions or not being in front of the door\n",
      "            reward = 0\n",
      "    else:\n",
      "        # Out of bounds or wrong orientation\n",
      "        reward = 0\n",
      "    \n",
      "    return reward\n",
      "def reward_7(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    import numpy as np\n",
      "\n",
      "    # Constants\n",
      "    GOAL_OBJECT_IDX = 3  # Assuming 'floor' object type indicates potential goal areas\n",
      "    GOAL_COLOR_IDX = 1   # 'green' color for the goal, light green specifically mentioned\n",
      "    MAX_REWARD = 1\n",
      "    MIN_REWARD = 0\n",
      "    \n",
      "    # Extract observation details\n",
      "    image = observation['image']\n",
      "    direction = observation['direction']\n",
      "    \n",
      "    # Dimensions of the image\n",
      "    width, height, _ = image.shape\n",
      "    \n",
      "    # Agent's position is centered at the bottom of the image\n",
      "    agent_x = width // 2\n",
      "    agent_y = height - 1  # Bottom row\n",
      "    \n",
      "    # Initialize reward\n",
      "    reward = MIN_REWARD\n",
      "    \n",
      "    # Check for floor colored green around the agent to find goal area\n",
      "    # We assume the goal might be reachable if it is directly in front of the agent\n",
      "    # Check in the direction the agent is facing\n",
      "    if direction == 0:  # Right\n",
      "        check_x, check_y = agent_x, agent_y - 1\n",
      "    elif direction == 1:  # Down\n",
      "        check_x, check_y = agent_x + 1, agent_y\n",
      "    elif direction == 2:  # Left\n",
      "        check_x, check_y = agent_x, agent_y + 1\n",
      "    elif direction == 3:  # Up\n",
      "        check_x, check_y = agent_x - 1, agent_y\n",
      "\n",
      "    # Check if the cell in the direction agent is facing is the goal\n",
      "    if (0 <= check_x < width) and (0 <= check_y < height):\n",
      "        object_idx, color_idx, _ = image[check_x, check_y]\n",
      "        if object_idx == GOAL_OBJECT_IDX and color_idx == GOAL_COLOR_IDX:\n",
      "            if action == 2:  # move forward\n",
      "                reward = MAX_REWARD\n",
      "            else:\n",
      "                reward = 0.5  # Encourage turning if not facing the goal directly\n",
      "        else:\n",
      "            # Penalize wrong moves slightly to encourage exploration\n",
      "            reward = 0.1\n",
      "    else:\n",
      "        # Penalize if looking or moving out of bounds\n",
      "        reward = 0.05\n",
      "\n",
      "    return reward\n"
     ]
    }
   ],
   "source": [
    "for c in completion_funcs_execute: \n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import RewardWrapper\n",
    "\n",
    "class CustomRewardWrapper(RewardWrapper):\n",
    "    def __init__(self, env, reward_func):\n",
    "        super().__init__(env)\n",
    "        self.generate_reward_func = reward_func # (obs, action) -> reard\n",
    "        self.counts = {} # ((x, y), action) => count\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        #params\n",
    "        bonus_factor = 0.2 # beta\n",
    "        intrinsic_factor = 0.9 # alpha\n",
    "        \n",
    "        observation, _, terminated, truncated, info = self.env.step(action)\n",
    "        reward = intrinsic_factor * self.reward_func(observation, action)\n",
    "        \n",
    "        pos = tuple(self.agent_pos)\n",
    "        state_and_action = (pos, action.item())\n",
    "\n",
    "        # Get the count for this key\n",
    "        count = self.counts[state_and_action] if state_and_action in self.counts else 0\n",
    "\n",
    "        # Update the count for this key\n",
    "        self.counts[state_and_action] = count + 1\n",
    "        \n",
    "        bonus = 1 / math.sqrt(self.counts[state_and_action])\n",
    "        reward += bonus_factor + bonus\n",
    "\n",
    "        # Get the position in front of the agent\n",
    "        fwd_pos = self.front_pos\n",
    "        fwd_cell = self.grid.get(*fwd_pos)\n",
    "        if action == self.actions.forward and fwd_cell is not None and fwd_cell.type == \"goal\":\n",
    "            print(\"REACHED GOAL, EXTRINSIC REWARD: \", self._reward())\n",
    "            reward += self._reward()\n",
    "            \n",
    "            \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        self.reward_func = self.generate_reward_func()\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "EPSILON = 0.1\n",
    "def generate_total_reward():\n",
    "    goal_number = 0\n",
    "    reward_funcs = [reward_0, reward_1, reward_2, reward_3, reward_4, reward_5, reward_6, reward_7]\n",
    "    def total_reward(obs, action):\n",
    "        nonlocal goal_number\n",
    "        \n",
    "        # print(obs)\n",
    "        \n",
    "        COLOR_TO_IDX = {\"red\": 0, \"green\": 1, \"blue\": 2, \"purple\": 3, \"yellow\": 4, \"grey\": 5}\n",
    "        \n",
    "        # preprocess -- ideally this would be done with LLM if we had more compute\n",
    "        lockedroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[2]]\n",
    "        keyroom_color = COLOR_TO_IDX[obs['mission'].split(' ')[6]]\n",
    "        door_color = COLOR_TO_IDX[obs['mission'].split(' ')[10]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        reward = reward_funcs[goal_number](obs, action, lockedroom_color, keyroom_color, door_color)\n",
    "\n",
    "        if reward > 1-EPSILON:\n",
    "            print(\"switching functions from \" + str(goal_number) + \" to \" + str(goal_number + 1))\n",
    "            goal_number += 1\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = RGBImgPartialObsWrapper(env) # convert to RGB obs DONT DO THIS  BRUH\n",
    "# env = ViewSizeWrapper(env, agent_view_size=7) # so the cnn can work with kernel size 8\n",
    "env = CustomRewardWrapper(env, generate_total_reward)\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (7 x 7). Kernel size: (8 x 8). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiInputPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(\u001b[38;5;241m1e5\u001b[39m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminigrid_models/minigrid_custom/12-exploration-bonus-states-actions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:171\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_kl \u001b[38;5;241m=\u001b[39m target_kl\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:174\u001b[0m, in \u001b[0;36mPPO._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range \u001b[38;5;241m=\u001b[39m get_schedule_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:135\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_class \u001b[38;5;241m=\u001b[39m RolloutBuffer\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_class(\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_kwargs,\n\u001b[1;32m    133\u001b[0m )\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:891\u001b[0m, in \u001b[0;36mMultiInputActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    873\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     optimizer_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    890\u001b[0m ):\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:507\u001b[0m, in \u001b[0;36mActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mortho_init \u001b[38;5;241m=\u001b[39m ortho_init\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor \u001b[38;5;241m=\u001b[39m share_features_extractor\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor\u001b[38;5;241m.\u001b[39mfeatures_dim\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:120\u001b[0m, in \u001b[0;36mBaseModel.make_features_extractor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseFeaturesExtractor:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/torch_layers.py:261\u001b[0m, in \u001b[0;36mCombinedExtractor.__init__\u001b[0;34m(self, observation_space, cnn_output_dim, normalized_image)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, subspace \u001b[38;5;129;01min\u001b[39;00m observation_space\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image_space(subspace, normalized_image\u001b[38;5;241m=\u001b[39mnormalized_image):\n\u001b[0;32m--> 261\u001b[0m         extractors[key] \u001b[38;5;241m=\u001b[39m \u001b[43mNatureCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_output_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m         total_concat_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cnn_output_dim\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;66;03m# The observation key is a vector, flatten it if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/torch_layers.py:101\u001b[0m, in \u001b[0;36mNatureCNN.__init__\u001b[0;34m(self, observation_space, features_dim, normalized_image)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Compute shape by doing one forward pass\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 101\u001b[0m     n_flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(n_flatten, features_dim), nn\u001b[38;5;241m.\u001b[39mReLU())\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (7 x 7). Kernel size: (8 x 8). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, ent_coef=0.2)\n",
    "model.learn(1e5)\n",
    "model.save(\"minigrid_models/minigrid_custom/12-exploration-bonus-states-actions\")\n",
    "\n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-12', episode_trigger=lambda e: e % 1 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 50000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"CustomLockedRoom-v0\", render_mode = \"rgb_array\", compute_reward = generate_total_reward())\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "model = PPO.load(\"minigrid_models/minigrid_custom/1\")\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "a.resize(3, 4)\n",
    "\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
