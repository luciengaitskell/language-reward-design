{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from gymnasium import spaces\n",
    "%matplotlib inline\n",
    "# import gymnasium as gym\n",
    "# from gym.envs.registration import registry, register\n",
    "from minigrid.wrappers import DictObservationSpaceWrapper # so that text mission string is actually a numerical dict\n",
    "\n",
    "# env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode = \"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env) # ONLY DO THIS FOR PPO TRAINING\n",
    "# env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "# import gym\n",
    "import torch\n",
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper, RGBImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the wrappers for the environment\n",
    "\n",
    "`MissionEncodingWrapper` adds one for every discrete space in the one-hot encoding of the mission, allowing 0 to be encoded as well.\n",
    "\n",
    "`ImageFeaturesExtractor` extracts relevant features if the observation is just an image, used with `ImgObsWrapper`\n",
    "\n",
    "`MinigridFeaturesExtractor` extracts relevant features from the entire observation, used with `MissionEncodingWrapper` and `DictObservationSpaceWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "# a custom wrapper to make the mission vector work with one hot encoding\n",
    "class MissionEncodingWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['mission'] = spaces.MultiDiscrete(np.array([n+1 for n in env.observation_space['mission'].nvec]))\n",
    "    def observation(self, obs):\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gymnasium.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        direction = observation_space['direction']\n",
    "        image = observation_space['image']\n",
    "        mission_string = observation_space['mission']\n",
    "        n_input_channels = image.shape[0] # should be 3, for RGB\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        direction_output_dim = 8\n",
    "        self.direction_net = nn.Sequential(nn.Linear(direction.n, direction_output_dim), nn.ReLU()) \n",
    "        \n",
    "        \n",
    "        ## add text extractor\n",
    "        self.transformer = nn.Transformer(d_model=len(mission_string), nhead=2, num_encoder_layers=2, num_decoder_layers=2) # squared because of one hot encoding\n",
    "        \n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space['image'].sample()[None]).float()).shape[1] ## 1024 for this example\n",
    "            \n",
    "        self.sentence_transformer_dim = len(mission_string) # is one-hot best here? or should we condense it to 50D vector?\n",
    "            \n",
    "        linear_input_dim = n_flatten + self.sentence_transformer_dim + direction_output_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(linear_input_dim, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        image_features = self.cnn(observations['image']) # .transpose((2, 0, 1)\n",
    "        direction_features = self.direction_net(observations['direction'])\n",
    "        if direction_features.shape[1] == 1:\n",
    "            direction_features = direction_features.squeeze(1)\n",
    "            \n",
    "       \n",
    "        one_hot_mission = observations['mission'].squeeze(0)\n",
    "       \n",
    "        mission_string_encoding = torch.empty((observations['mission'].shape[0], self.sentence_transformer_dim))\n",
    "        \n",
    "        # turn back into labels instead of one hot encoding\n",
    "        for i in range(0, self.sentence_transformer_dim**2, self.sentence_transformer_dim):\n",
    "\n",
    "            if len(one_hot_mission.size()) == 1:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = (torch.argmax(one_hot_mission[i:i+self.sentence_transformer_dim], dim = 0))\n",
    "            else:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = torch.argmax(one_hot_mission[:, i:i+self.sentence_transformer_dim], dim = 1)\n",
    "       \n",
    "        src = trg = torch.as_tensor(mission_string_encoding).unsqueeze(0).float()\n",
    "        \n",
    "        sentence_features = self.transformer(src, trg).squeeze(0) # to match dimensions\n",
    "\n",
    "        \n",
    "        try:\n",
    "            observations = torch.cat([image_features, sentence_features, direction_features], dim = 1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"image features dim\", image_features.shape)\n",
    "            print(\"sentence features dim\", sentence_features.shape)\n",
    "            print(\"direction features dim\", direction_features.shape)\n",
    "        return self.linear(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save it. -- also try `FlatObsWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (152, 152, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x11a0e6d40>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "(608, 608, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16b67ee10>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGiCAYAAACCpUOHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDcklEQVR4nO3dfXhU9Z03/veZxzPPk0kyM4mBGEiEhPBUIGHAdrualVIu11bu3uqPKrX+9JYGW6V1lV2rVlfxsru1tUXcuq7YW1229rdWpYoiVqgaHhIBCVDkSQNIEkzIE0lmJjPf3x8hs0ahNZkPSU54v65rrovMOfnw+Z7MzHvOzDnnqymlFIiIiAzKNNwNEBERpYNBRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGNmxBtnLlSlx44YXQdR3l5eXYunXrcLVCREQGNixB9l//9V9YtmwZ7rnnHrz33nuYOnUq5s2bh8bGxuFoh4iIDEwbjosGl5eXY9asWfjVr34FAEgmkxgzZgxuueUW3HnnnUPdDhERGZhlqP/DWCyGmpoaLF++PHWfyWRCRUUFqqqqzvg70WgU0Wg09XMymURzczMyMzOhado575mIiGQppdDe3o7c3FyYTOl9ODjkQfbJJ58gkUggFAr1uz8UCuHPf/7zGX9nxYoV+MlPfjIU7RER0RA6cuQI8vLy0qox5EE2GMuXL8eyZctSP7e2tmLs2LG4+uqrYbPZhrEzIiIajFgshjVr1sDj8aRda8iDLCsrC2azGQ0NDf3ub2hoQDgcPuPv2O122O32z91vs9kYZEREBibx9dCQH7Vos9kwY8YMbNiwIXVfMpnEhg0bEIlEhrodIiIyuGH5aHHZsmVYvHgxZs6cibKyMvz85z/HqVOncP311w9HO0REZGDDEmRXXXUVTpw4gbvvvhv19fWYNm0a1q1b97kDQIiIiP6aYTvYY+nSpVi6dOlw/fdERDRK8FqLRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERmaISbWPNeUUlBKidXTNE2snmQt6XrSvUnSNE1knqM+yWRSrBa32+CM9O12vvRmMo28/R8GGXqD7MUXX0RXV1fatXRdx4QJE7Bz506BzoDp06dj9+7diMViaddyuVwoKChAbW2tQGfAjBkzsHPnTvT09KRdy+fzIScnB3/+858FOgO+/OUvY8yYMSK1AGDbtm04ePCgSK1Zs2ahurpa5MUlHA7Dbrfjo48+EugMmDdvHjIzM0VqAcCmTZvw8ccfi9QqKyvD1q1bRWoVFBSgo6MDJ06cSLuWpmmYOXMmtm3bJtAZUFRUhE8++QQnT55Mu5bZbMb06dNRXV0t0BkwadIkTJ06VaSWJAbZaV1dXejs7Ey7TjKZRDweF6kFAPF4HF1dXYhGo2nXMplM4r11dnaKBJnNZkMsFhPrLZFIiNTpI9lbT08PTp06JVKru7sbAMR6k9yDAnr7k368SYhGo2K9aZqGnp4esd5isZhYb2azWXS7SbyhPhdG3j4iERHRADDIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkPjxJqn6bouMqmgruuwWCzQdV2gK6RqSUw/f656k5hYU9d1WK1Wsd7MZrNInT6SvVksFjgcDpEZom02m2hvEo+zT7Pb7SK9aZom+ti12WxivZlMJpjN5hHZm9lsFt1uVqtVpI40Bhl6nyQTJkxAPB5Pu5bFYkF2djZKS0sFOgOysrJQXFwsNgtzRkaGWG+ZmZkoKSkRewPg8XjEAsjr9YrU6XPBBReIvRj0/Q0kgqxvm3k8HoHOAKfTKVKnT35+PjIyMkRqBQIBscduRkYG4vE4gsFg2rU0TRPtLSsrC16vF7m5uWnXMplMor2FQiGROtIYZACUUti5c6fIdOC6rqO0tBTV1dUCnQFlZWXYuXMnotFo2rXcbjeKioqwfft2gc56Q/u9994TCVm/34+8vDzU1tYKdNZbz+fzidQCgA8//BD79u0TqWW327Ft2zaRWrm5udB1HYcOHRKpd8EFF4iG2QcffICjR4+K1LLb7WLPq8LCQrS3t6OhoSHtWpqmwWazifVWXFyMxsZGNDU1pV3LbDajrKxMrLepU6ciJydHpJYkfkdGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhjbgGaI3bdqEn/70p6ipqcHx48fxwgsv4Bvf+EZquVIK99xzD5544gm0tLRg7ty5WLVqFYqKilLrNDc345ZbbsHLL78Mk8mEhQsX4he/+AXcbrfIoAZK0zRMnz4d8Xg87VoWiwVZWVkoKysT6AzIycmB2WxGIpFIu5bNZoPf74fVahXoDAiHw5g5cyaSyWTatXRdh9vtFpud+IqGBhQdOwaVZh0NQJvbjaMFBWIzTgeDQbHHh9vthtlsRlZWlki9K688iFDoA6g0N5ymAQ0NARw+PAG5ubkivUluN7/fj3g8jvz8fJF6kr1lZmYiGAyiq6sr7VqapiEUCon1FgwGRepIG3CQnTp1ClOnTsV3v/tdXHnllZ9b/vDDD+PRRx/F008/jYKCAvz4xz/GvHnzsGfPHui6DgBYtGgRjh8/jvXr1yMej+P666/HTTfdhOeeey79EQ2CUgq7d+8WeeDouo7i4mLs3LlToLPeqcpra2sRi8XSruVyuTBu3Djs2rVLoDPAarVi165d6OnpSbuWz+dDbm4u9u7dK9AZ8P14HC8nk2gHYB5kjSR6nyA3ZGfjSGcnDhw4INKbrutij49wOAy73Y6PPvpIpF4gEMPzzyv09ACmQX5e09MDeL3A//7f+Th0yISPP/5YpDfJ7VZQUIBTp06hsbEx7Vqapon2NmHCBJw4cQLNzc1p1zKbzbBarWK9lZaWIhwOi9SSNOAgmz9/PubPn3/GZUop/PznP8ddd92FK664AgDwm9/8BqFQCL///e9x9dVXY+/evVi3bh22bduGmTNnAgB++ctf4utf/zr+5V/+Rezd20DFYjFEo9G062iahp6eHpFaAJBIJMR6s1qtSCQSor1Fo1GRIIvFYqLbLQrgOID/F8Bg3574ADwGoBsQ/5tK1YrH4zCbzWL1OjuBkyeB730PaG0dXA1dB558EojHe/sbidutp6fnLz+vbAAiAJYAyEHvg+k/AbwC4DMf3GiaJv43lXrO932aI7ndRqIBB9lfcvjwYdTX16OioiJ1n8/nQ3l5OaqqqnD11VejqqoKfr8/FWIAUFFRAZPJhC1btuCb3/zm5+pGo9F+f4i2tjbJtmmUsgM4CWDRIH//cQAOuXYMw+EADhwAbr55cL//7LOA3S7b05DSAFwO4FcAQqd/VgDmA1gK4P8OX2t0ZqIHe9TX1wMAQqFQv/tDoVBqWX19/ec+Z7VYLAgEAql1PmvFihXw+Xyp25gxYyTbplEs3e/I6DzkA/AP6A2xjwH8HsCHADwAbgMwdrgao7MxxFGLy5cvR2tra+p25MiR4W6JiEYrHcBU9O6JPQLgSgB3n/65BMDwfPtBf4FokPV9CdjQ0NDv/oaGhtSycDj8uS9Ye3p60NzcfNYvEe12O7xeb78bEdE5lwvACaDvQ6QeAOkfQEzCRIOsoKAA4XAYGzZsSN3X1taGLVu2IBKJAAAikQhaWlpQU1OTWufNN99EMplEeXm5ZDtERAPXAeA19B62ugTAbgD3ovdz6q3o/ZiRRpQBH+zR0dHR7zDkw4cPY8eOHQgEAhg7dixuvfVW/PM//zOKiopSh9/n5uamzjUrLi7G1772Ndx44414/PHHEY/HsXTpUlx99dXDdsQiEQC4AXwNwCkAbw5zL0bi9wMLFgDHjgFvvz3c3QjoAPBj9O6NTQOQj969sIMA7gNwYtg6o7MYcJBVV1fjb//2b1M/L1u2DACwePFirF69Gv/wD/+AU6dO4aabbkJLSwsuvvhirFu3LnUOGQA8++yzWLp0KS699NLUCdGPPvqowHCIBkcDcBOAf0bvp0eLh7cdw7BYgDvvBG69FWhvB85waqkxvQ/gfwFYDeCrAA4AuAxA3fC1RGc34CD76le/CvUXTvvXNA333Xcf7rvvvrOuEwgEhu3kZ6KzyUXv6UNWACPvlM+RyWwGcnMBqxVwOoEReuGHwfkIQN9xZe1giI1goueRERmVArAKvd/rtwN4Hr0HrtFfFo0CP/1p79U8PvwQeP31UbBXpqH3EHwNve9saMRjkBGddhDA90//e2Rev2Bk2rUL+D//B0gmAYFLgg6/IIA96A0xI5/YfR4xxHlkREOlBwyxwYjHR0mIAUAzgL9D73djrw9vK/TFcI+MiOjT4gDeO/3v9K/bS0OAe2RERGRo3CMjIvq0AIDfovfw1QnD3At9IQwyGrUUgAsBPDjI358MYJNYN8ahFDB5MvDgIDdcfj7SnphzWEUB/AH9P69qOMu6NCIwyGhUMgGIAfg1Bn/g2X4ArRj8xJxGZDb3zkP27//ee7LzYOzdC8Rig5+Yc9idQu/FgskwGGSnuVwumASeebquw2azwe12C3QF2Gw2uFwuWK3WtGu5XC7x3txut8hkey6XC3a7Xaw3M4BlGPykmn3sAGxOp2hvVqsVHo/nL15Y4ItyOByivTmdwB139J4fll5fQDSqw+FIim43qVq6riORSIjU0zRNvDen0yk2saZkb/YROtEcgwy9D8SCggLEYrG0a1mtVmRkZKCwsFCgM8Dv92PcuHEiYWG325GZmSnWm8/nw/jx45EQOO7a4XDA6/WK1AKAl8ePh9/nE6kFTUPwo49E3ugAvdutsLBQJMi8Xi8sFgtsNpkzd595ZiJcLqdILUBDbu4BuFwukWp9201CZmYmYrEYfAKPEU3TRHvLzs6Gw+FAZmZm2rVMJhP8fr/odhuJGGQAlFKora1FZ2dn2rV0XUdpaSl27NiRfmPo3evZtWuXyLszt9uNoqIisd50XcfOnTtFQtbv9yMvLw+1tbUCnQFZWVnwZWSI1AKAI0eOYN++fSK1XC4Xtm/fLlIrNzcXuq7j0KFDIvXy8/PhdMq8eweAgwcP4ujRoyK1XC6X2GO3sLAQ7e3tn5tyajA0TYPT6RTrrbi4GI2NjWhqakq7ltlsht1uF+tNKYULLrhApJYko36KTUREBIBBRkREBscgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNM0Sjd4bXGTNmIB6Pp13LYrEgMzMTFovMpg2Hw7BarUgkEmnXstls8Pl8sNvtAp0BOTk5KCsrQzKZTLuW3W6H2+2G2y0zO3EgEBCp02fcuHHIEJpxOhQKYfbs2SK13G43zGYzgsGgSD2XyyVSp09xcTHy8vJEakluN7/fj1gshoKCgrRraZom2lsgEEAoFEJ3d3fatUwmk2hv2dnZInWkMcjQO333zp070dnZmXYtXddRUlKC9957T6AzYObMmdi1axei0WjatdxuN8aPH4+dO3cKdAaUlZXhvffeQ09PT9q1/H4/cnNzsWfPHoHOAI/HA6/XK1ILAD788EPs379fpFYkEkF1dbVIrZycHNjtdnz44Yci9UKhEJxOp0gtAPjggw9w7NgxkVqS2238+PHo6OhAQ0ND2rU0TUN5eblYbxMnTkRjYyOam5vTrmU2mzFz5kyx3iZPnoxQKCRSSxKD7LSenh6RF+Senh4kk0mRWgBStdjbwCilROr0ORfbTUIikRCtJy2RSIzY7Sb12NU0DUop0d6ktptSSvyxOxLxOzIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaJxY8zSfzwebzZZ2HV3Xoes6/H5/+k2drufz+RCLxdKu5XK5RHuz2+3w+/0ik/Z5vV44HA6x3qxWq0idPk6nU3S7ZWRkiEz+6Xa7U38HCWazWaROH7fbLdKbpmmi43S5XAAgMvO6pmmw2WxivTmdTng8HiQSibRrmc1m0e3mcDhE6kjTlPRUukOgra0NPp8P1113nUj4GHAT0BegaZpYrUOHDqGxsVGkVkFBAQ4fPixSy+fzwWKxoKmpSaReaWkp3G63SC2Az63RSOp5FYvF8Jvf/Aatra3wer1p1eIeGWRf8Gh0OnbsGPbt2ydSy+fzoba2VqRWbm4udF3HoUOHROqNHz9eNMj43KKhMKDvyFasWIFZs2bB4/EgGAziG9/4xuee3N3d3aisrERmZibcbjcWLlyIhoaGfuvU1dVhwYIFcDqdCAaDuP3220U+niIiovPPgIJs48aNqKysxObNm7F+/XrE43FcdtllOHXqVGqd2267DS+//DKef/55bNy4ER9//DGuvPLK1PJEIoEFCxYgFovh3XffxdNPP43Vq1fj7rvvlhsVERGdNwb00eK6dev6/bx69WoEg0HU1NTgK1/5ClpbW/Hkk0/iueeewyWXXAIAeOqpp1BcXIzNmzdj9uzZeP3117Fnzx688cYbCIVCmDZtGu6//37ccccduPfee0W+8yIiovNHWofft7a2AgACgQAAoKamBvF4HBUVFal1Jk6ciLFjx6KqqgoAUFVVhcmTJyMUCqXWmTdvHtra2rB79+4z/j/RaBRtbW39bkREREAaQZZMJnHrrbdi7ty5KC0tBQDU19ef8TDUUCiE+vr61DqfDrG+5X3LzmTFihXw+Xyp25gxYwbbNhERjTKDDrLKykrU1tZizZo1kv2c0fLly9Ha2pq6HTly5Jz/n0REZAyDOvx+6dKlWLt2LTZt2oS8vLzU/eFwGLFYDC0tLf32yhoaGhAOh1PrbN26tV+9vqMa+9b5LLvdDrvdPphWiYholBvQHplSCkuXLsULL7yAN998EwUFBf2Wz5gxA1arFRs2bEjdt2/fPtTV1SESiQAAIpEIdu3a1e/k0vXr18Pr9aKkpCSdsRAR0XloQHtklZWVeO655/Diiy/C4/GkvtPy+XxwOBzw+Xy44YYbsGzZMgQCAXi9Xtxyyy2IRCKYPXs2AOCyyy5DSUkJrr32Wjz88MOor6/HXXfdhcrKSu51ERHRgA0oyFatWgUA+OpXv9rv/qeeegrf+c53AACPPPIITCYTFi5ciGg0innz5uGxxx5LrWs2m7F27VosWbIEkUgELpcLixcvxn333ZfeSIiI6Lw0oCD7ItdN03UdK1euxMqVK8+6Tn5+Pl555ZWB/NdERERnxGlciIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxhmi0XtaQVdXl8i07JqmwWq1IhaLCXQG2Gw2xONxkd5MJhPMZjPi8bhAZyO7N7vdDotF7uE9fvx4ZGZmitQKh8OYM2eOSC2XywWz2XzWy7sNlOTs0EDvRLuJREKkls1mE3teWSwWKKVGZG9WqxWJRALJZDLtWtKvR1ardUROtcUgQ2+QvfTSS+js7Ey7lq7rmDRpEmpqagQ6A2bNmoX3338f0Wg07VputxuFhYXYsWNH+o0BKC8vR01Njcjs3n6/HxdccMFZp/IZqEsvvRT5+fkitQDg0KFD+OCDD0RqzZkzB5s3bxaplZOTA13XcfjwYZF62dnZcDgcIrUAYNOmTTh69KhIrTlz5uDdd98VqTV+/Hh0dHR8bvb6wdA0DbNnz05NVZWu4uJiNDQ0oLm5Oe1aZrMZs2bNEnu8TZkyBTNnzhSpJYlBdloymRR5B5RMJqGUEqkFIFWLvQ2MxF7iZ+tJbzepWpL1pEk9PoBz8zeQ2usBINab5HNB07QR/bySwu/IiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaFxYs3TMjMz4XK50q5jt9vhdDqRnZ0t0BXgdDqRmZmJeDwuUsvlcon15nA4kJWVJTJdvMfjgdvtFuvNbreL1Onj8XhEt5tULb/fD5vNJlbPYpF9SfD5fCKzmwOy283r9cJisYhNXqnrulhvHo8H8XgcJlP6+xkmk0l0u0m8Rp4LDLLT/H4/YrFY2nWsViscDgcCgYBAV4Cu68jIyEBPT0/atex2+znpTeLFwOl0wul0ivVmtVpF6vSR7M1ut4vV8ng8sFgsYvWkg8zj8Yg8dgHZ7eZyuWA2m8VmPNZ1Xaw3p9OJnp4emM3mtGuZTCbx3kYiBtlpBw8eRGdnZ9p1dF2HruvYt2+fQFe972gPHDgg8q7W7XbDbDaL9ZaRkYH9+/eLvFD5/X7E43Gx3saMGYOsrCyRWgDQ0NAg1ltWVpZYrdzcXOi6jkOHDonUmzhxIjwej0gtADh69CiOHj0qUktyuyUSCbS3t6OhoSHtWpqmifZmMpnQ2NiIpqamtGuZzWb4/X6x3nRdx4UXXihSSxK/IyMiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJD4wzR6J3hddasWSIzHVssFmRkZMButwt0BgSDQei6jkQikXYtq9UKn88nNl15KBRCJBJBMplMu5bdbofL5YLP5xPoDAh3XAJsz0YS6f1NNZjhybJh/nw35syZI9JbMBjEhAkToJRKu5bT6YTZbEZ7e7tAZ0BeXh7MZnPavWmahlgshkmTJiE/P1+kt3A4jLlz54rU8vl8iMfjIrPCa5qGUCgk1ltGRgZyc3PR3d2ddi1N0xAMBsV6y8zMFKkjjUEGQCmF6upqnDp1Ku1aDocDpaWl2LZtm0BnQFlZGXbu3IloNJp2LY/Hg8LCQmzfvl2gM2D27Nmorq4WeQOQkZGBCy64ALW1tQKdAa7w3+CjU28ioXpg0gb3MFdIIql68DXbTejp6sKJEydEesvKykJjY6NIrUAgAJvNJtZbbm4ujh07Bk3ToGnaoGokk0mYTCZccMEF2LNnD44cOSLS28UXX4x33nlHpFZhYSE6OjpQX1+fdi1N0zBnzhyx3kpKStDQ0ICmpqa0a5nNZpSVlaGqqkqgM2Dq1KkIBoMitSQxyE6TeHfcV0eqlrSR2hcg35tCEkkkMC1jIVrjHw+qRoZtDLaf/F3ae3XnmuS2U0pB0zTk5+cP+o2dw+HAkSNHxJ8L4o+REfp8GKl9jWQMMhq1NJjR0XMC6+tXDOr3Lw39CCaYhbsa+TRNQ3t7O/bu3Tuo3588efKg9+aIBmNAB3usWrUKU6ZMgdfrhdfrRSQSwauvvppa3t3djcrKSmRmZsLtdmPhwoVoaGjoV6Ourg4LFiyA0+lEMBjE7bffLvLRFBERnZ8GFGR5eXl46KGHUFNTg+rqalxyySW44oorsHv3bgDAbbfdhpdffhnPP/88Nm7ciI8//hhXXnll6vcTiQQWLFiAWCyGd999F08//TRWr16Nu+++W3ZURER03hjQR4uXX355v58feOABrFq1Cps3b0ZeXh6efPJJPPfcc7jkkksAAE899RSKi4uxefNmzJ49G6+//jr27NmDN954A6FQCNOmTcP999+PO+64A/feey9sNpvcyIiI6Lww6PPIEokE1qxZg1OnTiESiaCmpgbxeBwVFRWpdSZOnIixY8emjpipqqrC5MmTEQqFUuvMmzcPbW1tqb26M4lGo2hra+t3IyIiAgYRZLt27YLb7YbdbsfNN9+MF154ASUlJaivr4fNZoPf7++3figUSh3iWl9f3y/E+pb3LTubFStWwOfzpW5jxowZaNtEf5XTnIEZGf8Ppvi+AatJ5ly784Hdbse4ceOQk5MDk4nXWKChN+CjFidMmIAdO3agtbUVv/vd77B48WJs3LjxXPSWsnz5cixbtiz1c1tbG8OMhGmY4v8myjKvg1JJxFX6J6OeDzRNw7hx45CXl4dEIoFYLDbcLdF5aMBBZrPZUFhYCACYMWMGtm3bhl/84he46qqrEIvF0NLS0m+vrKGhAeFwGEDvmflbt27tV6/vqMa+dc7EbreLXSmDiGTxvCcabml/DpBMJhGNRjFjxgxYrVZs2LAhtWzfvn2oq6tDJBIBAEQiEezatavfVQ3Wr18Pr9eLkpKSdFshSoPCzpYX8M6Jf8NbjY/iQPum4W7IEJRSOHz4MA4cOIC9e/fi5MmTw90SnYcGtEe2fPlyzJ8/H2PHjkV7ezuee+45vPXWW3jttdfg8/lwww03YNmyZQgEAvB6vbjlllsQiUQwe/ZsAMBll12GkpISXHvttXj44YdRX1+Pu+66C5WVldzjomHXlTiJmpP/OdxtGE40GsXhw4eHuw06jw0oyBobG3Hdddfh+PHj8Pl8mDJlCl577TX83d/9HQDgkUcegclkwsKFCxGNRjFv3jw89thjqd83m81Yu3YtlixZgkgkApfLhcWLF+O+++6THRUREZ03BhRkTz755F9crus6Vq5ciZUrV551nfz8fLzyyisD+W+JiIjOisfKEhGRoTHIiIjI0Hj1exq1FBJwW7JxWfgfB/X7flse6jrfE+5q5FNKwe12Y9KkSYP6fbvdzkPyaUgxyGhU0mCCCWbsOPn/DX5izVObkVQ9MMGC9OfANgZN06CUQl1dXdoTa3IqFxoqDLLTwuGwyNTiNpsNHo8Hubm5Al0Bbrcb4XAY8Xg87VoOh0O8t5ycHCQSCZFaPp9PrrdMDV/OuwpJld4UQRrM0DOSUC4XAoGASG+6rovV8nq9sFgsIo8PAHC5XCgpKUl7j0rTNHR1dSEzMxPJpMzbAJfLJfb4yMjIgN1uh9mc/nxzmqbB6XSK9eb3+6GUEjklyWQyiW43r9crUkcag+w0qfPYrFYrzGYzdF0XqWc2m8WecHa7HRaLRbw3iRcq6d4S42qB7AaRL4FjDgd0sw6r1SpQrffFxWaziXz8ZrFYYDabxXuT0NXVBZvNJvp4k6pltVpFe5N87FosFrHeTCaTeG8j0cjsahh89NFH6OzsTLuOruvweDw4dOiQQFdAVlYWPvroI0Sj0bRr9V3sWaq3YDCIDz/8UGRi1L53oVK9jRs3DtnZ2SK1gN7re352ktjBCgQCf/Ei2QMRj8dhtVrFervwwgtF6vQ5fvw4jh49KlIrJydH7PFhMpnQ3t4ust00TRPtzW63o7GxEU1NTWnXMpvNyM7OFuvN4/Fg/PjxIrUk8ahFIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjTOEI3eGV7LyspEZjo2m80IBAJiU4tnZ2dD13Ukk8m0a1mtVni9XrhcLoHOemeIjkQiUEqlXctms8HlcsHv96ffGIDMzEyROn1yc3Ph8/lEavn9fpSUlIjUstvtMJlMYuN1OBwidfpMmjRJbNbpcDiMiy++WKSW1+tFPB5HV1eXSL1QKCTWm9/vR25ursis8JqmIRgMivUm/bySwiADoJTC1q1b0dnZmXYtXddRWlqK6upqgc6AsrIy7Ny5U+RB7Xa7UVRUhO3btwt0BsyePRvV1dUibwD8fj/y8vJQW1sr0BlQUVEBj8cjUgsAPv74Yxw7dkykVnFxMfbu3StSKxAIwGq1oqGhQaSex+OBzWYTqQUAu3fvxtGjR0VqzZ07F++8845IrcLCQrS3t4tsN03TMGfOHLHeiouL0djYiKamprRrmc1mlJWVoaqqSqAzYOrUqcjOzhapJYkfLRIRkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhcYbo0/Ly8kRmYbbZbPD5fMjPzxfoqndK9jFjxiAej6ddy+FwwO/3i/Y2duxYJBKJtGu53W4EAgGx3pxOp0idPh6PB8FgUKSWw+EQq+V2u2GxWKCUEqlnsci+JIRCIZjNZpFaHo9H7PGRlZUFt9sNXdfTrqVpmmhvmZmZMJvNcLvdadcymUzwer1ivWVkZIjUkcYgQ+8f+ytf+YpozYKCArFaF154oVgtABg/frxYrbFjx4rVAoCLLrpItJ4UpRSSyeSIrCVZT9r06dNF6+Xl5YnWkzSSexszZsxwt3BOMciIvoCOjg588sknIrWys7PFaiWTSVitVrF6km9yiIYKvyMjIiJDY5ARDcAcACEA1uFuhIhS+NEi0QBcASAMoBrAOwD2AOge1o6IiEFGNAAagACAy9C7d3YUwHoAuwA0ABiZh1wQjW5pfbT40EMPQdM03Hrrran7uru7UVlZiczMTLjdbixcuBANDQ39fq+urg4LFiyA0+lEMBjE7bffjp6ennRaIRpybgATAXwPwD0AvgtgHADbcDZFdB4a9B7Ztm3b8G//9m+YMmVKv/tvu+02/OEPf8Dzzz8Pn8+HpUuX4sorr8Q777wDAEgkEliwYAHC4TDeffddHD9+HNdddx2sVisefPDB9EZDNAzMAC4AkAPg7wDsBbARwHYALcPXFtF5Y1B7ZB0dHVi0aBGeeOKJfifItba24sknn8TPfvYzXHLJJZgxYwaeeuopvPvuu9i8eTMA4PXXX8eePXvwzDPPYNq0aZg/fz7uv/9+rFy5ErFYTGZURMPABMAJYAaASgA/AXAtgDHgXhrRuTSoIKusrMSCBQtQUVHR7/6amhrE4/F+90+cOBFjx45FVVUVAKCqqgqTJ09GKBRKrTNv3jy0tbVh9+7dZ/z/otEo2tra+t2IRjI7gAIA3wRwE3r31ojo3BjwR4tr1qzBe++9h23btn1uWX19PWw2G/x+f7/7Q6EQ6uvrU+t8OsT6lvctO5MVK1bgJz/5yUBbJRo27eg9onHz6Vvn8LZDNKoNKMiOHDmCH/zgB1i/fr3INcq+qOXLl2PZsmWpn9va2kb9JVfIeOIATqD3u7FNAD4EA4xoKAwoyGpqatDY2IgvfelLqfsSiQQ2bdqEX/3qV3jttdcQi8XQ0tLSb6+soaEB4XAYABAOh7F169Z+dfuOauxb57PsdjvsdvtAWiUaEgpADMAhAG8B2AKgaTgbIjoPDSjILr30Uuzatavffddffz0mTpyIO+64A2PGjIHVasWGDRuwcOFCAMC+fftQV1eHSCQCAIhEInjggQfQ2NiYugL4+vXr4fV6UVJSIjEmoiHRiN6PD9cDOACgC73BRkRDa0BB5vF4UFpa2u8+l8uFzMzM1P033HADli1bhkAgAK/Xi1tuuQWRSASzZ88GAFx22WUoKSnBtddei4cffhj19fW46667UFlZyb0uGvGiAA4CeBvANgAfo/cjRSIaPuJX9njkkUdgMpmwcOFCRKNRzJs3D4899lhqudlsxtq1a7FkyRJEIhG4XC4sXrwY9913n3QrROKeBVAHfvdFNJKkHWRvvfVWv591XcfKlSuxcuXKs/5Ofn4+XnnllXT/a6Ih9+fhboCIPodXvyciIkNjkBERkaHx6vfonS7+xIkTItPFm0wmOJ1OdHR0CHTWe4DNqVOnRHozm81wOByivXV0dECp9I/Vs1gssNls6OyU+fbJ7/eLnuuYk5MDr9crUisjIwMlJSUi203XdZhMJgQCAYHOAIfDIVKnz8mTJxGNRkVqeb1esav6OBwOJBIJscviSfbmdDoRj8cRj6d/GJGmafB4PGK9uVwueDwekVqSGGToDbI33nhD5EVU13WUlpaiurpaoDOgrKwMO3fuFHkxcLvdKCoqwvbt2wU6A2bPno3q6mqRmQv8fj/y8vJQW1sr0BlQUVGBCy+8UKQWABw/fhzHjh0TqVVcXIy9e/eK1AoEArBarZ+bYWKwvF4vbDa5K0Nu2bIFR48eFak1d+7c1MXH01VYWIj29naR7aZpGubMmSPWW3FxMRobG9HUlP4ZiWazGWVlZalLBKZr6tSpmDVrlkgtSfxokYiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNM0SfVlBQIDILs81mQyAQQGFhoUBXQEZGBsaNGycy7bmu66K9+f1+jB8/HolEIu1aLpcLGRkZYr253W6ROn38fj+SyaRILZfLhdzcXCil0q7ldrthNpthMsm8J7VarSJ1+uTm5kLXdZFaPp9P7PERCoXg8/ng8XjSrqVpmmhvwWAQdrsdGRkZadcymUzw+/1ivWVmZorUkcYgO62jowPd3d1p17Hb7YjFYmhvbxfoCojFYujo6EAsFku7ViKROCe99fT0iNRzOp1ivUn11CcWi6Grq0ukVk9PD7q6ukSCzGq1wmKxiPUmFdZ9urq6RP6mmqYhHo+LPT58Pp9ob5LPq+7ubnR2dorUM5vN4s/5kYhBdtqJEyfQ2dmZdh1d1xEMBtHQ0CDQFZCfn4/GxkaRvUW32w2/3y/WW0FBARoaGkRCIxqNQtd1sd4k3pR8WmdnJ1paWkRqRaNRnDx5UqSWyWSC1WoV601i7/rTTp48KfY3HT9+vFgtj8eD9vZ2kXqapon2FggE0NTUhKamprRrmc1m5Ofni/UWDodF6kjjd2RERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0Dix5mmapkHTtLTrmEwmsVp9pOr11ZDqra8vqd5kt5sJyaRMLaVk3+/1jVNihmjpx5rSFJSWfl99tST7Oxe1+LwaeL2RiEGG3j/OzJkzRWY6NpvNCAQCsNlsAp0BwWAQuq6LzNxrtVrh8/ngdDoFOgNCoRDKy8tFXpBtNhvcbje8Xq9AZ8CePZXYvDkTQFealezIy/Pj6qv/W6w3v9+PiRMnitSy2+0wm83IyMgQqbdv4T5Ec9OfjRwArLVWFG8qxtixY0XqhUIhzJkzR6SW1+tFPB7H+PHjReqFw2Gx3jIyMhAOh0Vmhdc0DcFgUKy3zMxMkTrSGGQAlFLYtm0bOjs7066l6zpKS0tRXV0t0BlQVlaGnTt3ijyo3W43ioqKsH37doHOgNmzZ6O6ulrkDYDf70deXh5qa2sFOgOAZgBPA3ADsA+yRg+ARnR13Yvjx4/j2LFjIp0VFxdj7969IrUCgQCsVqvYVPYwATgO4EiadQoB5VDYs2cPjh49KtAYMHfuXLzzzjsitQoLC9He3i6y3TRNw5w5c8R6Ky4uRmNjI5qamtKuZTabUVZWhqqqKoHOgKlTpyIYDIrUksQgo1EqCcAG4CYAGwdZ428APAYg/b1hQ2kC8FGaNUbeax2NYgwyGsU0AB8C+KdB/v7jp2sQ0UjGoxaJiMjQGGRERGRoDDIiIjI0BhlRP1bwq2MiY+EzlihlPIAfAWgH8NNh7oWIvqgB7ZHde++9/c4U1zSt34md3d3dqKysRGZmJtxuNxYuXPi58zTq6uqwYMECOJ1OBINB3H777SLnIRGlRwOwBMCNAG4D8L+Gt52RzgnA/6mbZxh7ofPegPfIJk2ahDfeeON/Clj+p8Rtt92GP/zhD3j++efh8/mwdOlSXHnllakTBROJBBYsWIBwOIx3330Xx48fx3XXXQer1YoHH3xQYDhE6fgYQAy9J0LXA5g6vO2MVCYA0wEUfeq+JgAvD087RAMOMovFgnA4/Ln7W1tb8eSTT+K5557DJZdcAgB46qmnUFxcjM2bN2P27Nl4/fXXsWfPHrzxxhsIhUKYNm0a7r//ftxxxx249957xS7rRDRwCsCvAdQB6ADwRwDzhrWjESsJYCuA9z5zH9EwGfDBHvv370dubi7GjRuHRYsWoa6uDgBQU1ODeDyOioqK1LoTJ07E2LFjU5dHqaqqwuTJkxEKhVLrzJs3D21tbdi9e/dZ/89oNIq2trZ+NyJ5HQB+B2AdAJnrDY5acfRexrLvxs1Fw2hAQVZeXo7Vq1dj3bp1WLVqFQ4fPowvf/nLaG9vR319PWw2G/x+f7/fCYVCqK+vBwDU19f3C7G+5X3LzmbFihXw+Xyp25gxYwbSNhERjWID+mhx/vz5qX9PmTIF5eXlyM/Px29/+1s4HA7x5vosX74cy5YtS/3c1tbGMCMiIgBpnkfm9/tx0UUX4cCBAwiHw4jFYmhpaem3TkNDQ+o7tXA4/LmjGPt+PtP3bn3sdju8Xm+/GxEREZBmkHV0dODgwYPIycnBjBkzYLVasWHDhtTyffv2oa6uDpFIBAAQiUSwa9cuNDY2ptZZv349vF4vSkpK0mmF6Cw0/M+Ff7UvePvs7xHRSDagjxZ/9KMf4fLLL0d+fj4+/vhj3HPPPTCbzbjmmmvg8/lwww03YNmyZQgEAvB6vbjlllsQiUQwe/ZsAMBll12GkpISXHvttXj44YdRX1+Pu+66C5WVlbDbBztnFNHZRNF7ktPvBvn7PgCviXVDROfGgILs6NGjuOaaa9DU1ITs7GxcfPHF2Lx5M7KzswEAjzzyCEwmExYuXIhoNIp58+bhscceS/2+2WzG2rVrsWTJEkQiEbhcLixevBj33Xef7KiIYAWQA+C/AJgHWSMJIABAl2rKGIqQ/nximeidQYdoCAwoyNasWfMXl+u6jpUrV2LlypVnXSc/Px+vvPLKQP7bIVFUVIRYLJZ2HZvNhqysLBQXFwt01Tu1+IQJExCPx9Oupes6srOzxXoLBAKYOHEiEon0J550Op3w+/0itXo1AbgcveeHpUNDIHAYyWQSTqdToK/e00mkaplMvd8OSNXDdshMinkE6OruQsfiDuCkQD0Azian2GM3GAyiu7sbgUAg7VqapiEjI0Ost5ycHLjdbpGZmE0mEwKBgOh2G4l4rcXTPvnkE3R3d6ddp+/AlE9/D5iOYDCIEydOiISs0+mEw+EQ6y0UCqGxsVEkfDweDywWi1hv5eXrkZt79nMTB6qm5j189FG60yb3mjZtGnbs2CFSKzs7GzabDceOHROp99XEV5GRkSFSq3laM1r+uUWkFhQQXxoXe3zY7XZ0dnaiqakp7VqapiEcDov15na70dTUhNbW1rRrmUwmBINBsd4+e3rVSMEgO+3kyZPo7OxMu46u68jNzRV5ggBAV1cXmpubEY2mf8ZpNBpFVlaWWG/d3d1obm4WuVZmIpFIPYElSAT/p506dUp0u0nVstvt0HVdrN5Ivu5pvCcuNs6MjAy0t7eLBVk0GhXrLRgMorW1VaSe2WwWfbxJvEaeC5zGhYiIDI1BRkREhsYgIyIiQ2OQERGRoTHIiIjI0BhkRERkaAwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkaJ9Y8zWw2w2w2i9QxmUwitYDeSfske+urJ6FvnEqptGudi+0m6Vz8TSWYTCbR3iRpSoM5LtSXAkyQG2ffNpOop2naiP2bnovn/EjEIEPvA3H69OmIx+Np17JYLAgEAigrKxPoDAiFQrBarUgkEmnXslqt8Pv9sNvtAp319jZz5kwkk8m0a9ntdrjdbrhcLoHOemcAllRQUCA2zXswGBR7fLhcLlgsFmRnZ4vUc7vdInUAIG93Hr66+KtiswoH7XLbze/3IxaLIT8/P+1amqaJ/k0DgQCCwSC6u7vTrqVpGsLhsFhvWVlZInWkMcgAKKVQXV0t8oTTdR2lpaWorq4W6AwoKyvDzp07EY1G067ldrtRVFSE7du3C3QGzJ49G9XV1ejp6Um7lt/vR15eHmprawU6632B93q9IrUA4ODBg9i3b59Irblz56KqqkqkVm5uLnRdx6FDh0TqBYNBOBwOkVrmHjP2/Wkfjh49KlJPcrsVFhaivb0dDQ0NadfSNA1z5swR6624uBiNjY1oampKu5bZbEZZWZlYb1OnTkUoFBKpJWlk7icSERF9QQwyIiIyNAYZEREZGoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIbGICMiIkNjkBERkaExyIiIyNAYZEREZGicIfq0SZMmIRaLpV3HarUiFAph6tSpAl31zthbWloqMguz3W5HZmamWG/Z2dmYPHkykslk2rUcDge8Xi/MZrNAZ4DP5xOp02fMmDHQdV2kluTfwOv1wmKxwOPxiNSTmh26z7hx45CZmSlSS3K7ZWZmIhaLIRwOp11L0zTR3oLBIPx+v8iM9SaTCVlZWWK95eTkiNSRpiml1HA3MVBtbW3w+Xy47rrrYLPZhrsdIiIaoFgsht/85jdobW2F1+tNqxY/WiQiIkNjkBERkaExyIiIyNAYZEREZGgMMiIiMjQGGRERGRqDjIiIDI1BRkREhsYgIyIiQ2OQERGRoQ04yI4dO4Zvf/vbyMzMhMPhwOTJk1FdXZ1arpTC3XffjZycHDgcDlRUVGD//v39ajQ3N2PRokXwer3w+/244YYb0NHRkf5oiIjovDOgIDt58iTmzp0Lq9WKV199FXv27MG//uu/IiMjI7XOww8/jEcffRSPP/44tmzZApfLhXnz5qG7uzu1zqJFi7B7926sX78ea9euxaZNm3DTTTfJjYqIiM4bA7po8J133ol33nkHf/rTn864XCmF3Nxc/PCHP8SPfvQjAEBraytCoRBWr16Nq6++Gnv37kVJSQm2bduGmTNnAgDWrVuHr3/96zh69Chyc3P/ah+8aDARkbEN20WDX3rpJcycORPf+ta3EAwGMX36dDzxxBOp5YcPH0Z9fT0qKipS9/l8PpSXl6OqqgoAUFVVBb/fnwoxAKioqIDJZMKWLVvO+P9Go1G0tbX1uxEREQEDDLJDhw5h1apVKCoqwmuvvYYlS5bg+9//Pp5++mkAQH19PQAgFAr1+71QKJRaVl9fj2Aw2G+5xWJBIBBIrfNZK1asgM/nS93GjBkzkLaJiGgUG1CQJZNJfOlLX8KDDz6I6dOn46abbsKNN96Ixx9//Fz1BwBYvnw5WltbU7cjR46c0/+PiIiMY0BBlpOTg5KSkn73FRcXo66uDgBSs602NDT0W6ehoSG1LBwOo7Gxsd/ynp4eNDc3n3W2VrvdDq/X2+9GREQEAJaBrDx37lzs27ev330ffPAB8vPzAQAFBQUIh8PYsGEDpk2bBqD3wIwtW7ZgyZIlAIBIJIKWlhbU1NRgxowZAIA333wTyWQS5eXlX6iPvuNTYrHYQNonIqIRou/1ewDHG56dGoCtW7cqi8WiHnjgAbV//3717LPPKqfTqZ555pnUOg899JDy+/3qxRdfVO+//7664oorVEFBgerq6kqt87WvfU1Nnz5dbdmyRb399tuqqKhIXXPNNV+4j4MHDyoAvPHGG2+8Gfx25MiRgcTQGQ3o8HsAWLt2LZYvX479+/ejoKAAy5Ytw4033pharpTCPffcg1//+tdoaWnBxRdfjMceewwXXXRRap3m5mYsXboUL7/8MkwmExYuXIhHH30Ubrf7C/XQ0tKCjIwM1NXVwefzDaR9w2pra8OYMWNw5MiR8+ajVY6ZYx6NzrfxAmces1IK7e3tyM3NhcmU3kWmBhxkI0HfeWQS5x8YBcfMMY9W59uYz7fxAud+zLzWIhERGRqDjIiIDM2QQWa323HPPffAbrcPdytDhmM+P3DMo9/5Nl7g3I/ZkN+RERER9THkHhkREVEfBhkRERkag4yIiAyNQUZERIbGICMiIkMzZJCtXLkSF154IXRdR3l5ObZu3TrcLQ3apk2bcPnllyM3NxeapuH3v/99v+VKKdx9993IycmBw+FARUUF9u/f32+d5uZmLFq0CF6vF36/HzfccAM6OjqGcBRf3IoVKzBr1ix4PB4Eg0F84xvf+NyFqLu7u1FZWYnMzEy43W4sXLjwczMq1NXVYcGCBXA6nQgGg7j99tvR09MzlEP5wlatWoUpU6akZm6IRCJ49dVXU8tH23g/66GHHoKmabj11ltT9422Md97773QNK3fbeLEianlo228fY4dO4Zvf/vbyMzMhMPhwOTJk1FdXZ1aPmSvX2lfrXGIrVmzRtlsNvUf//Efavfu3erGG29Ufr9fNTQ0DHdrg/LKK6+of/qnf1L//d//rQCoF154od/yhx56SPl8PvX73/9e7dy5U/393//9GS/CPHXqVLV582b1pz/9SRUWFg7oIsxDad68eeqpp55StbW1aseOHerrX/+6Gjt2rOro6Eitc/PNN6sxY8aoDRs2qOrqajV79mw1Z86c1PKenh5VWlqqKioq1Pbt29Urr7yisrKy1PLly4djSH/VSy+9pP7whz+oDz74QO3bt0/94z/+o7Jaraq2tlYpNfrG+2lbt25VF154oZoyZYr6wQ9+kLp/tI35nnvuUZMmTVLHjx9P3U6cOJFaPtrGq5RSzc3NKj8/X33nO99RW7ZsUYcOHVKvvfaaOnDgQGqdoXr9MlyQlZWVqcrKytTPiURC5ebmqhUrVgxjVzI+G2TJZFKFw2H105/+NHVfS0uLstvt6j//8z+VUkrt2bNHAVDbtm1LrfPqq68qTdPUsWPHhqz3wWpsbFQA1MaNG5VSveOzWq3q+eefT62zd+9eBUBVVVUppXrD32Qyqfr6+tQ6q1atUl6vV0Wj0aEdwCBlZGSof//3fx/V421vb1dFRUVq/fr16m/+5m9SQTYax3zPPfeoqVOnnnHZaByvUkrdcccd6uKLLz7r8qF8/TLUR4uxWAw1NTWoqKhI3WcymVBRUYGqqqph7OzcOHz4MOrr6/uN1+fzoby8PDXeqqoq+P1+zJw5M7VORUUFTCYTtmzZMuQ9D1RraysAIBAIAABqamoQj8f7jXnixIkYO3ZsvzFPnjwZoVAotc68efPQ1taG3bt3D2H3A5dIJLBmzRqcOnUKkUhkVI+3srISCxYs6Dc2YPT+jffv34/c3FyMGzcOixYtSk04PFrH+9JLL2HmzJn41re+hWAwiOnTp+OJJ55ILR/K1y9DBdknn3yCRCLR748NAKFQCPX19cPU1bnTN6a/NN76+noEg8F+yy0WCwKBwIjfJslkErfeeivmzp2L0tJSAL3jsdls8Pv9/db97JjPtE36lo1Eu3btgtvtht1ux80334wXXngBJSUlo3a8a9aswXvvvYcVK1Z8btloHHN5eTlWr16NdevWYdWqVTh8+DC+/OUvo729fVSOFwAOHTqEVatWoaioCK+99hqWLFmC73//+3j66acBDO3r14BmiCaSVFlZidraWrz99tvD3co5N2HCBOzYsQOtra343e9+h8WLF2Pjxo3D3dY5ceTIEfzgBz/A+vXroev6cLczJObPn5/695QpU1BeXo78/Hz89re/hcPhGMbOzp1kMomZM2fiwQcfBABMnz4dtbW1ePzxx7F48eIh7cVQe2RZWVkwm82fO9qnoaEB4XB4mLo6d/rG9JfGGw6H0djY2G95T08PmpubR/Q2Wbp0KdauXYs//vGPyMvLS90fDocRi8XQ0tLSb/3PjvlM26Rv2Uhks9lQWFiIGTNmYMWKFZg6dSp+8YtfjMrx1tTUoLGxEV/60pdgsVhgsViwceNGPProo7BYLAiFQqNuzJ/l9/tx0UUX4cCBA6PybwwAOTk5KCkp6XdfcXFx6iPVoXz9MlSQ2Ww2zJgxAxs2bEjdl0wmsWHDBkQikWHs7NwoKChAOBzuN962tjZs2bIlNd5IJIKWlhbU1NSk1nnzzTeRTCZRXl4+5D3/NUopLF26FC+88ALefPNNFBQU9Fs+Y8YMWK3WfmPet28f6urq+o15165d/Z4A69evh9fr/dwTa6RKJpOIRqOjcryXXnopdu3ahR07dqRuM2fOxKJFi1L/Hm1j/qyOjg4cPHgQOTk5o/JvDABz58793KkzH3zwAfLz8wEM8evXwI9VGV5r1qxRdrtdrV69Wu3Zs0fddNNNyu/39zvax0ja29vV9u3b1fbt2xUA9bOf/Uxt375dffTRR0qp3sNX/X6/evHFF9X777+vrrjiijMevjp9+nS1ZcsW9fbbb6uioqIRe/j9kiVLlM/nU2+99Va/Q5U7OztT69x8881q7Nix6s0331TV1dUqEomoSCSSWt53qPJll12mduzYodatW6eys7NH7KHKd955p9q4caM6fPiwev/999Wdd96pNE1Tr7/+ulJq9I33TD591KJSo2/MP/zhD9Vbb72lDh8+rN555x1VUVGhsrKyVGNjo1Jq9I1Xqd5TKywWi3rggQfU/v371bPPPqucTqd65plnUusM1euX4YJMKaV++ctfqrFjxyqbzabKysrU5s2bh7ulQfvjH/+oAHzutnjxYqVU7yGsP/7xj1UoFFJ2u11deumlat++ff1qNDU1qWuuuUa53W7l9XrV9ddfr9rb24dhNH/dmcYKQD311FOpdbq6utT3vvc9lZGRoZxOp/rmN7+pjh8/3q/Ohx9+qObPn68cDofKyspSP/zhD1U8Hh/i0Xwx3/3ud1V+fr6y2WwqOztbXXrppakQU2r0jfdMPhtko23MV111lcrJyVE2m01dcMEF6qqrrup3PtVoG2+fl19+WZWWliq73a4mTpyofv3rX/dbPlSvX5yPjIiIDM1Q35ERERF9FoOMiIgMjUFGRESGxiAjIiJDY5AREZGhMciIiMjQGGRERGRoDDIiIjI0BhkRERkag4yIiAyNQUZERIb2/wPPbK4XmRCatAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env)\n",
    "# env = MissionEncodingWrapper(env)\n",
    "env = RGBImgObsWrapper(env)\n",
    "\n",
    "print(env.observation_space)\n",
    "env.reset()\n",
    "r = env.render()\n",
    "print(r.shape)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions:\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    FORWARD = 2\n",
    "    PICKUP = 3\n",
    "    DROP = 4\n",
    "    TOGGLE = 5\n",
    "    DONE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIRECTION:\n",
    "Up: 3\n",
    "Left: 2\n",
    "Down: 1\n",
    "Right: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m env \u001b[38;5;241m=\u001b[39m MissionEncodingWrapper(env) \u001b[38;5;66;03m# so that the multidiscrete mission space is 51, accounting for values 0 through 50\u001b[39;00m\n\u001b[1;32m      9\u001b[0m env\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_modes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiInputPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(\u001b[38;5;241m2e5\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m## the problem: ppo requires a gym env to train. but the env observation space is of type gymnasium.spaces. \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:171\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_kl \u001b[38;5;241m=\u001b[39m target_kl\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:174\u001b[0m, in \u001b[0;36mPPO._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range \u001b[38;5;241m=\u001b[39m get_schedule_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:134\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_class \u001b[38;5;241m=\u001b[39m RolloutBuffer\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_class(\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer_kwargs,\n\u001b[1;32m    133\u001b[0m )\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:891\u001b[0m, in \u001b[0;36mMultiInputActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    873\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     optimizer_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    890\u001b[0m ):\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:535\u001b[0m, in \u001b[0;36mActorCriticPolicy.__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Action distribution\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist \u001b[38;5;241m=\u001b[39m make_proba_distribution(action_space, use_sde\u001b[38;5;241m=\u001b[39muse_sde, dist_kwargs\u001b[38;5;241m=\u001b[39mdist_kwargs)\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:634\u001b[0m, in \u001b[0;36mActorCriticPolicy._build\u001b[0;34m(self, lr_schedule)\u001b[0m\n\u001b[1;32m    631\u001b[0m         module\u001b[38;5;241m.\u001b[39mapply(partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_weights, gain\u001b[38;5;241m=\u001b[39mgain))\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Setup optimizer with initial learning rate\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:284\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_current_modes\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_traceback_short\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompilerFn\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3383\u001b[0m\n\u001b[1;32m   3381\u001b[0m \u001b[38;5;66;03m# skip common third party libs\u001b[39;00m\n\u001b[1;32m   3382\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _name \u001b[38;5;129;01min\u001b[39;00m THIRDPARTY_SKIPLIST:\n\u001b[0;32m-> 3383\u001b[0m     \u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3385\u001b[0m _recompile_re()\n\u001b[1;32m   3388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_torch_inline_allowed\u001b[39m(filename):\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3266\u001b[0m, in \u001b[0;36madd\u001b[0;34m(import_name)\u001b[0m\n\u001b[1;32m   3264\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m SKIP_DIRS_RE\n\u001b[1;32m   3265\u001b[0m SKIP_DIRS\u001b[38;5;241m.\u001b[39mappend(_strip_init_py(origin))\n\u001b[0;32m-> 3266\u001b[0m \u001b[43m_recompile_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3249\u001b[0m, in \u001b[0;36m_recompile_re\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recompile_re\u001b[39m():\n\u001b[1;32m   3248\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m SKIP_DIRS_RE\n\u001b[0;32m-> 3249\u001b[0m     SKIP_DIRS_RE \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mescape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mSKIP_DIRS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/__init__.py:228\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[1;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_parser.py:862\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    859\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    861\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 862\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/_parser.py:886\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(subpattern))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    885\u001b[0m     op, av \u001b[38;5;241m=\u001b[39m subpattern[i]\n\u001b[0;32m--> 886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m SUBPATTERN:\n\u001b[1;32m    887\u001b[0m         group, add_flags, del_flags, p \u001b[38;5;241m=\u001b[39m av\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_flags \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m del_flags:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env) # so that the multidiscrete mission space is 51, accounting for values 0 through 50\n",
    "env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(2e5)\n",
    "\n",
    "## the problem: ppo requires a gym env to train. but the env observation space is of type gymnasium.spaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Video of the trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/kai/videos/minigrid-language-2/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import record_videos, show_videos\n",
    "\n",
    "model = PPO.load(\"minigrid_models/minigrid_custom/2\")\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env) \n",
    "env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-2', episode_trigger=lambda e: e % 2 == 0)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 50000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "env.close_video_recorder()\n",
    "env.close()\n",
    "show_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to render image\n",
    "\n",
    "-- good for passing into GPT4 VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "render = env.render()\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "ax.imshow(render) # , cmap=plt.get_cmap('gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from api.settings import Settings\n",
    "\n",
    "openai_client = OpenAI(api_key=Settings().openai_key)\n",
    "\n",
    "def vision(prompt_text: str, img_base64: str):\n",
    "    \"\"\"Run a GPT-4 vision model on the prompt text and image.\n",
    "\n",
    "    ```\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(r)\n",
    "    vision(\"what do you see?\", image_to_base64(im))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{img_base64}\",\n",
    "                        \"detail\": \"low\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the red key from the grey room, unlock the red door and go to the goal'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\") # filler env to get the render\n",
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = '''You are an assistant aiding with subgoal generataion for reinforcement learning problems. Specifically, you will\n",
    "be given an image of an environment and a textual goal description, and you are to output language subgoals that the agent should\n",
    "achieve in order to efficiently and successfully achieve the main goal. These subgoals should be with respect to the image itself:\n",
    "they should specify specific observations that show that the agent is on track. Output a list of ONLY these text subgoals in the following format:\n",
    "\n",
    "- [subgoal 1]\n",
    "- [subgoal 2]\n",
    "- ...\n",
    "\n",
    "where [subgoal i] is replaced by the ith subgoal. You should output 5 (five) subgoals Do not create directional subgoals but rather strategic\n",
    "subgoals that do not hard code the direction but instead tell the agent which states are more beneficial.\n",
    "\n",
    "Here, the main goal description is \n",
    "''' + ob['mission'] + ' where the goal is the light green square.'\n",
    "\n",
    "prompt2 = '''\n",
    "You are an assistant tasked with turning language subgoals into machine readable code. You will be given a text subgoals, and you must translate these subgoals into code that takes in an observation of the format\n",
    "\n",
    "{'direction': Discrete(4), image: np.ndarray}\n",
    "\n",
    "where image is of shape (7x7x3), and the final dimension corresponds to RGB colors. Each 7x7 subarray corresponds to the agent's view. Furthermore, direction corresponds to an enumeration where\n",
    "\n",
    "Up: 3\n",
    "Left: 2\n",
    "Down: 1\n",
    "Right: 0\n",
    "\n",
    "and each image observation is centered such that the agent is facing the entire observation and none of the image observation is behind the agent, and it can only see in front and to the side of itself.\n",
    "\n",
    "Output the subgoal as a python function that takes in the observation and returns a reward function that prioritizes the specific subgoal.\n",
    "This reward function should be dense; it should make the agent want to move closer to the specific subgoal. Have the maximum reward of the function be 0 (where the goal is obtained).\n",
    "You can do this by locating the subgoal in the image observation and using a distance metric to output a dense reward based on it.\n",
    "The code should be the only thing you output, all in one python function without sub functions. Name each function `reward_i` where i is ''' # add i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from api.image import image_to_base64\n",
    "\n",
    "im = Image.fromarray(render)\n",
    "completion1 = vision(prompt1, image_to_base64(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Locate and enter the grey room where the red key is visible.\n",
      "- Acquire the red key found in the grey room.\n",
      "- Identify and approach the red door that can be unlocked with the red key.\n",
      "- Use the red key to unlock the red door.\n",
      "- Move towards and reach the light green square, which is designated as the goal.\n"
     ]
    }
   ],
   "source": [
    "print(completion1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(render)\n",
    "completions = []\n",
    "for i, sg in enumerate(completion1.choices[0].message.content.splitlines()):\n",
    "    completions.append(complete(prompt2 + str(i) + '\\nThe textual subgoal is as follows: ' + sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def reward_0(observation):\n",
      "    direction = observation['direction']\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Define RGB values for red and grey\n",
      "    red_rgb = np.array([255, 0, 0])\n",
      "    grey_rgb = np.array([128, 128, 128])\n",
      "    \n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "    \n",
      "    # Check for presence of red key and grey room\n",
      "    red_key_present = False\n",
      "    grey_room_present = False\n",
      "    \n",
      "    # Calculate the center of the image\n",
      "    center_x, center_y = 3, 3\n",
      "    \n",
      "    # Search for red key and grey room in the image\n",
      "    for i in range(image.shape[0]):\n",
      "        for j in range(image.shape[1]):\n",
      "            # Check if the current pixel is red (key)\n",
      "            if np.array_equal(image[i, j], red_rgb):\n",
      "                red_key_present = True\n",
      "                # Calculate distance to red key from the center\n",
      "                distance_to_key = np.sqrt((center_x - i)**2 + (center_y - j)**2)\n",
      "                # Update reward based on distance to red key\n",
      "                reward -= distance_to_key\n",
      "            \n",
      "            # Check if the current pixel is grey (room)\n",
      "            if np.allclose(image[i, j], grey_rgb, atol=10):\n",
      "                grey_room_present = True\n",
      "                # Calculate distance to grey room from the center\n",
      "                distance_to_room = np.sqrt((center_x - i)**2 + (center_y - j)**2)\n",
      "                # Update reward based on distance to grey room\n",
      "                reward -= distance_to_room\n",
      "    \n",
      "    # Check if both red key and grey room are present\n",
      "    if red_key_present and grey_room_present:\n",
      "        # Additional reward for having both in the view\n",
      "        reward += 10\n",
      "    \n",
      "    return reward\n",
      "import numpy as np\n",
      "\n",
      "def reward_1(observation):\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Define the RGB color for the red key and grey room\n",
      "    red_key_color = np.array([255, 0, 0])  # Pure red\n",
      "    grey_room_color = np.array([128, 128, 128])  # Mid grey\n",
      "    \n",
      "    # Initialize variables to store the closest red key position\n",
      "    min_distance = float('inf')\n",
      "    key_position = None\n",
      "    \n",
      "    # Loop through each pixel in the image\n",
      "    for i in range(image.shape[0]):\n",
      "        for j in range(image.shape[1]):\n",
      "            # Check if the current pixel is grey (part of the room)\n",
      "            if np.allclose(image[i, j], grey_room_color, atol=10):\n",
      "                # If it's grey, check for red key in the vicinity\n",
      "                for di in range(-1, 2):\n",
      "                    for dj in range(-1, 2):\n",
      "                        ni, nj = i + di, j + dj\n",
      "                        if 0 <= ni < image.shape[0] and 0 <= nj < image.shape[1]:\n",
      "                            if np.allclose(image[ni, nj], red_key_color, atol=10):\n",
      "                                # Calculate the distance to the center of the image (3,3)\n",
      "                                distance = np.sqrt((ni - 3)**2 + (nj - 3)**2)\n",
      "                                if distance < min_distance:\n",
      "                                    min_distance = distance\n",
      "                                    key_position = (ni, nj)\n",
      "    \n",
      "    # If a red key was found in the grey room, calculate a negative reward based on distance\n",
      "    if key_position is not None:\n",
      "        # Normalize the distance to provide a reward between -1 and 0\n",
      "        # Maximum distance in a 7x7 grid from center can be sqrt((3-0)^2 + (3-0)^2) = sqrt(18) ≈ 4.24\n",
      "        normalized_distance = min_distance / 4.24\n",
      "        reward = -normalized_distance\n",
      "    else:\n",
      "        # If no key is found, provide the worst possible reward\n",
      "        reward = -1\n",
      "    \n",
      "    return reward\n",
      "def reward_2(observation):\n",
      "    import numpy as np\n",
      "    \n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Define the RGB color for a red door (assuming a specific shade, may need adjustment)\n",
      "    red_door_color = np.array([255, 0, 0])  # Pure red\n",
      "    \n",
      "    # Initialize a high penalty\n",
      "    min_distance = float('inf')\n",
      "    \n",
      "    # Dimensions of the image\n",
      "    height, width, _ = image.shape\n",
      "    \n",
      "    # Center of the image (agent's position)\n",
      "    center_x, center_y = width // 2, height // 2\n",
      "    \n",
      "    # Search for the closest pixel that matches the red door color\n",
      "    for i in range(height):\n",
      "        for j in range(width):\n",
      "            # Calculate the Euclidean distance in RGB space\n",
      "            color_distance = np.linalg.norm(image[i, j] - red_door_color)\n",
      "            \n",
      "            # If the color is close enough to our target red door color\n",
      "            if color_distance < 50:  # Threshold for color matching\n",
      "                # Calculate the Euclidean distance from the center of the image\n",
      "                distance = np.sqrt((center_x - j) ** 2 + (center_y - i) ** 2)\n",
      "                \n",
      "                # Update the minimum distance if this pixel is closer\n",
      "                if distance < min_distance:\n",
      "                    min_distance = distance\n",
      "    \n",
      "    # Reward function based on distance, maximum reward is 0 when distance is 0\n",
      "    reward = -min_distance\n",
      "    \n",
      "    return reward\n",
      "def reward_3(observation):\n",
      "    import numpy as np\n",
      "    \n",
      "    # Define RGB values for red key and red door\n",
      "    red_key_color = np.array([255, 0, 0])  # Pure red\n",
      "    red_door_color = np.array([128, 0, 0])  # Darker red\n",
      "    \n",
      "    image = observation['image']\n",
      "    \n",
      "    # Initialize positions\n",
      "    red_key_position = None\n",
      "    red_door_position = None\n",
      "    \n",
      "    # Search for red key and red door in the image\n",
      "    for i in range(image.shape[0]):\n",
      "        for j in range(image.shape[1]):\n",
      "            if np.array_equal(image[i, j], red_key_color):\n",
      "                red_key_position = np.array([i, j])\n",
      "            elif np.array_equal(image[i, j], red_door_color):\n",
      "                red_door_position = np.array([i, j])\n",
      "    \n",
      "    # Calculate distances to red key and red door\n",
      "    if red_key_position is not None and red_door_position is not None:\n",
      "        # Calculate Euclidean distances\n",
      "        distance_to_red_key = np.linalg.norm(red_key_position - np.array([3, 3]))\n",
      "        distance_to_red_door = np.linalg.norm(red_door_position - np.array([3, 3]))\n",
      "        \n",
      "        # Reward function prioritizes using the red key to unlock the red door\n",
      "        # Reward is more negative the further away the key or door is, with a maximum of 0\n",
      "        reward = -min(distance_to_red_key, distance_to_red_door)\n",
      "    else:\n",
      "        # High penalty if key or door not visible\n",
      "        reward = -10\n",
      "    \n",
      "    return reward\n",
      "def reward_4(observation):\n",
      "    import numpy as np\n",
      "\n",
      "    # Define the RGB color for light green\n",
      "    light_green = np.array([144, 238, 144])\n",
      "\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "\n",
      "    # Initialize the minimum distance to a large number\n",
      "    min_distance = float('inf')\n",
      "\n",
      "    # Dimensions of the image\n",
      "    rows, cols, _ = image.shape\n",
      "\n",
      "    # Center of the image\n",
      "    center_row, center_col = rows // 2, cols // 2\n",
      "\n",
      "    # Iterate over each pixel in the image\n",
      "    for i in range(rows):\n",
      "        for j in range(cols):\n",
      "            # Calculate the RGB distance from the current pixel to light green\n",
      "            color_distance = np.linalg.norm(image[i, j] - light_green)\n",
      "\n",
      "            # If the color matches light green (within a small threshold)\n",
      "            if color_distance < 10:\n",
      "                # Calculate the Euclidean distance from the center to this pixel\n",
      "                distance = np.sqrt((center_row - i) ** 2 + (center_col - j) ** 2)\n",
      "\n",
      "                # Update the minimum distance if this one is closer\n",
      "                if distance < min_distance:\n",
      "                    min_distance = distance\n",
      "\n",
      "    # Normalize the distance to provide a reward between -1 and 0\n",
      "    # Assuming the maximum distance could be diagonal across the image\n",
      "    max_possible_distance = np.sqrt((rows - 1) ** 2 + (cols - 1) ** 2)\n",
      "    normalized_distance = min_distance / max_possible_distance\n",
      "\n",
      "    # Return a negative reward where 0 is the maximum reward (goal reached)\n",
      "    return -normalized_distance\n"
     ]
    }
   ],
   "source": [
    "completion_funcs = [c.choices[0].message.content for c in completions]\n",
    "completion_funcs_execute = ['\\n'.join(c.splitlines()[1:-1]) for c in completion_funcs]\n",
    "for c in completion_funcs_execute:\n",
    "    print(c)\n",
    "    exec(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRewardWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['subgoals_achieved'] = spaces.MultiBinary(5)\n",
    "    def observation(self, obs):\n",
    "        for i, reward_func in enumerate([reward_0, reward_1, reward_2, reward_3, reward_4]):\n",
    "            reward = reward_func(obs)\n",
    "            epsilon = 0.4\n",
    "            if reward > -epsilon:\n",
    "                obs['subgoals_achieved'][i] = 1\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment CustomLockedRoom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "# custom_parking_env.py\n",
    "from typing import Callable\n",
    "\n",
    "from gymnasium.envs.registration import register\n",
    "from minigrid.envs.lockedroom import LockedRoomEnv\n",
    "\n",
    "from gymnasium import spaces\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomMinigridEnv(LockedRoomEnv):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        compute_reward: Callable[[\"CustomMinigridEnv\", spaces.Dict], float],\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.compute_reward_func = compute_reward\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def compute_reward(self, current_state: spaces.Dict) -> float:\n",
    "        return self.compute_reward_func(self, current_state)\n",
    "\n",
    "\n",
    "\n",
    "register( id=\"CustomLockedRoom-v0\", entry_point=CustomMinigridEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.01\n",
    "def generate_total_reward():\n",
    "    current_subgoal = 0\n",
    "    subgoals = [reward_0, reward_1, reward_2, reward_3, reward_4]\n",
    "    def total_reward(obs):\n",
    "        if current_subgoal == 5:\n",
    "            return 1.0\n",
    "\n",
    "        reward = subgoals[current_subgoal](obs)\n",
    "        if reward > -EPSILON:\n",
    "            current_subgoal += 1\n",
    "        \n",
    "        return reward\n",
    "                \n",
    "        # return max(reward(obs) for i, reward in enumerate([reward_0, reward_1, reward_2, reward_3, reward_4]) if i not in achieved_subgoals)\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "env = gymnasium.make(\"CustomLockedRoom-v0\", render_mode = \"rgb_array\", compute_reward = generate_total_reward())\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 195      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00928688 |\n",
      "|    clip_fraction        | 0.041      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | -3.29      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0127     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00384   |\n",
      "|    value_loss           | 0.00218    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010658324 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.0255     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    value_loss           | 0.000299    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009235553 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.199      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00109    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    value_loss           | 0.000192    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013307624 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0984     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00586     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    value_loss           | 0.00013     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105084255 |\n",
      "|    clip_fraction        | 0.092        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.406       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.026       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    value_loss           | 0.000148     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012069732 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.345      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00506    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.000158    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011288409 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -1.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.000168    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02062941 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.86      |\n",
      "|    explained_variance   | -1.65      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0215    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 0.000169   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009837396 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -2.88       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00297    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    value_loss           | 0.000118    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013728492 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -2.9        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00484    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.000129    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134754395 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | -2.12        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0458      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 0.000113     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013526246 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -4.22       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00512     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 8.87e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010527318 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -2.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 9.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014814534 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -5.6        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0173     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000104    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222379 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -4          |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0404     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    value_loss           | 8.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011427425 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -4.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 9.49e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014928962 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -6.4        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00286    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.00016     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017050643 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -2.45       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000101    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016508233 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -4.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00666    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.00013     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017748836 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -5.66       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0283      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 6.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016716488 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -4.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0196     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 6.33e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011536354 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -10.1       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000126    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010488605 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -2.69       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0469     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.000141    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014237249 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -2.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.009       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 8.38e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015267709 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.307      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 8.55e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016311295 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -2.56       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 9.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016323771 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -3.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0344     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 7.3e-05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105150025 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | -0.102       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0202      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 0.000125     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015459258 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -1.02       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 4.36e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 98         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 647        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694106 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | -0.188     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00664   |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 0.000235   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027485168 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -1.75       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00231    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 4.86e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017427888 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -1.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00654    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 4.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012726196 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -3.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    value_loss           | 6.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 737         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012356473 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -2.9        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 5.81e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012868501 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -5.76       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 7.57e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137255555 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | -2.86        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0309      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    value_loss           | 9.98e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014272848 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -3.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00633    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 4.26e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012895158 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -4.78       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.00017     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 852         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013284914 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.989      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 6.01e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012680462 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -1.33       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 4.01e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 894         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014694809 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.0482     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0477     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 6.67e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 914        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00997193 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | -1.82      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0439    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    value_loss           | 3.76e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 935         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017454695 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -3.13       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00345    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 5.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012074364 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.0512     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0202     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 8.3e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 975         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012947259 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -1.99       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.000114    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010390798 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -1.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00808     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 3.73e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014521912 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.796      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 6.53e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1038        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013705411 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.027      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 4.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015371318 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.825      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 6.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017758438 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -2.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 2.63e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013038409 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -1.68       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 2.6e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1127        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021256771 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -4.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0529     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 7.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019321397 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -2.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1171        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013413362 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -3.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0368     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 3.81e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 1192       |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02028982 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | -1.78      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    value_loss           | 1.62e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014700174 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.335      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.26e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966322 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.99       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 2.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1257        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015305914 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.644      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.21e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014533924 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -2.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00295    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 1.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1305        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014118088 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.154      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 3.71e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1327         |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126032075 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | -1.28        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -6.6e-05     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    value_loss           | 5.35e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1351        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015153438 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -1.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.033      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 1.3e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 1373       |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01355609 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | -1.55      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0357    |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 9.77e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1395        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012028048 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -2.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 1.77e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 1418       |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660318 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.44      |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0353    |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 5e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1440        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015687782 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 3.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1461        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013768651 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.415      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 2.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1483        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014389789 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -1.99       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0333     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 2.5e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 1505       |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01130815 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | 0.575      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0321    |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    value_loss           | 2.57e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1528        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013464729 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1552        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012888804 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.683      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0437     |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 1.44e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1575        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013193166 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -1.78       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 6.45e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1599        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012004138 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00277    |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1620         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126285385 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -4.14        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0466      |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0217      |\n",
      "|    value_loss           | 1.5e-05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1644        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009409528 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.569      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0584     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 6.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1668        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011278564 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -2.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.027      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1692        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012913999 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -2.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 1.16e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1715        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011230027 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.664      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 9.47e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1738        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012041518 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -2.92       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.057      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 1.74e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016428726 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.168      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 1.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1788        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020550024 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000986    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 6.17e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1812        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014778762 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.281      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0141     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 7.78e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1845        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856187 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -2.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 8.81e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1875        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018174244 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -1.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 5.88e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1906        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022843082 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.0437     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0357     |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 3.22e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1934        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012866041 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.493      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 5.05e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1960        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012577633 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 5.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1984        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013580281 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.821      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.027      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 5.52e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 2010        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015831875 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.941      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 1.38e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 2038        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014405668 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -3.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 5.54e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 2065        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016743504 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -2.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0369     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 2.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 6988        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029527232 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.819      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000929   |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 2.6e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 7025        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015377983 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.595      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0262     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 5.86e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 7052        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020724189 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -1.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00538    |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 4.59e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 7083        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015113059 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 4.37e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 7109        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016007569 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.788      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 4.24e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 7132        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014782395 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.556      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00668    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 7.02e-06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2852fbb90>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(2e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"minigrid_models/minigrid_custom/4-iterative-subgoals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"CustomLockedRoom-v0\", render_mode = \"rgb_array\", compute_reward = generate_total_reward())\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "model = PPO.load(\"minigrid_models/minigrid_custom/1\")\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
