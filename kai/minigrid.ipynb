{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gym/envs/registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from gymnasium import spaces\n",
    "%matplotlib inline\n",
    "# import gymnasium as gym\n",
    "# from gym.envs.registration import registry, register\n",
    "from minigrid.wrappers import DictObservationSpaceWrapper # so that text mission string is actually a numerical dict\n",
    "\n",
    "# env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode = \"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env) # ONLY DO THIS FOR PPO TRAINING\n",
    "# env.metadata['render_modes'] = [\"rgb_array\"]\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "# import gym\n",
    "import torch\n",
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper, RGBImgObsWrapper, RGBImgPartialObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x1738e75b0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n",
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (56, 56, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x1738e75b0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\")\n",
    "print(env.observation_space)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the wrappers for the environment\n",
    "\n",
    "`MissionEncodingWrapper` adds one for every discrete space in the one-hot encoding of the mission, allowing 0 to be encoded as well.\n",
    "\n",
    "`ImageFeaturesExtractor` extracts relevant features if the observation is just an image, used with `ImgObsWrapper`\n",
    "\n",
    "`MinigridFeaturesExtractor` extracts relevant features from the entire observation, used with `MissionEncodingWrapper` and `DictObservationSpaceWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import ObservationWrapper, RewardWrapper\n",
    "import numpy as np\n",
    "# a custom wrapper to make the mission vector work with one hot encoding\n",
    "class MissionEncodingWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space\n",
    "        self.observation_space['mission'] = spaces.MultiDiscrete(np.array([n+1 for n in env.observation_space['mission'].nvec]))\n",
    "    def observation(self, obs):\n",
    "        return obs\n",
    "    \n",
    "\n",
    "class RewardFunctionWrapper(RewardWrapper):\n",
    "    def __init__(self, env, compute_reward_func):\n",
    "        super().__init__(env)\n",
    "        self.curr_compute_reward = None\n",
    "        self.compute_reward_func = compute_reward_func\n",
    "    \n",
    "    def reset(self, *args, **kwargs) -> None:\n",
    "        ret = self.env.reset(*args, **kwargs)\n",
    "        self.curr_compute_reward = self.compute_reward_func()\n",
    "        return ret\n",
    "\n",
    "    def get_reward(self, obs):\n",
    "        return self.curr_compute_reward(obs)\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = self.env.step(action)\n",
    "        reward = self.curr_compute_reward(obs)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gymnasium.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        direction = observation_space['direction']\n",
    "        image = observation_space['image']\n",
    "        mission_string = observation_space['mission']\n",
    "        n_input_channels = image.shape[0] # should be 3, for RGB\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        direction_output_dim = 8\n",
    "        self.direction_net = nn.Sequential(nn.Linear(direction.n, direction_output_dim), nn.ReLU()) \n",
    "        \n",
    "        \n",
    "        ## add text extractor\n",
    "        self.transformer = nn.Transformer(d_model=len(mission_string), nhead=2, num_encoder_layers=2, num_decoder_layers=2) # squared because of one hot encoding\n",
    "        \n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space['image'].sample()[None]).float()).shape[1] ## 1024 for this example\n",
    "            \n",
    "        self.sentence_transformer_dim = len(mission_string) # is one-hot best here? or should we condense it to 50D vector?\n",
    "            \n",
    "        linear_input_dim = n_flatten + self.sentence_transformer_dim + direction_output_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(linear_input_dim, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        image_features = self.cnn(observations['image']) # .transpose((2, 0, 1)\n",
    "        direction_features = self.direction_net(observations['direction'])\n",
    "        if direction_features.shape[1] == 1:\n",
    "            direction_features = direction_features.squeeze(1)\n",
    "            \n",
    "       \n",
    "        one_hot_mission = observations['mission'].squeeze(0)\n",
    "       \n",
    "        mission_string_encoding = torch.empty((observations['mission'].shape[0], self.sentence_transformer_dim))\n",
    "        \n",
    "        # turn back into labels instead of one hot encoding\n",
    "        for i in range(0, self.sentence_transformer_dim**2, self.sentence_transformer_dim):\n",
    "\n",
    "            if len(one_hot_mission.size()) == 1:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = (torch.argmax(one_hot_mission[i:i+self.sentence_transformer_dim], dim = 0))\n",
    "            else:\n",
    "                mission_string_encoding[:, i//self.sentence_transformer_dim] = torch.argmax(one_hot_mission[:, i:i+self.sentence_transformer_dim], dim = 1)\n",
    "       \n",
    "        src = trg = torch.as_tensor(mission_string_encoding).unsqueeze(0).float()\n",
    "        \n",
    "        sentence_features = self.transformer(src, trg).squeeze(0) # to match dimensions\n",
    "\n",
    "        \n",
    "        try:\n",
    "            observations = torch.cat([image_features, sentence_features, direction_features], dim = 1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"image features dim\", image_features.shape)\n",
    "            print(\"sentence features dim\", sentence_features.shape)\n",
    "            print(\"direction features dim\", direction_features.shape)\n",
    "        return self.linear(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save it. -- also try `FlatObsWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (152, 152, 3), uint8), 'mission': MissionSpace(<function LockedRoomEnv._gen_mission at 0x1738e75b0>, [['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow'], ['blue', 'green', 'grey', 'purple', 'red', 'yellow']]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 608, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1738db790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = DictObservationSpaceWrapper(env)\n",
    "# env = MissionEncodingWrapper(env)\n",
    "env = RGBImgObsWrapper(env)\n",
    "\n",
    "print(env.observation_space)\n",
    "env.reset()\n",
    "r = env.render()\n",
    "print(r.shape)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions:\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    FORWARD = 2\n",
    "    PICKUP = 3\n",
    "    DROP = 4\n",
    "    TOGGLE = 5\n",
    "    DONE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIRECTION:\n",
    "Up: 3\n",
    "Left: 2\n",
    "Down: 1\n",
    "Right: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Video of the trained policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to render image\n",
    "\n",
    "-- good for passing into GPT4 VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "render = env.render()\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "ax.imshow(render) # , cmap=plt.get_cmap('gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from api.settings import Settings\n",
    "\n",
    "openai_client = OpenAI(api_key=Settings().openai_key)\n",
    "\n",
    "def vision(prompt_text: str, img_base64: str):\n",
    "    \"\"\"Run a GPT-4 vision model on the prompt text and image.\n",
    "\n",
    "    ```\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(r)\n",
    "    vision(\"what do you see?\", image_to_base64(im))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{img_base64}\",\n",
    "                        \"detail\": \"low\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def complete(prompt_text: str):\n",
    "    \"\"\"Run a GPT-4 model on the prompt text.\"\"\"\n",
    "    gpt_model = \"gpt-4-turbo\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_parking_env.py\n",
    "from typing import Callable, List\n",
    "\n",
    "from gymnasium.envs.registration import register\n",
    "from minigrid.envs.lockedroom import LockedRoomEnv\n",
    "\n",
    "from gymnasium import spaces\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomMinigridEnv(LockedRoomEnv):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        compute_reward: Callable[[\"CustomMinigridEnv\", spaces.Dict], float],\n",
    "        **kwargs\n",
    "    ):  \n",
    "        self.compute_reward_func = compute_reward\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    # this function is useless\n",
    "    \n",
    "    # def _reward(self) -> float:\n",
    "    #     return self.compute_reward_func(current_state)\n",
    "    \n",
    "    def get_reward(self, obs):\n",
    "        return self.compute_reward_func(obs)\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = super().step(action)\n",
    "        print(\"obs inside:\", obs)\n",
    "        reward = self.compute_reward_func(obs)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "register( id=\"CustomLockedRoom-v0\", entry_point=CustomMinigridEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the grey key from the yellow room, unlock the grey door and go to the goal'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\") # filler env to get the render with filler reward\n",
    "# purposely have alias so that I can change it later\n",
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get the purple key from the blue room, unlock the purple door and go to the goal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob, info = image_env.reset()\n",
    "render = image_env.render()\n",
    "plt.imshow(render)\n",
    "ob['mission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithoutMissionExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return { 'image': observations['image'], 'direction': observations['direction'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = '''You are an assistant aiding with subgoal generataion for reinforcement learning problems. Specifically, you will\n",
    "be given an example environment picture and a textual goal description, and you are to output language subgoals that the agent\n",
    "should achieve in order to efficiently and successfully achieve the main goal.\n",
    "\n",
    "The goal description is:\n",
    "\n",
    "“get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal”\n",
    "\n",
    "where you can use {lockedroom_color}, {keyroom_color}, and {door_color} as variables in the subgoals and the goal is a light green square.\n",
    "The variables can be the values “red”, “green”, “blue”, “purple”, “yellow” or “grey”.\n",
    "\n",
    "These subgoals should be with respect to the image itself:\n",
    "they should specify specific observations that show that the agent is on track. Output a list of ONLY these text subgoals in the following format (without any introduction text):\n",
    "\n",
    "- [subgoal 1]\n",
    "- [subgoal 2]\n",
    "- ...\n",
    "\n",
    "where [subgoal i] is replaced by the ith subgoal. You should output 5 (five) subgoals Do not create directional subgoals but rather strategic\n",
    "subgoals that do not hard code the direction but instead tell the agent which states are more beneficial.\n",
    "\n",
    "Keep in mind that the included image is an example of the environment but the door, key, and goal locations may differ so use it for context but do not\n",
    "hardcode the goals with respect to this specific image.\n",
    "'''\n",
    "\n",
    "prompt2 = '''\n",
    "You are an assistant tasked with turning language subgoals into machine readable code. You will be given text subgoals, and you must translate\n",
    "these subgoals into code that takes in an observation of the format\n",
    "\n",
    "{'direction': Discrete(4), 'image': np.ndarray, 'mission': str}\n",
    "\n",
    "where image is of shape (152x152x3), and the final dimension corresponds to RGB colors.\n",
    "Each 152x152 array corresponds to the entire area of the environment, with the agent represented as a red triangle.\n",
    "The agent can be oriented in 4 directions: 0 (right), 1 (down), 2 (left), 3 (up) and placed anywhere within this region.\n",
    "\n",
    "The text subgoals will include variables {lockedroom_color}, {keyroom_color}, and {door_color}, which can take values \n",
    "“red”, “green”, “blue”, “purple”, “yellow” or “grey”. These colors may not be precise; make sure to account for some error here.\n",
    "I suggest comparing the colors as normalized RGB vectors to prevent brightness from affecting the comparison.\n",
    "The 'mission' key in observation is of form.\n",
    "\n",
    "\n",
    "\n",
    "“get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal”\n",
    "\n",
    "As part of your reward function, you can use these three variables {lockedroom_color}, {keyroom_color}, and {door_color}\n",
    "to determine your specific reward function for the sub goal.\n",
    "\n",
    "The reward function must have parameters: {observation, lockedroom_color, keyroom_color, door_color}.\n",
    "\n",
    "\n",
    "Output the subgoal as a python function that takes in the above parameters and returns the reward that prioritizes the specific subgoal.\n",
    "This reward function should be dense; it should make the agent want to move closer to the specific subgoal. Have the maximum reward of the function be 1 (where the goal is obtained) and the minimum be 0.\n",
    "You can do this by locating the subgoal in the image observation and using a distance metric from the agent to this subgoal location to output a reward based on just that subgoal.\n",
    "The code should be the only thing you output, all in one python function without sub functions. Name each function `reward_i` where i is ''' # add i\n",
    "\n",
    "## Please also insert a couple print statements in each reward functions to show them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from api.image import image_to_base64\n",
    "\n",
    "im = Image.fromarray(render)\n",
    "completion1 = vision(prompt1, image_to_base64(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Locate the {keyroom_color} room where the {lockedroom_color} key is located.\n",
      "- Acquire the {lockedroom_color} key from the {keyroom_color} room.\n",
      "- Navigate to the {door_color} door that requires the {lockedroom_color} key.\n",
      "- Unlock the {door_color} door using the {lockedroom_color} key.\n",
      "- Proceed to the goal area marked by the light green square.\n"
     ]
    }
   ],
   "source": [
    "print(completion1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:05<00:00, 25.07s/it]\n"
     ]
    }
   ],
   "source": [
    "im = Image.fromarray(render)\n",
    "completions = []\n",
    "for i, sg in enumerate(tqdm(completion1.choices[0].message.content.splitlines())):\n",
    "    completions.append(complete(prompt2 + str(i) + '\\nThe textual subgoal is as follows: ' + sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_funcs = [c.choices[0].message.content for c in completions]\n",
    "completion_funcs_execute = ['\\n'.join(c.splitlines()[1:-1]) for c in completion_funcs]\n",
    "for c in completion_funcs_execute:\n",
    "    # print(c)\n",
    "    exec(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mission_to_string(mission_encoding):\n",
    "    indices = [idx - 1 for idx in mission_encoding] # remove offset\n",
    "    translation = {v: k for k, v in DictObservationSpaceWrapper.get_minigrid_words().items()}\n",
    "    translation[-1] = ''\n",
    "    return ' '.join([translation[idx] for idx in indices])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"def reward_0(observation, lockedroom_color, keyroom_color, door_color):\\n    import numpy as np\\n    \\n    # Define color mappings in normalized RGB\\n    color_map = {\\n        'red': np.array([1, 0, 0]),\\n        'green': np.array([0, 1, 0]),\\n        'blue': np.array([0, 0, 1]),\\n        'purple': np.array([0.5, 0, 0.5]),\\n        'yellow': np.array([1, 1, 0]),\\n        'grey': np.array([0.5, 0.5, 0.5])\\n    }\\n    \\n    # Normalize the image array\\n    image = observation['image'].astype(np.float32) / 255.0\\n    target_color = color_map[keyroom_color]\\n    \\n    # Calculate the mean squared error between each pixel and the target color\\n    mse = np.sum((image - target_color) ** 2, axis=2)\\n    \\n    # Find the coordinates of the minimum MSE\\n    target_coords = np.unravel_index(np.argmin(mse), mse.shape)\\n    \\n    # Assume the agent's position is at the center of the image (as a simplification)\\n    agent_position = (76, 76)  # Center of a 152x152 image\\n    \\n    # Calculate the Euclidean distance from the agent to the target\\n    distance = np.sqrt((target_coords[0] - agent_position[0]) ** 2 + (target_coords[1] - agent_position[1]) ** 2)\\n    \\n    # Normalize the distance to be between 0 and 1, where 0 is the farthest possible distance (corner to corner)\\n    max_distance = np.sqrt(2 * 76**2)\\n    normalized_distance = distance / max_distance\\n    \\n    # Reward is inversely proportional to the normalized distance\\n    reward = 1 - normalized_distance\\n    \\n    return reward\", \"def reward_1(observation, lockedroom_color, keyroom_color, door_color):\\n    import numpy as np\\n    \\n    # Define color mapping in normalized RGB\\n    color_map = {\\n        'red': np.array([255, 0, 0]),\\n        'green': np.array([0, 255, 0]),\\n        'blue': np.array([0, 0, 255]),\\n        'purple': np.array([128, 0, 128]),\\n        'yellow': np.array([255, 255, 0]),\\n        'grey': np.array([128, 128, 128])\\n    }\\n    \\n    # Normalize the RGB values to unit vectors\\n    for key in color_map:\\n        color_map[key] = color_map[key] / np.linalg.norm(color_map[key])\\n    \\n    # Extract the image and mission from observation\\n    image = observation['image']\\n    mission = observation['mission']\\n    \\n    # Extract the keyroom color from the mission\\n    keyroom_color_rgb = color_map[keyroom_color]\\n    \\n    # Find the center of the keyroom by averaging the positions of pixels that match the keyroom color\\n    # We use a threshold to determine color matching\\n    threshold = 0.9\\n    keyroom_positions = []\\n    \\n    for i in range(image.shape[0]):\\n        for j in range(image.shape[1]):\\n            pixel = image[i, j]\\n            pixel_norm = pixel / np.linalg.norm(pixel)\\n            similarity = np.dot(pixel_norm, keyroom_color_rgb)\\n            if similarity > threshold:\\n                keyroom_positions.append((i, j))\\n    \\n    if not keyroom_positions:\\n        return 0  # No matching keyroom found, minimal reward\\n    \\n    # Calculate the centroid of the keyroom\\n    keyroom_centroid = np.mean(keyroom_positions, axis=0)\\n    \\n    # Find the agent's position (agent is a red triangle)\\n    agent_color = np.array([255, 0, 0]) / np.linalg.norm([255, 0, 0])\\n    agent_positions = []\\n    \\n    for i in range(image.shape[0]):\\n        for j in range(image.shape[1]):\\n            pixel = image[i, j]\\n            pixel_norm = pixel / np.linalg.norm(pixel)\\n            similarity = np.dot(pixel_norm, agent_color)\\n            if similarity > threshold:\\n                agent_positions.append((i, j))\\n    \\n    if not agent_positions:\\n        return 0  # No agent found, minimal reward\\n    \\n    # Calculate the centroid of the agent's position\\n    agent_centroid = np.mean(agent_positions, axis=0)\\n    \\n    # Compute the Euclidean distance from the agent to the keyroom\\n    distance = np.linalg.norm(agent_centroid - keyroom_centroid)\\n    \\n    # Normalize the distance to a reward (closer is better, maximum distance is the diagonal of the image)\\n    max_distance = np.linalg.norm([152, 152])\\n    reward = 1 - (distance / max_distance)\\n    \\n    return reward\", \"def reward_2(observation, lockedroom_color, keyroom_color, door_color):\\n    import numpy as np\\n\\n    # Define color dictionary with RGB values\\n    color_dict = {\\n        'red': np.array([255, 0, 0]),\\n        'green': np.array([0, 255, 0]),\\n        'blue': np.array([0, 0, 255]),\\n        'purple': np.array([128, 0, 128]),\\n        'yellow': np.array([255, 255, 0]),\\n        'grey': np.array([128, 128, 128])\\n    }\\n\\n    # Normalize the RGB vectors to unit vectors for comparison\\n    for color in color_dict:\\n        color_dict[color] = color_dict[color] / np.linalg.norm(color_dict[color])\\n\\n    # Extract the image and direction from the observation\\n    image = observation['image']\\n    direction = observation['direction']\\n\\n    # Convert image to float and normalize\\n    image_float = image.astype(np.float32)\\n    norms = np.linalg.norm(image_float, axis=2, keepdims=True)\\n    norms[norms == 0] = 1  # to avoid division by zero\\n    image_normalized = image_float / norms\\n\\n    # Target door color normalized\\n    target_color = color_dict[door_color]\\n\\n    # Find the pixels in the image that match the door color\\n    matches = (np.abs(image_normalized - target_color) < 0.1).all(axis=2)\\n\\n    # Check if there are any matches\\n    if not matches.any():\\n        return 0.0  # No door found\\n\\n    # Find the center of the door\\n    door_positions = np.argwhere(matches)\\n    door_center = np.mean(door_positions, axis=0)\\n\\n    # Find the position of the agent (triangle tip based on direction)\\n    agent_position = np.array([76, 76])  # Assuming the agent is centered\\n    if direction == 0:  # right\\n        agent_position += [0, 10]\\n    elif direction == 1:  # down\\n        agent_position += [10, 0]\\n    elif direction == 2:  # left\\n        agent_position -= [0, 10]\\n    elif direction == 3:  # up\\n        agent_position -= [10, 0]\\n\\n    # Calculate the Euclidean distance from the agent to the door\\n    distance = np.linalg.norm(door_center - agent_position)\\n\\n    # Normalize the distance to a reward (closer has higher reward, max distance approx diagonal of image)\\n    max_distance = np.linalg.norm([152, 152])\\n    reward = max(0, 1 - (distance / max_distance))\\n\\n    return reward\", \"def reward_3(observation, lockedroom_color, keyroom_color, door_color):\\n    import numpy as np\\n    \\n    # Define color dictionary with RGB values normalized\\n    color_dict = {\\n        'red': np.array([255, 0, 0]),\\n        'green': np.array([0, 255, 0]),\\n        'blue': np.array([0, 0, 255]),\\n        'purple': np.array([128, 0, 128]),\\n        'yellow': np.array([255, 255, 0]),\\n        'grey': np.array([128, 128, 128])\\n    }\\n    \\n    # Normalize the RGB values to unit vectors\\n    for key in color_dict:\\n        color_dict[key] = color_dict[key] / np.linalg.norm(color_dict[key])\\n    \\n    # Extract the image from the observation\\n    image = observation['image']\\n    \\n    # Convert image to float and normalize\\n    image = image.astype(np.float32)\\n    norms = np.linalg.norm(image, axis=2, keepdims=True)\\n    norms[norms == 0] = 1  # To avoid division by zero\\n    image_normalized = image / norms\\n    \\n    # Define target color for the door and key\\n    door_color_rgb = color_dict[door_color]\\n    lockedroom_color_rgb = color_dict[lockedroom_color]\\n    \\n    # Calculate the Euclidean distance for each pixel to the target colors\\n    door_distance = np.linalg.norm(image_normalized - door_color_rgb, axis=2)\\n    key_distance = np.linalg.norm(image_normalized - lockedroom_color_rgb, axis=2)\\n    \\n    # Find the pixel coordinates with the minimum distance to the target colors\\n    door_location = np.unravel_index(np.argmin(door_distance), door_distance.shape)\\n    key_location = np.unravel_index(np.argmin(key_distance), key_distance.shape)\\n    \\n    # Agent's location (assumed to be the center of the image)\\n    agent_location = (76, 76)  # Center of a 152x152 image\\n    \\n    # Calculate Euclidean distances from the agent to the key and door\\n    distance_to_key = np.sqrt((agent_location[0] - key_location[0])**2 + (agent_location[1] - key_location[1])**2)\\n    distance_to_door = np.sqrt((agent_location[0] - door_location[0])**2 + (agent_location[1] - door_location[1])**2)\\n    \\n    # Normalize distances by the maximum possible distance in the image\\n    max_distance = np.sqrt(2 * (76**2))\\n    normalized_distance_to_key = distance_to_key / max_distance\\n    normalized_distance_to_door = distance_to_door / max_distance\\n    \\n    # Reward function based on the distance to the key and door\\n    # Assuming the agent first needs to get the key and then unlock the door\\n    if normalized_distance_to_key > 0.1:\\n        # Prioritize getting the key\\n        reward = 1 - normalized_distance_to_key\\n    else:\\n        # Once key is obtained, prioritize unlocking the door\\n        reward = 1 - normalized_distance_to_door\\n    \\n    return reward\", \"def reward_4(observation, lockedroom_color, keyroom_color, door_color):\\n    import numpy as np\\n    \\n    # Define the color for the goal area as mentioned in the subgoal\\n    goal_color_rgb = np.array([144, 238, 144]) / 255.0  # Light green in RGB, normalized\\n    \\n    # Extract the image and the agent's direction from the observation\\n    image = observation['image']\\n    \\n    # Normalize the image RGB values\\n    normalized_image = image / 255.0\\n    \\n    # Compute the Euclidean distance of each pixel in the image to the goal color\\n    distance_to_goal_color = np.linalg.norm(normalized_image - goal_color_rgb, axis=2)\\n    \\n    # Find the pixel coordinates that are closest to the goal color\\n    goal_positions = np.where(distance_to_goal_color < 0.1)\\n    \\n    if len(goal_positions[0]) == 0:\\n        # If no goal area is detected, return a reward of 0\\n        return 0\\n    \\n    # Calculate the center of the goal area\\n    goal_center = np.array([np.mean(goal_positions[0]), np.mean(goal_positions[1])])\\n    \\n    # Locate the agent's position (assuming the agent is represented as a red triangle)\\n    # We look for a strong red component, low green and blue components\\n    agent_mask = (image[:, :, 0] > 200) & (image[:, :, 1] < 50) & (image[:, :, 2] < 50)\\n    agent_positions = np.where(agent_mask)\\n    \\n    if len(agent_positions[0]) == 0:\\n        # If no agent is detected, return a reward of 0\\n        return 0\\n    \\n    # Calculate the center of the agent's position\\n    agent_center = np.array([np.mean(agent_positions[0]), np.mean(agent_positions[1])])\\n    \\n    # Calculate the Euclidean distance from the agent to the goal center\\n    distance_to_goal = np.linalg.norm(agent_center - goal_center)\\n    \\n    # Normalize the distance based on the maximum possible distance in the image (diagonal of the image)\\n    max_distance = np.linalg.norm([152, 152])\\n    normalized_distance = distance_to_goal / max_distance\\n    \\n    # Calculate the reward as the inverse of the distance (1 is maximum reward when distance is 0)\\n    reward = 1 - normalized_distance\\n    \\n    return reward\"]\n"
     ]
    }
   ],
   "source": [
    "print(completion_funcs_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def reward_0(observation, lockedroom_color, keyroom_color, door_color):\n",
      "    import numpy as np\n",
      "    \n",
      "    # Define color mappings in normalized RGB\n",
      "    color_map = {\n",
      "        'red': np.array([1, 0, 0]),\n",
      "        'green': np.array([0, 1, 0]),\n",
      "        'blue': np.array([0, 0, 1]),\n",
      "        'purple': np.array([0.5, 0, 0.5]),\n",
      "        'yellow': np.array([1, 1, 0]),\n",
      "        'grey': np.array([0.5, 0.5, 0.5])\n",
      "    }\n",
      "    \n",
      "    # Normalize the image array\n",
      "    image = observation['image'].astype(np.float32) / 255.0\n",
      "    target_color = color_map[keyroom_color]\n",
      "    \n",
      "    # Calculate the mean squared error between each pixel and the target color\n",
      "    mse = np.sum((image - target_color) ** 2, axis=2)\n",
      "    \n",
      "    # Find the coordinates of the minimum MSE\n",
      "    target_coords = np.unravel_index(np.argmin(mse), mse.shape)\n",
      "    \n",
      "    # Assume the agent's position is at the center of the image (as a simplification)\n",
      "    agent_position = (76, 76)  # Center of a 152x152 image\n",
      "    \n",
      "    # Calculate the Euclidean distance from the agent to the target\n",
      "    distance = np.sqrt((target_coords[0] - agent_position[0]) ** 2 + (target_coords[1] - agent_position[1]) ** 2)\n",
      "    \n",
      "    # Normalize the distance to be between 0 and 1, where 0 is the farthest possible distance (corner to corner)\n",
      "    max_distance = np.sqrt(2 * 76**2)\n",
      "    normalized_distance = distance / max_distance\n",
      "    \n",
      "    # Reward is inversely proportional to the normalized distance\n",
      "    reward = 1 - normalized_distance\n",
      "    \n",
      "    return reward\n"
     ]
    }
   ],
   "source": [
    "print(completion_funcs_execute[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "the_image = None\n",
    "\n",
    "def reward_999(observation, lockedroom_color, keyroom_color, door_color):\n",
    "    global the_image\n",
    "    # Extract the image from the observation\n",
    "    image = observation['image']\n",
    "    the_image = image\n",
    "    # print(image)\n",
    "    # print(image.shape)\n",
    "    # raise ValueError\n",
    "    \n",
    "    # Define a simple color mapping in RGB\n",
    "    color_mapping = {\n",
    "        'red': np.array([255, 0, 0]),\n",
    "        'green': np.array([0, 255, 0]),\n",
    "        'blue': np.array([0, 0, 255]),\n",
    "        'purple': np.array([128, 0, 128]),\n",
    "        'yellow': np.array([255, 255, 0]),\n",
    "        'grey': np.array([128, 128, 128])\n",
    "    }\n",
    "    \n",
    "    # Define a tolerance for color matching\n",
    "    tolerance = 30\n",
    "\n",
    "    print(keyroom_color)\n",
    "    \n",
    "    # Get the RGB values for the keyroom color\n",
    "    target_color = color_mapping[keyroom_color]\n",
    "    \n",
    "    # Calculate the mask where the color matches the keyroom color within the tolerance\n",
    "    mask = np.all(np.abs(image - target_color) <= tolerance, axis=-1)\n",
    "\n",
    "    \n",
    "    # Find the centroid of the keyroom color area\n",
    "    y_indices, x_indices = np.where(mask)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        print(\"Keyroom color not found in the image.\")\n",
    "        return 0\n",
    "    \n",
    "    centroid_x = np.mean(x_indices)\n",
    "    centroid_y = np.mean(y_indices)\n",
    "    \n",
    "    # Assume the agent's position is at the center of the image (since we don't have exact position)\n",
    "    agent_x, agent_y = 76, 76  # Center of a 152x152 image\n",
    "    \n",
    "    # Calculate the Euclidean distance from the agent to the centroid of the keyroom\n",
    "    distance = np.sqrt((centroid_x - agent_x) ** 2 + (centroid_y - agent_y) ** 2)\n",
    "    \n",
    "    # Normalize the distance to a reward (closer should have higher reward)\n",
    "    max_distance = np.sqrt(2 * 76**2)  # Maximum possible distance in the image from center\n",
    "    reward = 1 - (distance / max_distance)\n",
    "    \n",
    "    print(f\"Agent is {distance:.2f} pixels away from the centroid of the {keyroom_color} room.\")\n",
    "    print(f\"Reward calculated: {reward:.4f}\")\n",
    "    \n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0.2\n",
    "def generate_total_reward():\n",
    "    goal_number = 0\n",
    "    reward_funcs = [reward_0, reward_1, reward_2, reward_3, reward_4]\n",
    "    def total_reward(obs):\n",
    "        nonlocal goal_number\n",
    "        \n",
    "        # turn obs back into mission string\n",
    "        #obs['mission'] = mission_to_string(obs['mission'])\n",
    "        \n",
    "        # preprocess -- ideally this would be done with LLM if we had more compute\n",
    "        lockedroom_color = obs['mission'].split(' ')[2]\n",
    "        keyroom_color = obs['mission'].split(' ')[6]\n",
    "        door_color = obs['mission'].split(' ')[10]\n",
    "        \n",
    "        reward = reward_funcs[goal_number](obs, lockedroom_color, keyroom_color, door_color)\n",
    "        # print(\"current goal number\", goal_number)\n",
    "        # print(f\"goal: {goal_number} | reward:{reward}\")\n",
    "\n",
    "        if reward > 1-EPSILON:\n",
    "            print(f\"switching functions from {goal_number} to {goal_number + 1}\")\n",
    "            goal_number += 1\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-LockedRoom-v0\", render_mode=\"rgb_array\")\n",
    "# env = RGBImgPartialObsWrapper(env) # convert to RGB obs\n",
    "env = RGBImgObsWrapper(env) # convert to RGB obs\n",
    "env = RewardFunctionWrapper(env, compute_reward_func = generate_total_reward)\n",
    "\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "\n",
    "env = MissionEncodingWrapper(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# print(env.step)\n",
    "# obs, reward, done, truncated, info = env.step(0)\n",
    "# plt.imshow(obs['image'])\n",
    "# print(env.unwrapped.agent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(the_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:33: RuntimeWarning: invalid value encountered in divide\n",
      "<string>:51: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 197      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 72.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034948788 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00307      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.95        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    value_loss           | 4.66         |\n",
      "------------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 79.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 36           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047431607 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.275       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.869        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 6.76         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 83.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005790093 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.344      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 5.79        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 85.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004765308 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.976      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    value_loss           | 4.31        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 89.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 30           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 400          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071164295 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -1.35        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00956     |\n",
      "|    value_loss           | 2.03         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 3 to 4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008220008 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.0773      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -1.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 88.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011124709 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -1.56       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.728       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 88.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009387101 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -1.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 87.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012471858 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.027       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -1.72       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/kai/videos/minigrid-language-8/rl-video-episode-0.mp4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:33: RuntimeWarning: invalid value encountered in divide\n",
      "<string>:51: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m video_env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     15\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[1;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/stable_baselines3/common/policies.py:717\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    710\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/stable_baselines3/common/policies.py:751\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03mGet the current policy distribution given the observations.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m:param obs:\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m:return: the action distribution.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi_features_extractor)\n\u001b[0;32m--> 751\u001b[0m latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/stable_baselines3/common/torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/torch/nn/modules/module.py:1508\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, ent_coef=0.9)\n",
    "\n",
    "model.learn(2e4)\n",
    "model.save(\"minigrid_models/minigrid_custom/8-iterative-subgoals-generalized\")\n",
    "\n",
    "video_env = gymnasium.wrappers.RecordVideo(env, 'videos/minigrid-language-8', episode_trigger=lambda e: e % 2 == 0)\n",
    "\n",
    "obs, info = video_env.reset()\n",
    "done = False\n",
    "video_env.start_video_recorder()\n",
    "steps = 0\n",
    "while not done and steps <= 50000:\n",
    "    action = model.predict(obs)[0]\n",
    "    obs, reward, done, truncated, info = video_env.step(action)\n",
    "    steps += 1\n",
    "video_env.close_video_recorder()\n",
    "video_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Users/kmcclenn/Documents/Class notes/6.8200/final_project/language-reward-design/.venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make(\"CustomLockedRoom-v0\", render_mode = \"rgb_array\", compute_reward = generate_total_reward())\n",
    "env = DictObservationSpaceWrapper(env)\n",
    "env = MissionEncodingWrapper(env)\n",
    "model = PPO.load(\"minigrid_models/minigrid_custom/1\")\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
