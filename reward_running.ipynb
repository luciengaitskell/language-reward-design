{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatreward.minigrid.complete import build_reward_funcs, build_text_subgoals\n",
    "from chatreward.minigrid.env import create_env, Actions, COLOR_TO_IDX, RGBImgPartialObsWrapper\n",
    "from chatreward.ppo import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload please\n",
      "- Be in front of the {keyroom_color} door.\n",
      "- Toggle the {keyroom_color} door to open it.\n",
      "- Enter the {keyroom_color} room.\n",
      "- Pick up the {lockedroom_color} key.\n",
      "- Exit the {keyroom_color} room.\n",
      "- Be in front of the {lockedroom_color} door.\n",
      "- Toggle the {lockedroom_color} door to open it.\n",
      "- Enter the {lockedroom_color} room.\n",
      "- Be in front of the {door_color} door.\n",
      "- Toggle the {door_color} door to open it.\n",
      "- Enter the {door_color} room.\n",
      "- Move to the goal location.\n"
     ]
    }
   ],
   "source": [
    "quick_env = create_env()\n",
    "quick_env.reset()\n",
    "render = quick_env.render()\n",
    "\n",
    "subgoals = build_text_subgoals(render)\n",
    "print(\"\\n\".join(subgoals.choices[0].message.content.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New reward function: 0A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to position itself in front of the door of the color specified by `keyroom_color`.\n",
      "    The agent receives a higher reward when it is directly in front of the door of the correct color and the door is closed or locked.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: the action taken by the agent, an integer from 0 to 6.\n",
      "    - lockedroom_color: integer representing the color of the locked room.\n",
      "    - keyroom_color: integer representing the color of the key room.\n",
      "    - door_color: integer representing the color of the door to unlock.\n",
      "    \n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1, where 1 is the maximum reward when the agent is in front of the correct door.\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "    \n",
      "    # Position right in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Check if the position in front of the agent is within bounds\n",
      "    if front_y >= 0:\n",
      "        front_object, front_color, front_state = image[front_x, front_y]\n",
      "        \n",
      "        # Check if the object in front is a door and has the color of the keyroom\n",
      "        if front_object == 4 and front_color == keyroom_color:\n",
      "            # Check if the door is either closed or locked\n",
      "            if front_state in [1, 2]:\n",
      "                return 1.0  # Maximum reward when in front of the correct door and it's not open\n",
      "    \n",
      "    # Penalize slightly for not being in front of the correct door\n",
      "    return 0.0\n",
      "New reward function: 1A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function incentivizes the agent to toggle open the door of the {keyroom_color} room.\n",
      "    The agent receives a reward based on its proximity to the target door and the action of toggling it open.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the agent's action.\n",
      "    - lockedroom_color: integer, not used directly in this subgoal.\n",
      "    - keyroom_color: integer representing the color index of the keyroom door.\n",
      "    - door_color: integer, not used directly in this subgoal.\n",
      "    \n",
      "    Returns:\n",
      "    - float: a reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "    \n",
      "    # Position right in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Check the object, color, and state of the position right in front of the agent\n",
      "    front_object, front_color, front_state = image[front_x, front_y]\n",
      "    \n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "    \n",
      "    # Check if the object in front is a door and matches the keyroom color\n",
      "    if front_object == 4 and front_color == keyroom_color:\n",
      "        # Check the state of the door\n",
      "        if front_state == 1:  # Closed\n",
      "            if action == 5:  # Toggle/activate action\n",
      "                reward = 1  # Maximum reward for opening the correct door\n",
      "            else:\n",
      "                reward = 0.5  # Encourage being in front of the door but not toggling\n",
      "        elif front_state == 0:  # Already open\n",
      "            reward = 0.1  # Small reward for being in front of an already open door\n",
      "    else:\n",
      "        # Penalize being in front of the wrong door or not a door\n",
      "        reward = 0\n",
      "    \n",
      "    return reward\n",
      "New reward function: 2A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    Reward function for the subgoal of entering the room with the color corresponding to `keyroom_color`.\n",
      "    The function provides a higher reward for actions that move the agent closer to the door of the keyroom_color\n",
      "    and for actions that open or unlock the door if it is closed or locked.\n",
      "\n",
      "    Parameters:\n",
      "    - observation: dict containing 'direction', 'image', and 'mission'\n",
      "    - action: int, the action taken by the agent\n",
      "    - lockedroom_color: int, the color index of the locked room\n",
      "    - keyroom_color: int, the color index of the room where the key is located\n",
      "    - door_color: int, the color index of the door that needs to be unlocked\n",
      "\n",
      "    Returns:\n",
      "    - float, the reward for the action taken in the context of the current observation\n",
      "    \"\"\"\n",
      "    image = observation['image']\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1  # Agent is always at the bottom center of the image\n",
      "\n",
      "    # Check the space in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "\n",
      "    # Extract object, color, and state from the image at the position in front of the agent\n",
      "    object_in_front, color_in_front, state_in_front = image[front_x, front_y]\n",
      "\n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "\n",
      "    # Check if the agent is facing a door of the keyroom_color\n",
      "    if object_in_front == 4 and color_in_front == keyroom_color:  # 4 corresponds to 'door'\n",
      "        if state_in_front == 1 or state_in_front == 2:  # 1: 'closed', 2: 'locked'\n",
      "            if action == 5:  # Action to toggle/activate (open/unlock) the door\n",
      "                reward = 1  # Max reward for opening/unlocking the door\n",
      "        elif state_in_front == 0:  # 0: 'open'\n",
      "            if action == 2:  # Action to move forward (enter the room)\n",
      "                reward = 1  # Max reward for entering the room\n",
      "\n",
      "    # Encourage the agent to move towards the door if not already in front of it\n",
      "    if object_in_front != 4 or color_in_front != keyroom_color:\n",
      "        # Penalize all actions except moving forward when not facing the correct door\n",
      "        if action == 2:\n",
      "            reward = 0.5  # Reward for moving forward, potentially towards the door\n",
      "        else:\n",
      "            reward = 0.1  # Small reward to encourage exploration\n",
      "\n",
      "    return reward\n",
      "New reward function: 3A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function is designed to encourage the agent to pick up the key of the color corresponding to the locked room.\n",
      "    The agent receives a higher reward for being adjacent to the key and performing the 'pick up' action.\n",
      "    The reward is maximized when the agent successfully picks up the correct key.\n",
      "\n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the agent's action.\n",
      "    - lockedroom_color: integer representing the color index of the locked room's key.\n",
      "    - keyroom_color: integer not used in this subgoal.\n",
      "    - door_color: integer not used in this subgoal.\n",
      "\n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Constants\n",
      "    KEY_OBJECT_IDX = 5\n",
      "    PICK_UP_ACTION = 3\n",
      "\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "\n",
      "    # Check the space right in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "\n",
      "    # Get the object, color, and state of the object right in front of the agent\n",
      "    object_idx, color_idx, _ = image[front_x, front_y]\n",
      "\n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "\n",
      "    # Check if the agent is in front of the correct key\n",
      "    if object_idx == KEY_OBJECT_IDX and color_idx == lockedroom_color:\n",
      "        # Encourage the agent to pick up the key\n",
      "        if action == PICK_UP_ACTION:\n",
      "            reward = 1  # Max reward for picking up the correct key\n",
      "\n",
      "    return reward\n",
      "New reward function: 4A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to exit the room of the color specified by `keyroom_color`.\n",
      "    The agent receives a higher reward for moving towards and through a door that is not locked and matches the `keyroom_color`.\n",
      "    The function checks the space in front of the agent for a door of the correct color and state.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: A dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: An integer representing the agent's action.\n",
      "    - lockedroom_color: Integer representing the color index of the locked room.\n",
      "    - keyroom_color: Integer representing the color index of the key room.\n",
      "    - door_color: Integer representing the color index of the door to unlock.\n",
      "    \n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Constants\n",
      "    DOOR_IDX = 4\n",
      "    OPEN_STATE = 0\n",
      "    CLOSED_STATE = 1\n",
      "    LOCKED_STATE = 2\n",
      "    \n",
      "    # Extract the image and agent's position\n",
      "    img = observation['image']\n",
      "    agent_x = img.shape[1] // 2\n",
      "    agent_y = img.shape[0] - 1\n",
      "    \n",
      "    # Check the space in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Ensure the front coordinates are within the image bounds\n",
      "    if front_y >= 0:\n",
      "        front_object = img[front_y, front_x]\n",
      "        object_type, color_idx, state = front_object\n",
      "        \n",
      "        # Check if the front object is a door of the correct color and not locked\n",
      "        if object_type == DOOR_IDX and color_idx == keyroom_color and state != LOCKED_STATE:\n",
      "            # Reward for being in front of the correct door\n",
      "            if action == 5:  # toggle/activate object\n",
      "                return 1.0  # Maximum reward for opening the door\n",
      "            else:\n",
      "                return 0.5  # Encourage staying near the door\n",
      "        else:\n",
      "            return 0.1  # Small reward for moving around, looking for the door\n",
      "    else:\n",
      "        return 0.0  # No reward if looking out of bounds\n",
      "New reward function: 5A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    Reward function for the subgoal of being in front of the locked door of a specific color.\n",
      "    \n",
      "    The function checks if the agent is directly in front of a door of the specified lockedroom_color.\n",
      "    The reward is 1 if the agent is in front of the correct colored locked door, otherwise it is 0.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: dict with keys 'direction', 'image', and 'mission'\n",
      "    - action: int, the action taken by the agent\n",
      "    - lockedroom_color: int, the color index of the locked room's door\n",
      "    - keyroom_color: int, the color index of the room containing the key (not used in this function)\n",
      "    - door_color: int, the color index of the door to unlock (not used in this function)\n",
      "    \n",
      "    Returns:\n",
      "    - float, the reward for the current state and action\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "    \n",
      "    # Position directly in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Check if the position in front of the agent is within the image bounds\n",
      "    if front_y >= 0:\n",
      "        # Get the object, color, and state of the position in front of the agent\n",
      "        object_idx, color_idx, state_idx = image[front_x, front_y]\n",
      "        \n",
      "        # Check if it's a door of the correct color and is locked\n",
      "        if object_idx == 4 and color_idx == lockedroom_color and state_idx == 2:\n",
      "            return 1.0  # Maximum reward when in front of the correct locked door\n",
      "    \n",
      "    # Default reward if not in front of the correct locked door\n",
      "    return 0.0\n",
      "New reward function: 6A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function is designed to encourage the agent to toggle open a door of a specific color (lockedroom_color).\n",
      "    The agent receives a reward based on its proximity and interaction with the door of the specified color.\n",
      "    The maximum reward is given when the agent successfully toggles the door to an open state.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the action taken by the agent.\n",
      "    - lockedroom_color: integer representing the color index of the locked room's door.\n",
      "    - keyroom_color: integer representing the color index of the key room (not used in this subgoal).\n",
      "    - door_color: integer representing the color index of the door to unlock (not used in this subgoal).\n",
      "    \n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "    \n",
      "    # Check the space right in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Get the object, color, and state of the position in front of the agent\n",
      "    object_idx, color_idx, state = image[front_x, front_y]\n",
      "    \n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "    \n",
      "    # Check if the agent is facing a door of the correct color and it's locked or closed\n",
      "    if object_idx == 4 and color_idx == lockedroom_color and (state == 1 or state == 2):\n",
      "        # Increase reward for being in front of the correct door\n",
      "        reward += 0.5\n",
      "        \n",
      "        # Check if the action is to toggle/activate an object\n",
      "        if action == 5:\n",
      "            # Check if the door state changes to open\n",
      "            if state == 0:\n",
      "                # Maximum reward for opening the door\n",
      "                reward = 1\n",
      "            else:\n",
      "                # Reward for attempting to toggle the door\n",
      "                reward += 0.5\n",
      "    \n",
      "    return reward\n",
      "New reward function: 7A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to enter the room of a specific color, identified by `lockedroom_color`.\n",
      "    The reward is higher when the agent is closer to a door of the `lockedroom_color` that is open, and maximizes when the agent enters the room.\n",
      "\n",
      "    Parameters:\n",
      "    - observation: dict containing 'direction', 'image', and 'mission'\n",
      "    - action: int, the action taken by the agent\n",
      "    - lockedroom_color: int, the color index of the locked room the agent needs to enter\n",
      "    - keyroom_color: int, the color index of the room containing the key (not used in this subgoal)\n",
      "    - door_color: int, the color index of the door to unlock (not used in this subgoal)\n",
      "\n",
      "    Returns:\n",
      "    - float, the reward for the current state and action, ranging from 0 to 1\n",
      "    \"\"\"\n",
      "    image = observation['image']\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1  # Agent is always at the bottom center of the image\n",
      "\n",
      "    # Check the space directly in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "\n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "\n",
      "    # Check if the front cell is a door of the correct color and is open\n",
      "    if front_y >= 0:\n",
      "        front_cell = image[front_x, front_y]\n",
      "        if front_cell[0] == 4 and front_cell[1] == lockedroom_color and front_cell[2] == 0:\n",
      "            # Front cell is an open door of the locked room color\n",
      "            reward = 1.0\n",
      "\n",
      "    # Encourage moving forward if facing an open door of the correct color\n",
      "    if action == 2 and reward == 1.0:\n",
      "        reward += 0.1  # Small incentive to actually move through the door\n",
      "\n",
      "    return reward\n",
      "New reward function: 8A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function incentivizes the agent to be positioned directly in front of a door of the specified `door_color`.\n",
      "    The agent receives a high reward when directly in front of the door, and a smaller reward based on proximity to the door otherwise.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the action taken by the agent.\n",
      "    - lockedroom_color: integer representing the color index of the locked room (not used in this subgoal).\n",
      "    - keyroom_color: integer representing the color index of the key room (not used in this subgoal).\n",
      "    - door_color: integer representing the color index of the door the agent needs to be in front of.\n",
      "    \n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Constants for object and state indices\n",
      "    OBJECT_IDX = 0\n",
      "    COLOR_IDX = 1\n",
      "    STATE_IDX = 2\n",
      "    \n",
      "    # Constants for object types and states\n",
      "    DOOR = 4\n",
      "    CLOSED = 1\n",
      "    \n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    \n",
      "    # Agent's position in the image\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1\n",
      "    \n",
      "    # Position directly in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Check if the position in front of the agent is within bounds\n",
      "    if front_y >= 0:\n",
      "        front_object = image[front_x, front_y]\n",
      "        \n",
      "        # Check if the object in front is a door of the correct color and is closed\n",
      "        if front_object[OBJECT_IDX] == DOOR and front_object[COLOR_IDX] == door_color and front_object[STATE_IDX] == CLOSED:\n",
      "            # Maximum reward if directly in front of the correct closed door\n",
      "            return 1.0\n",
      "    \n",
      "    # Compute a proximity-based reward if not directly in front of the door\n",
      "    # Initialize minimum distance to a large number\n",
      "    min_distance = float('inf')\n",
      "    \n",
      "    # Iterate over all positions in the image to find the closest door of the correct color and state\n",
      "    for x in range(image.shape[0]):\n",
      "        for y in range(image.shape[1]):\n",
      "            if image[x, y][OBJECT_IDX] == DOOR and image[x, y][COLOR_IDX] == door_color and image[x, y][STATE_IDX] == CLOSED:\n",
      "                # Calculate Manhattan distance to the door\n",
      "                distance = abs(x - agent_x) + abs(y - agent_y)\n",
      "                if distance < min_distance:\n",
      "                    min_distance = distance\n",
      "    \n",
      "    # Normalize the distance to provide a reward between 0 and 1\n",
      "    # Assuming the maximum distance could be the diagonal of the image\n",
      "    max_possible_distance = np.sqrt(image.shape[0]**2 + image.shape[1]**2)\n",
      "    normalized_distance = min_distance / max_possible_distance\n",
      "    \n",
      "    # Invert the normalized distance to make the reward higher when closer to the door\n",
      "    proximity_reward = 1 - normalized_distance\n",
      "    \n",
      "    return proximity_reward\n",
      "New reward function: 9A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to toggle the door of a specified color to open it.\n",
      "    The agent receives a higher reward for being adjacent to a closed or locked door of the specified color\n",
      "    and performing the toggle action. The reward is maximized when the door is successfully toggled open.\n",
      "    \n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the agent's action.\n",
      "    - lockedroom_color: integer, not used in this specific subgoal.\n",
      "    - keyroom_color: integer, not used in this specific subgoal.\n",
      "    - door_color: integer representing the color of the door to be toggled open.\n",
      "    \n",
      "    Returns:\n",
      "    - A float reward value between 0 and 1.\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[1] // 2\n",
      "    agent_y = image.shape[0] - 1\n",
      "    \n",
      "    # Check the space in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Get the object, color, and state of the tile in front of the agent\n",
      "    object_idx, color_idx, state = image[front_y, front_x]\n",
      "    \n",
      "    # Initialize reward\n",
      "    reward = 0\n",
      "    \n",
      "    # Check if the front tile is a door of the specified color\n",
      "    if object_idx == 4 and color_idx == door_color:\n",
      "        # Check if the door is closed or locked\n",
      "        if state in [1, 2]:  # 1: closed, 2: locked\n",
      "            # Check if the action is to toggle/activate an object\n",
      "            if action == 5:\n",
      "                # Provide a high reward for toggling the correct door\n",
      "                reward = 1\n",
      "            else:\n",
      "                # Small reward for being in the correct position but not toggling\n",
      "                reward = 0.1\n",
      "        elif state == 0:  # 0: open\n",
      "            # Provide a small reward if the door is already open\n",
      "            reward = 0.5\n",
      "    else:\n",
      "        # Penalize slightly for not being in front of the correct door\n",
      "        reward = 0\n",
      "    \n",
      "    return reward\n",
      "New reward function: 10A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to enter the room with the door of specified `door_color`.\n",
      "    The agent receives a higher reward for being adjacent to a closed or locked door of the correct color and\n",
      "    performing the toggle action (5) to open it. The reward increases as the agent approaches the door and\n",
      "    maximizes when the agent successfully opens the door.\n",
      "\n",
      "    Parameters:\n",
      "    - observation: dict with keys 'direction', 'image', and 'mission'.\n",
      "    - action: int, the action taken by the agent.\n",
      "    - lockedroom_color: int, color index of the locked room.\n",
      "    - keyroom_color: int, color index of the key room.\n",
      "    - door_color: int, color index of the door the agent needs to enter.\n",
      "\n",
      "    Returns:\n",
      "    - float, the reward for the current action and state, ranging from 0 to 1.\n",
      "    \"\"\"\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    # Agent's position is at the bottom center of the image\n",
      "    agent_x = image.shape[1] // 2\n",
      "    agent_y = image.shape[0] - 1\n",
      "    \n",
      "    # Check the space in front of the agent\n",
      "    front_x = agent_x\n",
      "    front_y = agent_y - 1\n",
      "    \n",
      "    # Get the object, color, and state of the object in front of the agent\n",
      "    front_object, front_color, front_state = image[front_y, front_x]\n",
      "    \n",
      "    # Initialize the reward\n",
      "    reward = 0\n",
      "    \n",
      "    # Check if the front object is a door of the correct color\n",
      "    if front_object == 4 and front_color == door_color:\n",
      "        # Check the state of the door\n",
      "        if front_state == 1:  # closed\n",
      "            # Reward for being in front of the correct closed door\n",
      "            reward += 0.5\n",
      "            # Additional reward for opening the door\n",
      "            if action == 5:\n",
      "                reward += 0.5\n",
      "        elif front_state == 2:  # locked\n",
      "            # Slightly lower reward for being in front of a locked door\n",
      "            reward += 0.3\n",
      "            # No additional reward for trying to open a locked door\n",
      "        elif front_state == 0:  # open\n",
      "            # Highest reward for having the door already open\n",
      "            reward += 0.8\n",
      "            # Encourage the agent to move forward into the room\n",
      "            if action == 2:\n",
      "                reward += 0.2\n",
      "    \n",
      "    return reward\n",
      "New reward function: 11A\n",
      "import numpy as np\n",
      "\n",
      "def reward(observation, action, lockedroom_color, keyroom_color, door_color):\n",
      "    \"\"\"\n",
      "    This reward function encourages the agent to move towards the goal location.\n",
      "    The goal is assumed to be represented by a specific object type in the observation image.\n",
      "    The reward is higher when the agent is closer to the goal and reaches its maximum when the agent is at the goal.\n",
      "\n",
      "    Parameters:\n",
      "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
      "    - action: an integer representing the action taken by the agent.\n",
      "    - lockedroom_color: integer, not used in this specific subgoal.\n",
      "    - keyroom_color: integer, not used in this specific subgoal.\n",
      "    - door_color: integer, not used in this specific subgoal.\n",
      "\n",
      "    Returns:\n",
      "    - A float representing the reward, where 0 is the minimum and 1 is the maximum when the goal is reached.\n",
      "    \"\"\"\n",
      "    # Constants for object types and states\n",
      "    GOAL_OBJECT_IDX = 3  # Assuming 'floor' represents the goal location for simplicity\n",
      "\n",
      "    # Extract the image from the observation\n",
      "    image = observation['image']\n",
      "    agent_x = image.shape[0] // 2\n",
      "    agent_y = image.shape[1] - 1  # Agent is always at the bottom center of the image\n",
      "\n",
      "    # Find the goal location in the image\n",
      "    goal_positions = np.argwhere(image[:, :, 0] == GOAL_OBJECT_IDX)\n",
      "\n",
      "    # If there's no goal in the image, return minimal reward\n",
      "    if goal_positions.size == 0:\n",
      "        return 0.0\n",
      "\n",
      "    # Calculate the distance to the closest goal position\n",
      "    distances = np.sqrt((goal_positions[:, 0] - agent_x) ** 2 + (goal_positions[:, 1] - agent_y) ** 2)\n",
      "    min_distance = np.min(distances)\n",
      "\n",
      "    # Normalize the distance to provide a reward between 0 and 1\n",
      "    max_distance = np.sqrt((image.shape[0] - 1) ** 2 + (image.shape[1] - 1) ** 2)\n",
      "    normalized_distance = min_distance / max_distance\n",
      "\n",
      "    # Reward is higher when the distance is smaller\n",
      "    reward = 1 - normalized_distance\n",
      "\n",
      "    return reward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_suffixes = 1\n",
    "suffixes = list(map(chr, range(65, 65+num_suffixes))) # [\"A\", \"B\", \"C\"]\n",
    "\n",
    "reward_funcs = build_reward_funcs(subgoals, suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reward_demo(observation, action, lockedroom_color, keyroom_color, door_color):\n",
    "    \"\"\"\n",
    "    This reward function encourages the agent to position itself in front of the door of the color specified by `keyroom_color`.\n",
    "    The agent receives a higher reward when it is directly in front of the door of the correct color and the door is closed or locked.\n",
    "    \n",
    "    Parameters:\n",
    "    - observation: a dictionary containing 'direction', 'image', and 'mission'.\n",
    "    - action: the action taken by the agent, an integer from 0 to 6.\n",
    "    - lockedroom_color: integer representing the color of the locked room.\n",
    "    - keyroom_color: integer representing the color of the key room.\n",
    "    - door_color: integer representing the color of the door to unlock.\n",
    "    \n",
    "    Returns:\n",
    "    - A float reward value between 0 and 1, where 1 is the maximum reward when the agent is in front of the correct door.\n",
    "    \"\"\"\n",
    "    # Extract the image from the observation\n",
    "    image = observation['image']\n",
    "    # Agent's position is at the bottom center of the image\n",
    "    agent_x = image.shape[0] // 2\n",
    "    agent_y = image.shape[1] - 1\n",
    "    \n",
    "    # Position right in front of the agent\n",
    "    front_x = agent_x\n",
    "    front_y = agent_y - 1\n",
    "    \n",
    "    # Check if the position in front of the agent is within bounds\n",
    "    if front_y >= 0:\n",
    "        front_object, front_color, front_state = image[front_x, front_y]\n",
    "        \n",
    "        # Check if the object in front is a door and has the color of the keyroom\n",
    "        if front_object == 4 and front_color == keyroom_color:\n",
    "            # Check if the door is either closed or locked\n",
    "            if front_state in [1, 2]:\n",
    "                return 1.0  # Maximum reward when in front of the correct door and it's not open\n",
    "    \n",
    "    # Penalize slightly for not being in front of the correct door\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14f033d60>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_env = create_env(rgb_support=False, farama_support=False)\n",
    "obs, _ = quick_env.reset()\n",
    "\n",
    "plt.imshow(quick_env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the blue key from the purple room, unlock the blue door and go to the goal\n"
     ]
    }
   ],
   "source": [
    "lockedroom_color = COLOR_TO_IDX[obs[\"mission\"].split(\" \")[2]]\n",
    "keyroom_color = COLOR_TO_IDX[obs[\"mission\"].split(\" \")[6]]\n",
    "door_color = COLOR_TO_IDX[obs[\"mission\"].split(\" \")[10]]\n",
    "\n",
    "print(obs['mission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action = Actions.FORWARD\n",
    "prev_obs = obs\n",
    "obs, reward, done, _, info = quick_env.step(action)\n",
    "\n",
    "plt.imshow(quick_env.render())\n",
    "\n",
    "## Reward:\n",
    "reward_funcs[0]['A'](prev_obs, action, lockedroom_color, keyroom_color, door_color)\n",
    "# reward_demo(prev_obs, action, lockedroom_color, keyroom_color, door_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [4, 0, 1],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 5, 0],\n",
       "         [2, 5, 0]]], dtype=uint8),\n",
       " 'direction': 2,\n",
       " 'mission': 'get the grey key from the red room, unlock the grey door and go to the goal'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 10.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 710      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 8.32         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067238146 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00794      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 7.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074516702 |\n",
      "|    clip_fraction        | 0.0766       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.219       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.587       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 0.314        |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863935 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0313     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008108702 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 7.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 180          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114707975 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.0716      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.293       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00912     |\n",
      "|    value_loss           | 0.713        |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 7.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 177          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067043453 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.027       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.515       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    value_loss           | 0.807        |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 175         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007839418 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.0492     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    value_loss           | 0.756       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253554 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.61       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.0746      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009718226 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.162      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.529      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 8            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 169          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076308213 |\n",
      "|    clip_fraction        | 0.0719       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.495       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00775     |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 168         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009358088 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0652     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.96        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010295901 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.812       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535214 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505686 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.512      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009081521 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0182      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00972     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 10.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00906076 |\n",
      "|    clip_fraction        | 0.0846     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.688      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00852   |\n",
      "|    value_loss           | 2.55       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007149433 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.203      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 4.04        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010527227 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 11.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 145        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01021423 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | -0.973     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.484     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 0.591      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011646649 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0974     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.86        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013068072 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.396      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012621951 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009320008 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0292     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 4.92        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011737471 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00374     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013714967 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.525      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0555     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016350023 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0606     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.521      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010159971 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.108      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.927       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013073882 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.193      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.915       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010989506 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0337     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 8.22        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 11.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 615          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097100455 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | -0.165       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.551        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 11.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 630        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01174154 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | -0.0351    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.295      |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 3.86       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011451523 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.435       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 4.05        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007052511 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 5.6         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009143246 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.272      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0926     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 734         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014276567 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.517      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 817         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632338 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.209      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012789749 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.501      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.329       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016255591 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.169      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 0.409       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 852         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012276483 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 922         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010591752 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.999       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 934         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014107914 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.0944      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.497      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.56        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012459079 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.38        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 5.98        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228296 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 4.27        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 16.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 82         |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 1114       |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01038824 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.18       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    value_loss           | 12.6       |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 16.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012267148 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.114      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 16.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1139        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011626748 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.224      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 17.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009999648 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.454      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 18          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1211        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013055618 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 17.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1223        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006766434 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 7.81        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 17.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009595793 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.343      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 16.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1253         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123206545 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.48        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1264        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010147501 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.458      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1278        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015241932 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.561      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1542        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014996573 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.361      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.792       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 13.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1555         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131804105 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.163       |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 11.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1567         |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081517855 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.289        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 3.98         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 10.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1579       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01260278 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    value_loss           | 0.806      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1666        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015660591 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1685        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013021111 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1698        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014900268 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.524      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.64        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 10.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1710        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015485699 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.0586      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.162      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1723        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013269717 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 12.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1735         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070433863 |\n",
      "|    clip_fraction        | 0.071        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 5.59         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 12.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 76           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1746         |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111653935 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.112       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.156       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1758        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008899564 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.188      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.403       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 12.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 77         |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 1771       |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339544 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.0846     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.531     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.628      |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1782        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009892866 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.351       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 3.85        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 13.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 78         |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 1794       |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00966002 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.77       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    value_loss           | 7.08       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1806        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010350536 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.174      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.398      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 5.83        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1818        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015592561 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.547      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 12.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1830         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075058704 |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.355        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1842        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015596377 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.543      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1854        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009017838 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1866        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009844892 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 6.24        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1877        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009319527 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.652      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.378      |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1889        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012205083 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.147      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1901        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011463987 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1913        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016468477 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.586      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009595758 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008908296 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00888     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 7.41        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1949        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009998376 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.377      |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 7.23        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1961        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008231853 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0925      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 4.6         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1973        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009929938 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.107      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.387      |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1984        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010594625 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.717       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1996        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009151686 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.916       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 2009        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012478233 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.544      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 0.679       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 11.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 2021        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013640573 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 9.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 2034         |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134487115 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.568       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 0.306        |\n",
      "------------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 7.89       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 90         |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 2046       |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01763172 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.807      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.606     |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    value_loss           | 0.0936     |\n",
      "----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 7.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 2058        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016408734 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.589      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.0958      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 2071        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018519998 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.635      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 2084        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012321674 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.48       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 8.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 2097        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009866067 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0631      |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "switching functions from 2 to 3\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 2109        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012161842 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.599      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 2122        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010863781 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.0592      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 2134        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015639484 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.299      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.524      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "switching functions from 0 to 1\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 9.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 2146        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018826496 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.166      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.571      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 0.0715      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/lucg/.pyenv/versions/3.10.13/envs/6.8200/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/lucg/Library/Mobile Documents/com~apple~CloudDocs/Content/Work/MIT/academics/semesters/2024s/6.8200/final project/language-reward-design/videos/run_demo/rl-video-episode-0.mp4\n",
      "switching functions from 0 to 1\n",
      "switching functions from 1 to 2\n"
     ]
    }
   ],
   "source": [
    "env = create_env(reward_funcs)\n",
    "learn(2e5, env, \"minigrid_models/minigrid_custom/run_demo\", \"videos/run_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.8200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
